// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;
using Pulumi;

namespace Pulumi.PolicyPacks.Aws.Sagemaker
{
    [PolicyResourceType("aws:sagemaker/ModelPrimaryContainer:ModelPrimaryContainer")]
    public sealed class ModelPrimaryContainer
    {
        /// <summary>
        /// The DNS host name for the container.
        /// </summary>
        [Input("containerHostname")]
        public string? ContainerHostname;

        /// <summary>
        /// Environment variables for the Docker container.
        /// A list of key value pairs.
        /// </summary>
        [Input("environment")]
        public Dictionary<string, string>? Environment;

        /// <summary>
        /// The registry path where the inference code image is stored in Amazon ECR.
        /// </summary>
        [Input("image")]
        public string? Image;

        /// <summary>
        /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see [Using a Private Docker Registry for Real-Time Inference Containers](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-containers-inference-private.html). see Image Config.
        /// </summary>
        [Input("imageConfig")]
        public ModelPrimaryContainerImageConfig? ImageConfig;

        /// <summary>
        /// The inference specification name in the model package version.
        /// </summary>
        [Input("inferenceSpecificationName")]
        public string? InferenceSpecificationName;

        /// <summary>
        /// The container hosts value `SingleModel/MultiModel`. The default value is `SingleModel`.
        /// </summary>
        [Input("mode")]
        public string? Mode;

        /// <summary>
        /// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see [Deploying uncompressed models](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-uncompressed.html) in the _AWS SageMaker AI Developer Guide_.
        /// </summary>
        [Input("modelDataSource")]
        public ModelPrimaryContainerModelDataSource? ModelDataSource;

        /// <summary>
        /// The URL for the S3 location where model artifacts are stored.
        /// </summary>
        [Input("modelDataUrl")]
        public string? ModelDataUrl;

        /// <summary>
        /// The Amazon Resource Name (ARN) of the model package to use to create the model.
        /// </summary>
        [Input("modelPackageName")]
        public string? ModelPackageName;

        /// <summary>
        /// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
        /// </summary>
        [Input("multiModelConfig")]
        public ModelPrimaryContainerMultiModelConfig? MultiModelConfig;
    }
}
