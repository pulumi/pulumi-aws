// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;
using Pulumi;

namespace Pulumi.PolicyPacks.Aws.Sagemaker
{
    [PolicyResourceType("aws:sagemaker/DataQualityJobDefinitionJobResourcesClusterConfig:DataQualityJobDefinitionJobResourcesClusterConfig")]
    public sealed class DataQualityJobDefinitionJobResourcesClusterConfig
    {
        /// <summary>
        /// The number of ML compute instances to use in the model monitoring job. For distributed processing jobs, specify a value greater than 1.
        /// </summary>
        [Input("instanceCount")]
        public int? InstanceCount;

        /// <summary>
        /// The ML compute instance type for the processing job.
        /// </summary>
        [Input("instanceType")]
        public string? InstanceType;

        /// <summary>
        /// The AWS Key Management Service (AWS KMS) key that Amazon SageMaker AI uses to encrypt data on the storage volume attached to the ML compute instance(s) that run the model monitoring job.
        /// </summary>
        [Input("volumeKmsKeyId")]
        public string? VolumeKmsKeyId;

        /// <summary>
        /// The size of the ML storage volume, in gigabytes, that you want to provision. You must specify sufficient ML storage for your scenario.
        /// </summary>
        [Input("volumeSizeInGb")]
        public int? VolumeSizeInGb;
    }
}
