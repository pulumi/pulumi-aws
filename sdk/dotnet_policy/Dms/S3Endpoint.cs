// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;
using Pulumi;

namespace Pulumi.PolicyPacks.Aws.Dms
{
    [PolicyResourceType("aws:dms/s3Endpoint:S3Endpoint")]
    public sealed class S3Endpoint : global::Pulumi.PolicyResource
    {
        /// <summary>
        /// Whether to add column name information to the .csv output file. Default is `false`.
        /// </summary>
        [Input("addColumnName")]
        public bool? AddColumnName;

        /// <summary>
        /// Whether to add padding. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("addTrailingPaddingCharacter")]
        public bool? AddTrailingPaddingCharacter;

        /// <summary>
        /// S3 object prefix.
        /// </summary>
        [Input("bucketFolder")]
        public string? BucketFolder;

        /// <summary>
        /// S3 bucket name.
        /// </summary>
        [Input("bucketName")]
        public string? BucketName;

        /// <summary>
        /// Predefined (canned) access control list for objects created in an S3 bucket. Valid values include `none`, `private`, `public-read`, `public-read-write`, `authenticated-read`, `aws-exec-read`, `bucket-owner-read`, and `bucket-owner-full-control`. Default is `none`.
        /// </summary>
        [Input("cannedAclForObjects")]
        public string? CannedAclForObjects;

        /// <summary>
        /// Whether to write insert and update operations to .csv or .parquet output files. Default is `false`.
        /// </summary>
        [Input("cdcInsertsAndUpdates")]
        public bool? CdcInsertsAndUpdates;

        /// <summary>
        /// Whether to write insert operations to .csv or .parquet output files. Default is `false`.
        /// </summary>
        [Input("cdcInsertsOnly")]
        public bool? CdcInsertsOnly;

        /// <summary>
        /// Maximum length of the interval, defined in seconds, after which to output a file to Amazon S3. (AWS default is `60`.)
        /// </summary>
        [Input("cdcMaxBatchInterval")]
        public int? CdcMaxBatchInterval;

        /// <summary>
        /// Minimum file size condition as defined in kilobytes to output a file to Amazon S3. (AWS default is 32000 KB.)
        /// </summary>
        [Input("cdcMinFileSize")]
        public int? CdcMinFileSize;

        /// <summary>
        /// Folder path of CDC files. If `cdc_path` is set, AWS DMS reads CDC files from this path and replicates the data changes to the target endpoint. Supported in AWS DMS versions 3.4.2 and later.
        /// </summary>
        [Input("cdcPath")]
        public string? CdcPath;

        /// <summary>
        /// ARN for the certificate.
        /// </summary>
        [Input("certificateArn")]
        public string? CertificateArn;

        /// <summary>
        /// Set to compress target files. Valid values are `GZIP` and `NONE`. Default is `NONE`. (Ignored for source endpoints.)
        /// </summary>
        [Input("compressionType")]
        public string? CompressionType;

        /// <summary>
        /// Delimiter used to separate columns in the source files. Default is `,`.
        /// </summary>
        [Input("csvDelimiter")]
        public string? CsvDelimiter;

        /// <summary>
        /// Only applies if output files for a CDC load are written in .csv format. If `use_csv_no_sup_value` is set to `true`, string to use for all columns not included in the supplemental log. If you do not specify a string value, DMS uses the null value for these columns regardless of `use_csv_no_sup_value`. (Ignored for source endpoints.)
        /// </summary>
        [Input("csvNoSupValue")]
        public string? CsvNoSupValue;

        /// <summary>
        /// String to as null when writing to the target. (AWS default is `NULL`.)
        /// </summary>
        [Input("csvNullValue")]
        public string? CsvNullValue;

        /// <summary>
        /// Delimiter used to separate rows in the source files. Default is newline (_i.e._, `\n`).
        /// </summary>
        [Input("csvRowDelimiter")]
        public string? CsvRowDelimiter;

        /// <summary>
        /// Output format for the files that AWS DMS uses to create S3 objects. Valid values are `csv` and `parquet`.  (Ignored for source endpoints -- only `csv` is valid.)
        /// </summary>
        [Input("dataFormat")]
        public string? DataFormat;

        /// <summary>
        /// Size of one data page in bytes. (AWS default is 1 MiB, _i.e._, `1048576`.)
        /// </summary>
        [Input("dataPageSize")]
        public int? DataPageSize;

        /// <summary>
        /// Date separating delimiter to use during folder partitioning. Valid values are `SLASH`, `UNDERSCORE`, `DASH`, and `NONE`. (AWS default is `SLASH`.) (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionDelimiter")]
        public string? DatePartitionDelimiter;

        /// <summary>
        /// Partition S3 bucket folders based on transaction commit dates. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionEnabled")]
        public bool? DatePartitionEnabled;

        /// <summary>
        /// Date format to use during folder partitioning. Use this parameter when `date_partition_enabled` is set to true. Valid values are `YYYYMMDD`, `YYYYMMDDHH`, `YYYYMM`, `MMYYYYDD`, and `DDMMYYYY`. (AWS default is `YYYYMMDD`.) (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionSequence")]
        public string? DatePartitionSequence;

        /// <summary>
        /// Convert the current UTC time to a timezone. The conversion occurs when a date partition folder is created and a CDC filename is generated. The timezone format is Area/Location (_e.g._, `Europe/Paris`). Use this when `date_partition_enabled` is `true`. (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionTimezone")]
        public string? DatePartitionTimezone;

        /// <summary>
        /// Undocumented argument for use as directed by AWS Support.
        /// </summary>
        [Input("detachTargetOnLobLookupFailureParquet")]
        public bool? DetachTargetOnLobLookupFailureParquet;

        /// <summary>
        /// Maximum size in bytes of an encoded dictionary page of a column. (AWS default is 1 MiB, _i.e._, `1048576`.)
        /// </summary>
        [Input("dictPageSizeLimit")]
        public int? DictPageSizeLimit;

        /// <summary>
        /// Whether to enable statistics for Parquet pages and row groups. Default is `true`.
        /// </summary>
        [Input("enableStatistics")]
        public bool? EnableStatistics;

        /// <summary>
        /// Type of encoding to use. Value values are `rle_dictionary`, `plain`, and `plain_dictionary`. (AWS default is `rle_dictionary`.)
        /// </summary>
        [Input("encodingType")]
        public string? EncodingType;

        /// <summary>
        /// Server-side encryption mode that you want to encrypt your .csv or .parquet object files copied to S3. Valid values are `SSE_S3` and `SSE_KMS`. (AWS default is `SSE_S3`.) (Ignored for source endpoints -- only `SSE_S3` is valid.)
        /// </summary>
        [Input("encryptionMode")]
        public string? EncryptionMode;

        /// <summary>
        /// ARN for the endpoint.
        /// </summary>
        [Input("endpointArn")]
        public string? EndpointArn;

        /// <summary>
        /// Database endpoint identifier. Identifiers must contain from 1 to 255 alphanumeric characters or hyphens, begin with a letter, contain only ASCII letters, digits, and hyphens, not end with a hyphen, and not contain two consecutive hyphens.
        /// </summary>
        [Input("endpointId")]
        public string? EndpointId;

        /// <summary>
        /// Type of endpoint. Valid values are `source`, `target`.
        /// </summary>
        [Input("endpointType")]
        public string? EndpointType;

        /// <summary>
        /// Expanded name for the engine name.
        /// </summary>
        [Input("engineDisplayName")]
        public string? EngineDisplayName;

        /// <summary>
        /// Bucket owner to prevent sniping. Value is an AWS account ID.
        /// </summary>
        [Input("expectedBucketOwner")]
        public string? ExpectedBucketOwner;

        /// <summary>
        /// Can be used for cross-account validation. Use it in another account with `aws.dms.S3Endpoint` to create the endpoint cross-account.
        /// </summary>
        [Input("externalId")]
        public string? ExternalId;

        /// <summary>
        /// JSON document that describes how AWS DMS should interpret the data.
        /// </summary>
        [Input("externalTableDefinition")]
        public string? ExternalTableDefinition;

        /// <summary>
        /// Whether to integrate AWS Glue Data Catalog with an Amazon S3 target. See [Using AWS Glue Data Catalog with an Amazon S3 target for AWS DMS](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html#CHAP_Target.S3.GlueCatalog) for more information. Default is `false`.
        /// </summary>
        [Input("glueCatalogGeneration")]
        public bool? GlueCatalogGeneration;

        /// <summary>
        /// When this value is set to `1`, DMS ignores the first row header in a .csv file. (AWS default is `0`.)
        /// </summary>
        [Input("ignoreHeaderRows")]
        public int? IgnoreHeaderRows;

        /// <summary>
        /// Whether to enable a full load to write INSERT operations to the .csv output files only to indicate how the rows were added to the source database. Default is `false`.
        /// </summary>
        [Input("includeOpForFullLoad")]
        public bool? IncludeOpForFullLoad;

        /// <summary>
        /// ARN for the KMS key that will be used to encrypt the connection parameters. If you do not specify a value for `kms_key_arn`, then AWS DMS will use your default encryption key. AWS KMS creates the default encryption key for your AWS account. Your AWS account has a different default encryption key for each AWS region.
        /// </summary>
        [Input("kmsKeyArn")]
        public string? KmsKeyArn;

        /// <summary>
        /// Maximum size (in KB) of any .csv file to be created while migrating to an S3 target during full load. Valid values are from `1` to `1048576`. (AWS default is 1 GB, _i.e._, `1048576`.)
        /// </summary>
        [Input("maxFileSize")]
        public int? MaxFileSize;

        /// <summary>
        /// Specifies the precision of any TIMESTAMP column values written to an S3 object file in .parquet format. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("parquetTimestampInMillisecond")]
        public bool? ParquetTimestampInMillisecond;

        /// <summary>
        /// Version of the .parquet file format. Valid values are `parquet-1-0` and `parquet-2-0`. (AWS default is `parquet-1-0`.) (Ignored for source endpoints.)
        /// </summary>
        [Input("parquetVersion")]
        public string? ParquetVersion;

        /// <summary>
        /// Whether DMS saves the transaction order for a CDC load on the S3 target specified by `cdc_path`. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("preserveTransactions")]
        public bool? PreserveTransactions;

        /// <summary>
        /// For an S3 source, whether each leading double quotation mark has to be followed by an ending double quotation mark. Default is `true`.
        /// </summary>
        [Input("rfc4180")]
        public bool? Rfc4180;

        /// <summary>
        /// Number of rows in a row group. (AWS default is `10000`.)
        /// </summary>
        [Input("rowGroupLength")]
        public int? RowGroupLength;

        /// <summary>
        /// When `encryption_mode` is `SSE_KMS`, ARN for the AWS KMS key. (Ignored for source endpoints -- only `SSE_S3` `encryption_mode` is valid.)
        /// </summary>
        [Input("serverSideEncryptionKmsKeyId")]
        public string? ServerSideEncryptionKmsKeyId;

        /// <summary>
        /// ARN of the IAM role with permissions to the S3 Bucket.
        /// 
        /// The following arguments are optional:
        /// </summary>
        [Input("serviceAccessRoleArn")]
        public string? ServiceAccessRoleArn;

        /// <summary>
        /// SSL mode to use for the connection. Valid values are `none`, `require`, `verify-ca`, `verify-full`. (AWS default is `none`.)
        /// </summary>
        [Input("sslMode")]
        public string? SslMode;

        /// <summary>
        /// Status of the endpoint.
        /// </summary>
        [Input("status")]
        public string? Status;

        /// <summary>
        /// Map of tags to assign to the resource. If configured with a provider `default_tags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
        /// </summary>
        [Input("tags")]
        public Dictionary<string, string>? Tags;

        /// <summary>
        /// Map of tags assigned to the resource, including those inherited from the provider `default_tags` configuration block.
        /// </summary>
        [Input("tagsAll")]
        public Dictionary<string, string>? TagsAll;

        /// <summary>
        /// Column to add with timestamp information to the endpoint data for an Amazon S3 target.
        /// </summary>
        [Input("timestampColumnName")]
        public string? TimestampColumnName;

        /// <summary>
        /// Whether to use `csv_no_sup_value` for columns not included in the supplemental log. (Ignored for source endpoints.)
        /// </summary>
        [Input("useCsvNoSupValue")]
        public bool? UseCsvNoSupValue;

        /// <summary>
        /// When set to `true`, uses the task start time as the timestamp column value instead of the time data is written to target. For full load, when set to `true`, each row of the timestamp column contains the task start time. For CDC loads, each row of the timestamp column contains the transaction commit time.When set to false, the full load timestamp in the timestamp column increments with the time data arrives at the target. Default is `false`.
        /// </summary>
        [Input("useTaskStartTimeForFullLoadTimestamp")]
        public bool? UseTaskStartTimeForFullLoadTimestamp;
    }
}
