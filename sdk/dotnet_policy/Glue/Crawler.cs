// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;
using Pulumi;

namespace Pulumi.PolicyPacks.Aws.Glue
{
    [PolicyResourceType("aws:glue/crawler:Crawler")]
    public sealed class Crawler : global::Pulumi.PolicyResource
    {
        /// <summary>
        /// The ARN of the crawler
        /// </summary>
        [Input("arn")]
        public string? Arn;

        /// <summary>
        /// List of nested AWS Glue Data Catalog target arguments. See Catalog Target below.
        /// </summary>
        [Input("catalogTargets")]
        public List<CrawlerCatalogTarget>? CatalogTargets;

        /// <summary>
        /// List of custom classifiers. By default, all AWS classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.
        /// </summary>
        [Input("classifiers")]
        public List<string>? Classifiers;

        /// <summary>
        /// JSON string of configuration information. For more details see [Setting Crawler Configuration Options](https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html).
        /// </summary>
        [Input("configuration")]
        public string? Configuration;

        /// <summary>
        /// Glue database where results are written.
        /// </summary>
        [Input("databaseName")]
        public string? DatabaseName;

        /// <summary>
        /// List of nested Delta Lake target arguments. See Delta Target below.
        /// </summary>
        [Input("deltaTargets")]
        public List<CrawlerDeltaTarget>? DeltaTargets;

        /// <summary>
        /// Description of the crawler.
        /// </summary>
        [Input("description")]
        public string? Description;

        /// <summary>
        /// List of nested DynamoDB target arguments. See Dynamodb Target below.
        /// </summary>
        [Input("dynamodbTargets")]
        public List<CrawlerDynamodbTarget>? DynamodbTargets;

        /// <summary>
        /// List of nested Hudi target arguments. See Iceberg Target below.
        /// </summary>
        [Input("hudiTargets")]
        public List<CrawlerHudiTarget>? HudiTargets;

        /// <summary>
        /// List of nested Iceberg target arguments. See Iceberg Target below.
        /// </summary>
        [Input("icebergTargets")]
        public List<CrawlerIcebergTarget>? IcebergTargets;

        /// <summary>
        /// List of nested JDBC target arguments. See JDBC Target below.
        /// </summary>
        [Input("jdbcTargets")]
        public List<CrawlerJdbcTarget>? JdbcTargets;

        /// <summary>
        /// Specifies Lake Formation configuration settings for the crawler. See Lake Formation Configuration below.
        /// </summary>
        [Input("lakeFormationConfiguration")]
        public CrawlerLakeFormationConfiguration? LakeFormationConfiguration;

        /// <summary>
        /// Specifies data lineage configuration settings for the crawler. See Lineage Configuration below.
        /// </summary>
        [Input("lineageConfiguration")]
        public CrawlerLineageConfiguration? LineageConfiguration;

        /// <summary>
        /// List of nested MongoDB target arguments. See MongoDB Target below.
        /// </summary>
        [Input("mongodbTargets")]
        public List<CrawlerMongodbTarget>? MongodbTargets;

        /// <summary>
        /// Name of the crawler.
        /// </summary>
        [Input("name")]
        public string? Name;

        /// <summary>
        /// A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that were added since the last crawler run.. See Recrawl Policy below.
        /// </summary>
        [Input("recrawlPolicy")]
        public CrawlerRecrawlPolicy? RecrawlPolicy;

        /// <summary>
        /// The IAM role friendly name (including path without leading slash), or ARN of an IAM role, used by the crawler to access other resources.
        /// </summary>
        [Input("role")]
        public string? Role;

        /// <summary>
        /// List of nested Amazon S3 target arguments. See S3 Target below.
        /// </summary>
        [Input("s3Targets")]
        public List<CrawlerS3Target>? S3Targets;

        /// <summary>
        /// A cron expression used to specify the schedule. For more information, see [Time-Based Schedules for Jobs and Crawlers](https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html). For example, to run something every day at 12:15 UTC, you would specify: `cron(15 12 * * ? *)`.
        /// </summary>
        [Input("schedule")]
        public string? Schedule;

        /// <summary>
        /// Policy for the crawler's update and deletion behavior. See Schema Change Policy below.
        /// </summary>
        [Input("schemaChangePolicy")]
        public CrawlerSchemaChangePolicy? SchemaChangePolicy;

        /// <summary>
        /// The name of Security Configuration to be used by the crawler
        /// </summary>
        [Input("securityConfiguration")]
        public string? SecurityConfiguration;

        /// <summary>
        /// The table prefix used for catalog tables that are created.
        /// </summary>
        [Input("tablePrefix")]
        public string? TablePrefix;

        /// <summary>
        /// Key-value map of resource tags. .If configured with a provider `default_tags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
        /// </summary>
        [Input("tags")]
        public Dictionary<string, string>? Tags;

        /// <summary>
        /// A map of tags assigned to the resource, including those inherited from the provider `default_tags` configuration block.
        /// </summary>
        [Input("tagsAll")]
        public Dictionary<string, string>? TagsAll;
    }
}
