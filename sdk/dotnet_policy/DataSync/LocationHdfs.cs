// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;
using Pulumi;

namespace Pulumi.PolicyPacks.Aws.DataSync
{
    [PolicyResourceType("aws:datasync/locationHdfs:LocationHdfs")]
    public sealed class LocationHdfs : global::Pulumi.PolicyResource
    {
        /// <summary>
        /// A list of DataSync Agent ARNs with which this location will be associated.
        /// </summary>
        [Input("agentArns")]
        public List<string>? AgentArns;

        /// <summary>
        /// Amazon Resource Name (ARN) of the DataSync Location.
        /// </summary>
        [Input("arn")]
        public string? Arn;

        /// <summary>
        /// The type of authentication used to determine the identity of the user. Valid values are `SIMPLE` and `KERBEROS`.
        /// </summary>
        [Input("authenticationType")]
        public string? AuthenticationType;

        /// <summary>
        /// The size of data blocks to write into the HDFS cluster. The block size must be a multiple of 512 bytes. The default block size is 128 mebibytes (MiB).
        /// </summary>
        [Input("blockSize")]
        public int? BlockSize;

        /// <summary>
        /// The Kerberos key table (keytab) that contains mappings between the defined Kerberos principal and the encrypted keys. Use `kerberos_keytab_base64` instead whenever the value is not a valid UTF-8 string. If `KERBEROS` is specified for `authentication_type`, this parameter (or `kerberos_keytab_base64`) is required.
        /// </summary>
        [Input("kerberosKeytab")]
        public string? KerberosKeytab;

        /// <summary>
        /// Use instead of `kerberos_keytab` to pass base64-encoded binary data directly. If `KERBEROS` is specified for `authentication_type`, this parameter (or `kerberos_keytab`) is required.
        /// </summary>
        [Input("kerberosKeytabBase64")]
        public string? KerberosKeytabBase64;

        /// <summary>
        /// The krb5.conf file that contains the Kerberos configuration information. Use `kerberos_krb5_conf_base64` instead whenever the value is not a valid UTF-8 string. If `KERBEROS` is specified for `authentication_type`, this parameter (or `kerberos_krb5_conf_base64`) is required.
        /// </summary>
        [Input("kerberosKrb5Conf")]
        public string? KerberosKrb5Conf;

        /// <summary>
        /// Use instead of `kerberos_krb5_conf` to pass base64-encoded binary data directly. If `KERBEROS` is specified for `authentication_type`, this parameter (or `kerberos_krb5_conf`) is required.
        /// </summary>
        [Input("kerberosKrb5ConfBase64")]
        public string? KerberosKrb5ConfBase64;

        /// <summary>
        /// The Kerberos principal with access to the files and folders on the HDFS cluster. If `KERBEROS` is specified for `authentication_type`, this parameter is required.
        /// </summary>
        [Input("kerberosPrincipal")]
        public string? KerberosPrincipal;

        /// <summary>
        /// The URI of the HDFS cluster's Key Management Server (KMS).
        /// </summary>
        [Input("kmsKeyProviderUri")]
        public string? KmsKeyProviderUri;

        /// <summary>
        /// The NameNode that manages the HDFS namespace. The NameNode performs operations such as opening, closing, and renaming files and directories. The NameNode contains the information to map blocks of data to the DataNodes. You can use only one NameNode. See configuration below.
        /// </summary>
        [Input("nameNodes")]
        public List<LocationHdfsNameNode>? NameNodes;

        /// <summary>
        /// The Quality of Protection (QOP) configuration specifies the Remote Procedure Call (RPC) and data transfer protection settings configured on the Hadoop Distributed File System (HDFS) cluster. If `qop_configuration` isn't specified, `rpc_protection` and `data_transfer_protection` default to `PRIVACY`. If you set RpcProtection or DataTransferProtection, the other parameter assumes the same value.  See configuration below.
        /// </summary>
        [Input("qopConfiguration")]
        public LocationHdfsQopConfiguration? QopConfiguration;

        /// <summary>
        /// The number of DataNodes to replicate the data to when writing to the HDFS cluster. By default, data is replicated to three DataNodes.
        /// </summary>
        [Input("replicationFactor")]
        public int? ReplicationFactor;

        /// <summary>
        /// The user name used to identify the client on the host operating system. If `SIMPLE` is specified for `authentication_type`, this parameter is required.
        /// </summary>
        [Input("simpleUser")]
        public string? SimpleUser;

        /// <summary>
        /// A subdirectory in the HDFS cluster. This subdirectory is used to read data from or write data to the HDFS cluster. If the subdirectory isn't specified, it will default to /.
        /// </summary>
        [Input("subdirectory")]
        public string? Subdirectory;

        /// <summary>
        /// Key-value pairs of resource tags to assign to the DataSync Location. If configured with a provider `default_tags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
        /// </summary>
        [Input("tags")]
        public Dictionary<string, string>? Tags;

        /// <summary>
        /// A map of tags assigned to the resource, including those inherited from the provider `default_tags` configuration block.
        /// </summary>
        [Input("tagsAll")]
        public Dictionary<string, string>? TagsAll;

        [Input("uri")]
        public string? Uri;
    }
}
