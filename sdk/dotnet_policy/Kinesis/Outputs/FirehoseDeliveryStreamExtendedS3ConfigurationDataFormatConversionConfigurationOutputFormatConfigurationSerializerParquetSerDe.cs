// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;
using Pulumi;

namespace Pulumi.PolicyPacks.Aws.Kinesis.Outputs
{
    public sealed class FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializerParquetSerDe
    {
        /// <summary>
        /// The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.
        /// </summary>
        [PolicyResourceProperty("blockSizeBytes", "_mUnknown_BlockSizeBytes")]
        #pragma warning disable CS0649 // Field is assigned through deserializer
        private int? _mValue_BlockSizeBytes;
        private bool _mUnknown_BlockSizeBytes;
        public int? BlockSizeBytes
        {
            get
            {
                if (!_mUnknown_BlockSizeBytes) return _mValue_BlockSizeBytes;
                throw new UndeferrableValueException("Value 'FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializerParquetSerDe.BlockSizeBytes' is not present");
            }
        }

        /// <summary>
        /// The compression code to use over data blocks. The possible values are `UNCOMPRESSED`, `SNAPPY`, and `GZIP`, with the default being `SNAPPY`. Use `SNAPPY` for higher decompression speed. Use `GZIP` if the compression ratio is more important than speed.
        /// </summary>
        [PolicyResourceProperty("compression", "_mUnknown_Compression")]
        #pragma warning disable CS0649 // Field is assigned through deserializer
        private string? _mValue_Compression;
        private bool _mUnknown_Compression;
        public string? Compression
        {
            get
            {
                if (!_mUnknown_Compression) return _mValue_Compression;
                throw new UndeferrableValueException("Value 'FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializerParquetSerDe.Compression' is not present");
            }
        }

        /// <summary>
        /// Indicates whether to enable dictionary compression.
        /// </summary>
        [PolicyResourceProperty("enableDictionaryCompression", "_mUnknown_EnableDictionaryCompression")]
        #pragma warning disable CS0649 // Field is assigned through deserializer
        private bool? _mValue_EnableDictionaryCompression;
        private bool _mUnknown_EnableDictionaryCompression;
        public bool? EnableDictionaryCompression
        {
            get
            {
                if (!_mUnknown_EnableDictionaryCompression) return _mValue_EnableDictionaryCompression;
                throw new UndeferrableValueException("Value 'FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializerParquetSerDe.EnableDictionaryCompression' is not present");
            }
        }

        /// <summary>
        /// The maximum amount of padding to apply. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is `0`.
        /// </summary>
        [PolicyResourceProperty("maxPaddingBytes", "_mUnknown_MaxPaddingBytes")]
        #pragma warning disable CS0649 // Field is assigned through deserializer
        private int? _mValue_MaxPaddingBytes;
        private bool _mUnknown_MaxPaddingBytes;
        public int? MaxPaddingBytes
        {
            get
            {
                if (!_mUnknown_MaxPaddingBytes) return _mValue_MaxPaddingBytes;
                throw new UndeferrableValueException("Value 'FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializerParquetSerDe.MaxPaddingBytes' is not present");
            }
        }

        /// <summary>
        /// The Parquet page size. Column chunks are divided into pages. A page is conceptually an indivisible unit (in terms of compression and encoding). The minimum value is 64 KiB and the default is 1 MiB.
        /// </summary>
        [PolicyResourceProperty("pageSizeBytes", "_mUnknown_PageSizeBytes")]
        #pragma warning disable CS0649 // Field is assigned through deserializer
        private int? _mValue_PageSizeBytes;
        private bool _mUnknown_PageSizeBytes;
        public int? PageSizeBytes
        {
            get
            {
                if (!_mUnknown_PageSizeBytes) return _mValue_PageSizeBytes;
                throw new UndeferrableValueException("Value 'FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializerParquetSerDe.PageSizeBytes' is not present");
            }
        }

        /// <summary>
        /// Indicates the version of row format to output. The possible values are `V1` and `V2`. The default is `V1`.
        /// </summary>
        [PolicyResourceProperty("writerVersion", "_mUnknown_WriterVersion")]
        #pragma warning disable CS0649 // Field is assigned through deserializer
        private string? _mValue_WriterVersion;
        private bool _mUnknown_WriterVersion;
        public string? WriterVersion
        {
            get
            {
                if (!_mUnknown_WriterVersion) return _mValue_WriterVersion;
                throw new UndeferrableValueException("Value 'FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializerParquetSerDe.WriterVersion' is not present");
            }
        }
    }
}
