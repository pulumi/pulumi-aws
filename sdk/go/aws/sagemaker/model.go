// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package sagemaker

import (
	"github.com/pkg/errors"
	"github.com/pulumi/pulumi/sdk/go/pulumi"
)

// Provides a SageMaker model resource.
//
// > This content is derived from https://github.com/terraform-providers/terraform-provider-aws/blob/master/website/docs/r/sagemaker_model.html.markdown.
type Model struct {
	s *pulumi.ResourceState
}

// NewModel registers a new resource with the given unique name, arguments, and options.
func NewModel(ctx *pulumi.Context,
	name string, args *ModelArgs, opts ...pulumi.ResourceOpt) (*Model, error) {
	if args == nil || args.ExecutionRoleArn == nil {
		return nil, errors.New("missing required argument 'ExecutionRoleArn'")
	}
	inputs := make(map[string]interface{})
	if args == nil {
		inputs["containers"] = nil
		inputs["enableNetworkIsolation"] = nil
		inputs["executionRoleArn"] = nil
		inputs["name"] = nil
		inputs["primaryContainer"] = nil
		inputs["tags"] = nil
		inputs["vpcConfig"] = nil
	} else {
		inputs["containers"] = args.Containers
		inputs["enableNetworkIsolation"] = args.EnableNetworkIsolation
		inputs["executionRoleArn"] = args.ExecutionRoleArn
		inputs["name"] = args.Name
		inputs["primaryContainer"] = args.PrimaryContainer
		inputs["tags"] = args.Tags
		inputs["vpcConfig"] = args.VpcConfig
	}
	inputs["arn"] = nil
	s, err := ctx.RegisterResource("aws:sagemaker/model:Model", name, true, inputs, opts...)
	if err != nil {
		return nil, err
	}
	return &Model{s: s}, nil
}

// GetModel gets an existing Model resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetModel(ctx *pulumi.Context,
	name string, id pulumi.ID, state *ModelState, opts ...pulumi.ResourceOpt) (*Model, error) {
	inputs := make(map[string]interface{})
	if state != nil {
		inputs["arn"] = state.Arn
		inputs["containers"] = state.Containers
		inputs["enableNetworkIsolation"] = state.EnableNetworkIsolation
		inputs["executionRoleArn"] = state.ExecutionRoleArn
		inputs["name"] = state.Name
		inputs["primaryContainer"] = state.PrimaryContainer
		inputs["tags"] = state.Tags
		inputs["vpcConfig"] = state.VpcConfig
	}
	s, err := ctx.ReadResource("aws:sagemaker/model:Model", name, id, inputs, opts...)
	if err != nil {
		return nil, err
	}
	return &Model{s: s}, nil
}

// URN is this resource's unique name assigned by Pulumi.
func (r *Model) URN() *pulumi.URNOutput {
	return r.s.URN()
}

// ID is this resource's unique identifier assigned by its provider.
func (r *Model) ID() *pulumi.IDOutput {
	return r.s.ID()
}

// The Amazon Resource Name (ARN) assigned by AWS to this model.
func (r *Model) Arn() *pulumi.StringOutput {
	return (*pulumi.StringOutput)(r.s.State["arn"])
}

// Specifies containers in the inference pipeline. If not specified, the `primaryContainer` argument is required. Fields are documented below.
func (r *Model) Containers() *pulumi.ArrayOutput {
	return (*pulumi.ArrayOutput)(r.s.State["containers"])
}

// Isolates the model container. No inbound or outbound network calls can be made to or from the model container.
func (r *Model) EnableNetworkIsolation() *pulumi.BoolOutput {
	return (*pulumi.BoolOutput)(r.s.State["enableNetworkIsolation"])
}

// A role that SageMaker can assume to access model artifacts and docker images for deployment.
func (r *Model) ExecutionRoleArn() *pulumi.StringOutput {
	return (*pulumi.StringOutput)(r.s.State["executionRoleArn"])
}

// The name of the model (must be unique). If omitted, this provider will assign a random, unique name.
func (r *Model) Name() *pulumi.StringOutput {
	return (*pulumi.StringOutput)(r.s.State["name"])
}

// The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the `container` argument is required. Fields are documented below.
func (r *Model) PrimaryContainer() *pulumi.Output {
	return r.s.State["primaryContainer"]
}

// A mapping of tags to assign to the resource.
func (r *Model) Tags() *pulumi.MapOutput {
	return (*pulumi.MapOutput)(r.s.State["tags"])
}

// Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.
func (r *Model) VpcConfig() *pulumi.Output {
	return r.s.State["vpcConfig"]
}

// Input properties used for looking up and filtering Model resources.
type ModelState struct {
	// The Amazon Resource Name (ARN) assigned by AWS to this model.
	Arn interface{}
	// Specifies containers in the inference pipeline. If not specified, the `primaryContainer` argument is required. Fields are documented below.
	Containers interface{}
	// Isolates the model container. No inbound or outbound network calls can be made to or from the model container.
	EnableNetworkIsolation interface{}
	// A role that SageMaker can assume to access model artifacts and docker images for deployment.
	ExecutionRoleArn interface{}
	// The name of the model (must be unique). If omitted, this provider will assign a random, unique name.
	Name interface{}
	// The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the `container` argument is required. Fields are documented below.
	PrimaryContainer interface{}
	// A mapping of tags to assign to the resource.
	Tags interface{}
	// Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.
	VpcConfig interface{}
}

// The set of arguments for constructing a Model resource.
type ModelArgs struct {
	// Specifies containers in the inference pipeline. If not specified, the `primaryContainer` argument is required. Fields are documented below.
	Containers interface{}
	// Isolates the model container. No inbound or outbound network calls can be made to or from the model container.
	EnableNetworkIsolation interface{}
	// A role that SageMaker can assume to access model artifacts and docker images for deployment.
	ExecutionRoleArn interface{}
	// The name of the model (must be unique). If omitted, this provider will assign a random, unique name.
	Name interface{}
	// The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the `container` argument is required. Fields are documented below.
	PrimaryContainer interface{}
	// A mapping of tags to assign to the resource.
	Tags interface{}
	// Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.
	VpcConfig interface{}
}
