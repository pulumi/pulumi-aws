// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package rekognition

import (
	"context"
	"reflect"

	"errors"
	"github.com/pulumi/pulumi-aws/sdk/v6/go/aws/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Resource for managing an AWS Rekognition Stream Processor.
//
// > This resource must be configured specifically for your use case, and not all options are compatible with one another. See [Stream Processor API documentation](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_CreateStreamProcessor.html#rekognition-CreateStreamProcessor-request-Input) for configuration information.
//
// > Stream Processors configured for Face Recognition cannot have _any_ properties updated after the fact, and it will result in an AWS API error.
//
// ## Example Usage
//
// ### Label Detection
//
// ```go
// package main
//
// import (
//
//	"encoding/json"
//	"fmt"
//
//	"github.com/pulumi/pulumi-aws/sdk/v6/go/aws/iam"
//	"github.com/pulumi/pulumi-aws/sdk/v6/go/aws/kinesis"
//	"github.com/pulumi/pulumi-aws/sdk/v6/go/aws/rekognition"
//	"github.com/pulumi/pulumi-aws/sdk/v6/go/aws/s3"
//	"github.com/pulumi/pulumi-aws/sdk/v6/go/aws/sns"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			example, err := s3.NewBucketV2(ctx, "example", &s3.BucketV2Args{
//				Bucket: pulumi.String("example-bucket"),
//			})
//			if err != nil {
//				return err
//			}
//			exampleTopic, err := sns.NewTopic(ctx, "example", &sns.TopicArgs{
//				Name: pulumi.String("example-topic"),
//			})
//			if err != nil {
//				return err
//			}
//			exampleVideoStream, err := kinesis.NewVideoStream(ctx, "example", &kinesis.VideoStreamArgs{
//				Name:                 pulumi.String("example-kinesis-input"),
//				DataRetentionInHours: pulumi.Int(1),
//				DeviceName:           pulumi.String("kinesis-video-device-name"),
//				MediaType:            pulumi.String("video/h264"),
//			})
//			if err != nil {
//				return err
//			}
//			tmpJSON0, err := json.Marshal(map[string]interface{}{
//				"Version": "2012-10-17",
//				"Statement": []map[string]interface{}{
//					map[string]interface{}{
//						"Action": "sts:AssumeRole",
//						"Effect": "Allow",
//						"Principal": map[string]interface{}{
//							"Service": "rekognition.amazonaws.com",
//						},
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			json0 := string(tmpJSON0)
//			exampleRole, err := iam.NewRole(ctx, "example", &iam.RoleArgs{
//				Name: pulumi.String("example-role"),
//				InlinePolicies: iam.RoleInlinePolicyArray{
//					&iam.RoleInlinePolicyArgs{
//						Name: pulumi.String("Rekognition-Access"),
//						Policy: pulumi.All(example.Arn, exampleTopic.Arn, exampleVideoStream.Arn).ApplyT(func(_args []interface{}) (string, error) {
//							exampleArn := _args[0].(string)
//							exampleTopicArn := _args[1].(string)
//							exampleVideoStreamArn := _args[2].(string)
//							var _zero string
//							tmpJSON1, err := json.Marshal(map[string]interface{}{
//								"Version": "2012-10-17",
//								"Statement": []interface{}{
//									map[string]interface{}{
//										"Action": []string{
//											"s3:PutObject",
//										},
//										"Effect": "Allow",
//										"Resource": []string{
//											fmt.Sprintf("%v/*", exampleArn),
//										},
//									},
//									map[string]interface{}{
//										"Action": []string{
//											"sns:Publish",
//										},
//										"Effect": "Allow",
//										"Resource": []string{
//											exampleTopicArn,
//										},
//									},
//									map[string]interface{}{
//										"Action": []string{
//											"kinesis:Get*",
//											"kinesis:DescribeStreamSummary",
//										},
//										"Effect": "Allow",
//										"Resource": []string{
//											exampleVideoStreamArn,
//										},
//									},
//								},
//							})
//							if err != nil {
//								return _zero, err
//							}
//							json1 := string(tmpJSON1)
//							return json1, nil
//						}).(pulumi.StringOutput),
//					},
//				},
//				AssumeRolePolicy: pulumi.String(json0),
//			})
//			if err != nil {
//				return err
//			}
//			_, err = rekognition.NewStreamProcessor(ctx, "example", &rekognition.StreamProcessorArgs{
//				RoleArn: exampleRole.Arn,
//				Name:    pulumi.String("example-processor"),
//				DataSharingPreference: &rekognition.StreamProcessorDataSharingPreferenceArgs{
//					OptIn: pulumi.Bool(false),
//				},
//				Output: &rekognition.StreamProcessorOutputTypeArgs{
//					S3Destination: &rekognition.StreamProcessorOutputS3DestinationArgs{
//						Bucket: example.Bucket,
//					},
//				},
//				Settings: &rekognition.StreamProcessorSettingsArgs{
//					ConnectedHome: &rekognition.StreamProcessorSettingsConnectedHomeArgs{
//						Labels: pulumi.StringArray{
//							pulumi.String("PERSON"),
//							pulumi.String("PET"),
//						},
//					},
//				},
//				Input: &rekognition.StreamProcessorInputTypeArgs{
//					KinesisVideoStream: &rekognition.StreamProcessorInputKinesisVideoStreamArgs{
//						Arn: exampleVideoStream.Arn,
//					},
//				},
//				NotificationChannel: &rekognition.StreamProcessorNotificationChannelArgs{
//					SnsTopicArn: exampleTopic.Arn,
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// ### Face Detection Usage
//
// ```go
// package main
//
// import (
//
//	"encoding/json"
//
//	"github.com/pulumi/pulumi-aws/sdk/v6/go/aws/iam"
//	"github.com/pulumi/pulumi-aws/sdk/v6/go/aws/kinesis"
//	"github.com/pulumi/pulumi-aws/sdk/v6/go/aws/rekognition"
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			example, err := kinesis.NewVideoStream(ctx, "example", &kinesis.VideoStreamArgs{
//				Name:                 pulumi.String("example-kinesis-input"),
//				DataRetentionInHours: pulumi.Int(1),
//				DeviceName:           pulumi.String("kinesis-video-device-name"),
//				MediaType:            pulumi.String("video/h264"),
//			})
//			if err != nil {
//				return err
//			}
//			exampleStream, err := kinesis.NewStream(ctx, "example", &kinesis.StreamArgs{
//				Name:       pulumi.String("pulumi-kinesis-example"),
//				ShardCount: pulumi.Int(1),
//			})
//			if err != nil {
//				return err
//			}
//			tmpJSON0, err := json.Marshal(map[string]interface{}{
//				"Version": "2012-10-17",
//				"Statement": []map[string]interface{}{
//					map[string]interface{}{
//						"Action": "sts:AssumeRole",
//						"Effect": "Allow",
//						"Principal": map[string]interface{}{
//							"Service": "rekognition.amazonaws.com",
//						},
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			json0 := string(tmpJSON0)
//			exampleRole, err := iam.NewRole(ctx, "example", &iam.RoleArgs{
//				Name: pulumi.String("example-role"),
//				InlinePolicies: iam.RoleInlinePolicyArray{
//					&iam.RoleInlinePolicyArgs{
//						Name: pulumi.String("Rekognition-Access"),
//						Policy: pulumi.All(example.Arn, exampleStream.Arn).ApplyT(func(_args []interface{}) (string, error) {
//							exampleArn := _args[0].(string)
//							exampleStreamArn := _args[1].(string)
//							var _zero string
//							tmpJSON1, err := json.Marshal(map[string]interface{}{
//								"Version": "2012-10-17",
//								"Statement": []interface{}{
//									map[string]interface{}{
//										"Action": []string{
//											"kinesis:Get*",
//											"kinesis:DescribeStreamSummary",
//										},
//										"Effect": "Allow",
//										"Resource": []string{
//											exampleArn,
//										},
//									},
//									map[string]interface{}{
//										"Action": []string{
//											"kinesis:PutRecord",
//										},
//										"Effect": "Allow",
//										"Resource": []string{
//											exampleStreamArn,
//										},
//									},
//								},
//							})
//							if err != nil {
//								return _zero, err
//							}
//							json1 := string(tmpJSON1)
//							return json1, nil
//						}).(pulumi.StringOutput),
//					},
//				},
//				AssumeRolePolicy: pulumi.String(json0),
//			})
//			if err != nil {
//				return err
//			}
//			exampleCollection, err := rekognition.NewCollection(ctx, "example", &rekognition.CollectionArgs{
//				CollectionId: pulumi.String("example-collection"),
//			})
//			if err != nil {
//				return err
//			}
//			_, err = rekognition.NewStreamProcessor(ctx, "example", &rekognition.StreamProcessorArgs{
//				RoleArn: exampleRole.Arn,
//				Name:    pulumi.String("example-processor"),
//				DataSharingPreference: &rekognition.StreamProcessorDataSharingPreferenceArgs{
//					OptIn: pulumi.Bool(false),
//				},
//				RegionsOfInterests: rekognition.StreamProcessorRegionsOfInterestArray{
//					&rekognition.StreamProcessorRegionsOfInterestArgs{
//						Polygons: rekognition.StreamProcessorRegionsOfInterestPolygonArray{
//							&rekognition.StreamProcessorRegionsOfInterestPolygonArgs{
//								X: pulumi.Float64(0.5),
//								Y: pulumi.Float64(0.5),
//							},
//							&rekognition.StreamProcessorRegionsOfInterestPolygonArgs{
//								X: pulumi.Float64(0.5),
//								Y: pulumi.Float64(0.5),
//							},
//							&rekognition.StreamProcessorRegionsOfInterestPolygonArgs{
//								X: pulumi.Float64(0.5),
//								Y: pulumi.Float64(0.5),
//							},
//						},
//					},
//				},
//				Input: &rekognition.StreamProcessorInputTypeArgs{
//					KinesisVideoStream: &rekognition.StreamProcessorInputKinesisVideoStreamArgs{
//						Arn: example.Arn,
//					},
//				},
//				Output: &rekognition.StreamProcessorOutputTypeArgs{
//					KinesisDataStream: &rekognition.StreamProcessorOutputKinesisDataStreamArgs{
//						Arn: exampleStream.Arn,
//					},
//				},
//				Settings: &rekognition.StreamProcessorSettingsArgs{
//					FaceSearch: &rekognition.StreamProcessorSettingsFaceSearchArgs{
//						CollectionId: exampleCollection.ID(),
//					},
//				},
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// ## Import
//
// Using `pulumi import`, import Rekognition Stream Processor using the `name`. For example:
//
// ```sh
// $ pulumi import aws:rekognition/streamProcessor:StreamProcessor example my-stream
// ```
type StreamProcessor struct {
	pulumi.CustomResourceState

	// ARN of the Stream Processor.
	Arn pulumi.StringOutput `pulumi:"arn"`
	// See `dataSharingPreference`.
	DataSharingPreference StreamProcessorDataSharingPreferencePtrOutput `pulumi:"dataSharingPreference"`
	// Input video stream. See `input`.
	Input StreamProcessorInputTypePtrOutput `pulumi:"input"`
	// Optional parameter for label detection stream processors.
	KmsKeyId pulumi.StringPtrOutput `pulumi:"kmsKeyId"`
	// The name of the Stream Processor.
	Name pulumi.StringOutput `pulumi:"name"`
	// The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the completion status. See `notificationChannel`.
	NotificationChannel StreamProcessorNotificationChannelPtrOutput `pulumi:"notificationChannel"`
	// Kinesis data stream stream or Amazon S3 bucket location to which Amazon Rekognition Video puts the analysis results. See `output`.
	Output StreamProcessorOutputTypePtrOutput `pulumi:"output"`
	// Specifies locations in the frames where Amazon Rekognition checks for objects or people. See `regionsOfInterest`.
	RegionsOfInterests StreamProcessorRegionsOfInterestArrayOutput `pulumi:"regionsOfInterests"`
	// The Amazon Resource Number (ARN) of the IAM role that allows access to the stream processor. The IAM role provides Rekognition read permissions for a Kinesis stream. It also provides write permissions to an Amazon S3 bucket and Amazon Simple Notification Service topic for a label detection stream processor. This is required for both face search and label detection stream processors.
	RoleArn pulumi.StringOutput `pulumi:"roleArn"`
	// Input parameters used in a streaming video analyzed by a stream processor. See `settings`.
	//
	// The following arguments are optional:
	Settings StreamProcessorSettingsPtrOutput `pulumi:"settings"`
	// (**Deprecated**) ARN of the Stream Processor.
	// Use `arn` instead.
	//
	// Deprecated: Use 'arn' instead. This attribute will be removed in a future version of the provider.
	StreamProcessorArn pulumi.StringOutput `pulumi:"streamProcessorArn"`
	// A map of tags to assign to the resource. If configured with a provider `defaultTags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
	Tags pulumi.StringMapOutput `pulumi:"tags"`
	// A map of tags assigned to the resource, including those inherited from the provider `defaultTags` configuration block.
	//
	// Deprecated: Please use `tags` instead.
	TagsAll  pulumi.StringMapOutput           `pulumi:"tagsAll"`
	Timeouts StreamProcessorTimeoutsPtrOutput `pulumi:"timeouts"`
}

// NewStreamProcessor registers a new resource with the given unique name, arguments, and options.
func NewStreamProcessor(ctx *pulumi.Context,
	name string, args *StreamProcessorArgs, opts ...pulumi.ResourceOption) (*StreamProcessor, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.RoleArn == nil {
		return nil, errors.New("invalid value for required argument 'RoleArn'")
	}
	opts = internal.PkgResourceDefaultOpts(opts)
	var resource StreamProcessor
	err := ctx.RegisterResource("aws:rekognition/streamProcessor:StreamProcessor", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetStreamProcessor gets an existing StreamProcessor resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetStreamProcessor(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *StreamProcessorState, opts ...pulumi.ResourceOption) (*StreamProcessor, error) {
	var resource StreamProcessor
	err := ctx.ReadResource("aws:rekognition/streamProcessor:StreamProcessor", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering StreamProcessor resources.
type streamProcessorState struct {
	// ARN of the Stream Processor.
	Arn *string `pulumi:"arn"`
	// See `dataSharingPreference`.
	DataSharingPreference *StreamProcessorDataSharingPreference `pulumi:"dataSharingPreference"`
	// Input video stream. See `input`.
	Input *StreamProcessorInputType `pulumi:"input"`
	// Optional parameter for label detection stream processors.
	KmsKeyId *string `pulumi:"kmsKeyId"`
	// The name of the Stream Processor.
	Name *string `pulumi:"name"`
	// The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the completion status. See `notificationChannel`.
	NotificationChannel *StreamProcessorNotificationChannel `pulumi:"notificationChannel"`
	// Kinesis data stream stream or Amazon S3 bucket location to which Amazon Rekognition Video puts the analysis results. See `output`.
	Output *StreamProcessorOutputType `pulumi:"output"`
	// Specifies locations in the frames where Amazon Rekognition checks for objects or people. See `regionsOfInterest`.
	RegionsOfInterests []StreamProcessorRegionsOfInterest `pulumi:"regionsOfInterests"`
	// The Amazon Resource Number (ARN) of the IAM role that allows access to the stream processor. The IAM role provides Rekognition read permissions for a Kinesis stream. It also provides write permissions to an Amazon S3 bucket and Amazon Simple Notification Service topic for a label detection stream processor. This is required for both face search and label detection stream processors.
	RoleArn *string `pulumi:"roleArn"`
	// Input parameters used in a streaming video analyzed by a stream processor. See `settings`.
	//
	// The following arguments are optional:
	Settings *StreamProcessorSettings `pulumi:"settings"`
	// (**Deprecated**) ARN of the Stream Processor.
	// Use `arn` instead.
	//
	// Deprecated: Use 'arn' instead. This attribute will be removed in a future version of the provider.
	StreamProcessorArn *string `pulumi:"streamProcessorArn"`
	// A map of tags to assign to the resource. If configured with a provider `defaultTags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
	Tags map[string]string `pulumi:"tags"`
	// A map of tags assigned to the resource, including those inherited from the provider `defaultTags` configuration block.
	//
	// Deprecated: Please use `tags` instead.
	TagsAll  map[string]string        `pulumi:"tagsAll"`
	Timeouts *StreamProcessorTimeouts `pulumi:"timeouts"`
}

type StreamProcessorState struct {
	// ARN of the Stream Processor.
	Arn pulumi.StringPtrInput
	// See `dataSharingPreference`.
	DataSharingPreference StreamProcessorDataSharingPreferencePtrInput
	// Input video stream. See `input`.
	Input StreamProcessorInputTypePtrInput
	// Optional parameter for label detection stream processors.
	KmsKeyId pulumi.StringPtrInput
	// The name of the Stream Processor.
	Name pulumi.StringPtrInput
	// The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the completion status. See `notificationChannel`.
	NotificationChannel StreamProcessorNotificationChannelPtrInput
	// Kinesis data stream stream or Amazon S3 bucket location to which Amazon Rekognition Video puts the analysis results. See `output`.
	Output StreamProcessorOutputTypePtrInput
	// Specifies locations in the frames where Amazon Rekognition checks for objects or people. See `regionsOfInterest`.
	RegionsOfInterests StreamProcessorRegionsOfInterestArrayInput
	// The Amazon Resource Number (ARN) of the IAM role that allows access to the stream processor. The IAM role provides Rekognition read permissions for a Kinesis stream. It also provides write permissions to an Amazon S3 bucket and Amazon Simple Notification Service topic for a label detection stream processor. This is required for both face search and label detection stream processors.
	RoleArn pulumi.StringPtrInput
	// Input parameters used in a streaming video analyzed by a stream processor. See `settings`.
	//
	// The following arguments are optional:
	Settings StreamProcessorSettingsPtrInput
	// (**Deprecated**) ARN of the Stream Processor.
	// Use `arn` instead.
	//
	// Deprecated: Use 'arn' instead. This attribute will be removed in a future version of the provider.
	StreamProcessorArn pulumi.StringPtrInput
	// A map of tags to assign to the resource. If configured with a provider `defaultTags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
	Tags pulumi.StringMapInput
	// A map of tags assigned to the resource, including those inherited from the provider `defaultTags` configuration block.
	//
	// Deprecated: Please use `tags` instead.
	TagsAll  pulumi.StringMapInput
	Timeouts StreamProcessorTimeoutsPtrInput
}

func (StreamProcessorState) ElementType() reflect.Type {
	return reflect.TypeOf((*streamProcessorState)(nil)).Elem()
}

type streamProcessorArgs struct {
	// See `dataSharingPreference`.
	DataSharingPreference *StreamProcessorDataSharingPreference `pulumi:"dataSharingPreference"`
	// Input video stream. See `input`.
	Input *StreamProcessorInputType `pulumi:"input"`
	// Optional parameter for label detection stream processors.
	KmsKeyId *string `pulumi:"kmsKeyId"`
	// The name of the Stream Processor.
	Name *string `pulumi:"name"`
	// The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the completion status. See `notificationChannel`.
	NotificationChannel *StreamProcessorNotificationChannel `pulumi:"notificationChannel"`
	// Kinesis data stream stream or Amazon S3 bucket location to which Amazon Rekognition Video puts the analysis results. See `output`.
	Output *StreamProcessorOutputType `pulumi:"output"`
	// Specifies locations in the frames where Amazon Rekognition checks for objects or people. See `regionsOfInterest`.
	RegionsOfInterests []StreamProcessorRegionsOfInterest `pulumi:"regionsOfInterests"`
	// The Amazon Resource Number (ARN) of the IAM role that allows access to the stream processor. The IAM role provides Rekognition read permissions for a Kinesis stream. It also provides write permissions to an Amazon S3 bucket and Amazon Simple Notification Service topic for a label detection stream processor. This is required for both face search and label detection stream processors.
	RoleArn string `pulumi:"roleArn"`
	// Input parameters used in a streaming video analyzed by a stream processor. See `settings`.
	//
	// The following arguments are optional:
	Settings *StreamProcessorSettings `pulumi:"settings"`
	// A map of tags to assign to the resource. If configured with a provider `defaultTags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
	Tags     map[string]string        `pulumi:"tags"`
	Timeouts *StreamProcessorTimeouts `pulumi:"timeouts"`
}

// The set of arguments for constructing a StreamProcessor resource.
type StreamProcessorArgs struct {
	// See `dataSharingPreference`.
	DataSharingPreference StreamProcessorDataSharingPreferencePtrInput
	// Input video stream. See `input`.
	Input StreamProcessorInputTypePtrInput
	// Optional parameter for label detection stream processors.
	KmsKeyId pulumi.StringPtrInput
	// The name of the Stream Processor.
	Name pulumi.StringPtrInput
	// The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the completion status. See `notificationChannel`.
	NotificationChannel StreamProcessorNotificationChannelPtrInput
	// Kinesis data stream stream or Amazon S3 bucket location to which Amazon Rekognition Video puts the analysis results. See `output`.
	Output StreamProcessorOutputTypePtrInput
	// Specifies locations in the frames where Amazon Rekognition checks for objects or people. See `regionsOfInterest`.
	RegionsOfInterests StreamProcessorRegionsOfInterestArrayInput
	// The Amazon Resource Number (ARN) of the IAM role that allows access to the stream processor. The IAM role provides Rekognition read permissions for a Kinesis stream. It also provides write permissions to an Amazon S3 bucket and Amazon Simple Notification Service topic for a label detection stream processor. This is required for both face search and label detection stream processors.
	RoleArn pulumi.StringInput
	// Input parameters used in a streaming video analyzed by a stream processor. See `settings`.
	//
	// The following arguments are optional:
	Settings StreamProcessorSettingsPtrInput
	// A map of tags to assign to the resource. If configured with a provider `defaultTags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
	Tags     pulumi.StringMapInput
	Timeouts StreamProcessorTimeoutsPtrInput
}

func (StreamProcessorArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*streamProcessorArgs)(nil)).Elem()
}

type StreamProcessorInput interface {
	pulumi.Input

	ToStreamProcessorOutput() StreamProcessorOutput
	ToStreamProcessorOutputWithContext(ctx context.Context) StreamProcessorOutput
}

func (*StreamProcessor) ElementType() reflect.Type {
	return reflect.TypeOf((**StreamProcessor)(nil)).Elem()
}

func (i *StreamProcessor) ToStreamProcessorOutput() StreamProcessorOutput {
	return i.ToStreamProcessorOutputWithContext(context.Background())
}

func (i *StreamProcessor) ToStreamProcessorOutputWithContext(ctx context.Context) StreamProcessorOutput {
	return pulumi.ToOutputWithContext(ctx, i).(StreamProcessorOutput)
}

// StreamProcessorArrayInput is an input type that accepts StreamProcessorArray and StreamProcessorArrayOutput values.
// You can construct a concrete instance of `StreamProcessorArrayInput` via:
//
//	StreamProcessorArray{ StreamProcessorArgs{...} }
type StreamProcessorArrayInput interface {
	pulumi.Input

	ToStreamProcessorArrayOutput() StreamProcessorArrayOutput
	ToStreamProcessorArrayOutputWithContext(context.Context) StreamProcessorArrayOutput
}

type StreamProcessorArray []StreamProcessorInput

func (StreamProcessorArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*StreamProcessor)(nil)).Elem()
}

func (i StreamProcessorArray) ToStreamProcessorArrayOutput() StreamProcessorArrayOutput {
	return i.ToStreamProcessorArrayOutputWithContext(context.Background())
}

func (i StreamProcessorArray) ToStreamProcessorArrayOutputWithContext(ctx context.Context) StreamProcessorArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(StreamProcessorArrayOutput)
}

// StreamProcessorMapInput is an input type that accepts StreamProcessorMap and StreamProcessorMapOutput values.
// You can construct a concrete instance of `StreamProcessorMapInput` via:
//
//	StreamProcessorMap{ "key": StreamProcessorArgs{...} }
type StreamProcessorMapInput interface {
	pulumi.Input

	ToStreamProcessorMapOutput() StreamProcessorMapOutput
	ToStreamProcessorMapOutputWithContext(context.Context) StreamProcessorMapOutput
}

type StreamProcessorMap map[string]StreamProcessorInput

func (StreamProcessorMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*StreamProcessor)(nil)).Elem()
}

func (i StreamProcessorMap) ToStreamProcessorMapOutput() StreamProcessorMapOutput {
	return i.ToStreamProcessorMapOutputWithContext(context.Background())
}

func (i StreamProcessorMap) ToStreamProcessorMapOutputWithContext(ctx context.Context) StreamProcessorMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(StreamProcessorMapOutput)
}

type StreamProcessorOutput struct{ *pulumi.OutputState }

func (StreamProcessorOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**StreamProcessor)(nil)).Elem()
}

func (o StreamProcessorOutput) ToStreamProcessorOutput() StreamProcessorOutput {
	return o
}

func (o StreamProcessorOutput) ToStreamProcessorOutputWithContext(ctx context.Context) StreamProcessorOutput {
	return o
}

// ARN of the Stream Processor.
func (o StreamProcessorOutput) Arn() pulumi.StringOutput {
	return o.ApplyT(func(v *StreamProcessor) pulumi.StringOutput { return v.Arn }).(pulumi.StringOutput)
}

// See `dataSharingPreference`.
func (o StreamProcessorOutput) DataSharingPreference() StreamProcessorDataSharingPreferencePtrOutput {
	return o.ApplyT(func(v *StreamProcessor) StreamProcessorDataSharingPreferencePtrOutput { return v.DataSharingPreference }).(StreamProcessorDataSharingPreferencePtrOutput)
}

// Input video stream. See `input`.
func (o StreamProcessorOutput) Input() StreamProcessorInputTypePtrOutput {
	return o.ApplyT(func(v *StreamProcessor) StreamProcessorInputTypePtrOutput { return v.Input }).(StreamProcessorInputTypePtrOutput)
}

// Optional parameter for label detection stream processors.
func (o StreamProcessorOutput) KmsKeyId() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *StreamProcessor) pulumi.StringPtrOutput { return v.KmsKeyId }).(pulumi.StringPtrOutput)
}

// The name of the Stream Processor.
func (o StreamProcessorOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *StreamProcessor) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

// The Amazon Simple Notification Service topic to which Amazon Rekognition publishes the completion status. See `notificationChannel`.
func (o StreamProcessorOutput) NotificationChannel() StreamProcessorNotificationChannelPtrOutput {
	return o.ApplyT(func(v *StreamProcessor) StreamProcessorNotificationChannelPtrOutput { return v.NotificationChannel }).(StreamProcessorNotificationChannelPtrOutput)
}

// Kinesis data stream stream or Amazon S3 bucket location to which Amazon Rekognition Video puts the analysis results. See `output`.
func (o StreamProcessorOutput) Output() StreamProcessorOutputTypePtrOutput {
	return o.ApplyT(func(v *StreamProcessor) StreamProcessorOutputTypePtrOutput { return v.Output }).(StreamProcessorOutputTypePtrOutput)
}

// Specifies locations in the frames where Amazon Rekognition checks for objects or people. See `regionsOfInterest`.
func (o StreamProcessorOutput) RegionsOfInterests() StreamProcessorRegionsOfInterestArrayOutput {
	return o.ApplyT(func(v *StreamProcessor) StreamProcessorRegionsOfInterestArrayOutput { return v.RegionsOfInterests }).(StreamProcessorRegionsOfInterestArrayOutput)
}

// The Amazon Resource Number (ARN) of the IAM role that allows access to the stream processor. The IAM role provides Rekognition read permissions for a Kinesis stream. It also provides write permissions to an Amazon S3 bucket and Amazon Simple Notification Service topic for a label detection stream processor. This is required for both face search and label detection stream processors.
func (o StreamProcessorOutput) RoleArn() pulumi.StringOutput {
	return o.ApplyT(func(v *StreamProcessor) pulumi.StringOutput { return v.RoleArn }).(pulumi.StringOutput)
}

// Input parameters used in a streaming video analyzed by a stream processor. See `settings`.
//
// The following arguments are optional:
func (o StreamProcessorOutput) Settings() StreamProcessorSettingsPtrOutput {
	return o.ApplyT(func(v *StreamProcessor) StreamProcessorSettingsPtrOutput { return v.Settings }).(StreamProcessorSettingsPtrOutput)
}

// (**Deprecated**) ARN of the Stream Processor.
// Use `arn` instead.
//
// Deprecated: Use 'arn' instead. This attribute will be removed in a future version of the provider.
func (o StreamProcessorOutput) StreamProcessorArn() pulumi.StringOutput {
	return o.ApplyT(func(v *StreamProcessor) pulumi.StringOutput { return v.StreamProcessorArn }).(pulumi.StringOutput)
}

// A map of tags to assign to the resource. If configured with a provider `defaultTags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
func (o StreamProcessorOutput) Tags() pulumi.StringMapOutput {
	return o.ApplyT(func(v *StreamProcessor) pulumi.StringMapOutput { return v.Tags }).(pulumi.StringMapOutput)
}

// A map of tags assigned to the resource, including those inherited from the provider `defaultTags` configuration block.
//
// Deprecated: Please use `tags` instead.
func (o StreamProcessorOutput) TagsAll() pulumi.StringMapOutput {
	return o.ApplyT(func(v *StreamProcessor) pulumi.StringMapOutput { return v.TagsAll }).(pulumi.StringMapOutput)
}

func (o StreamProcessorOutput) Timeouts() StreamProcessorTimeoutsPtrOutput {
	return o.ApplyT(func(v *StreamProcessor) StreamProcessorTimeoutsPtrOutput { return v.Timeouts }).(StreamProcessorTimeoutsPtrOutput)
}

type StreamProcessorArrayOutput struct{ *pulumi.OutputState }

func (StreamProcessorArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*StreamProcessor)(nil)).Elem()
}

func (o StreamProcessorArrayOutput) ToStreamProcessorArrayOutput() StreamProcessorArrayOutput {
	return o
}

func (o StreamProcessorArrayOutput) ToStreamProcessorArrayOutputWithContext(ctx context.Context) StreamProcessorArrayOutput {
	return o
}

func (o StreamProcessorArrayOutput) Index(i pulumi.IntInput) StreamProcessorOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *StreamProcessor {
		return vs[0].([]*StreamProcessor)[vs[1].(int)]
	}).(StreamProcessorOutput)
}

type StreamProcessorMapOutput struct{ *pulumi.OutputState }

func (StreamProcessorMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*StreamProcessor)(nil)).Elem()
}

func (o StreamProcessorMapOutput) ToStreamProcessorMapOutput() StreamProcessorMapOutput {
	return o
}

func (o StreamProcessorMapOutput) ToStreamProcessorMapOutputWithContext(ctx context.Context) StreamProcessorMapOutput {
	return o
}

func (o StreamProcessorMapOutput) MapIndex(k pulumi.StringInput) StreamProcessorOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *StreamProcessor {
		return vs[0].(map[string]*StreamProcessor)[vs[1].(string)]
	}).(StreamProcessorOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*StreamProcessorInput)(nil)).Elem(), &StreamProcessor{})
	pulumi.RegisterInputType(reflect.TypeOf((*StreamProcessorArrayInput)(nil)).Elem(), StreamProcessorArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*StreamProcessorMapInput)(nil)).Elem(), StreamProcessorMap{})
	pulumi.RegisterOutputType(StreamProcessorOutput{})
	pulumi.RegisterOutputType(StreamProcessorArrayOutput{})
	pulumi.RegisterOutputType(StreamProcessorMapOutput{})
}
