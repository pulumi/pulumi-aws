// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../../types/input";
import * as outputs from "../../types/output";
import * as enums from "../../types/enums";
import * as utilities from "../../utilities";

import {RoutingRule} from "@/s3";

export interface AnalyticsApplicationCloudwatchLoggingOptions {
    /**
     * The ARN of the Kinesis Analytics Application.
     */
    id: string;
    /**
     * The ARN of the CloudWatch Log Stream.
     */
    logStreamArn: string;
    /**
     * The ARN of the IAM Role used to send application messages.
     */
    roleArn: string;
}

export interface AnalyticsApplicationInputs {
    /**
     * The ARN of the Kinesis Analytics Application.
     */
    id: string;
    /**
     * The Kinesis Firehose configuration for the streaming source. Conflicts with `kinesisStream`.
     * See Kinesis Firehose below for more details.
     */
    kinesisFirehose?: outputs.kinesis.AnalyticsApplicationInputsKinesisFirehose;
    /**
     * The Kinesis Stream configuration for the streaming source. Conflicts with `kinesisFirehose`.
     * See Kinesis Stream below for more details.
     */
    kinesisStream?: outputs.kinesis.AnalyticsApplicationInputsKinesisStream;
    /**
     * The Name Prefix to use when creating an in-application stream.
     */
    namePrefix: string;
    /**
     * The number of Parallel in-application streams to create.
     * See Parallelism below for more details.
     */
    parallelism: outputs.kinesis.AnalyticsApplicationInputsParallelism;
    /**
     * The Processing Configuration to transform records as they are received from the stream.
     * See Processing Configuration below for more details.
     */
    processingConfiguration?: outputs.kinesis.AnalyticsApplicationInputsProcessingConfiguration;
    /**
     * The Schema format of the data in the streaming source. See Source Schema below for more details.
     */
    schema: outputs.kinesis.AnalyticsApplicationInputsSchema;
    /**
     * The point at which the application starts processing records from the streaming source.
     * See Starting Position Configuration below for more details.
     */
    startingPositionConfigurations: outputs.kinesis.AnalyticsApplicationInputsStartingPositionConfiguration[];
    streamNames: string[];
}

export interface AnalyticsApplicationInputsKinesisFirehose {
    /**
     * The ARN of the Kinesis Firehose delivery stream.
     */
    resourceArn: string;
    /**
     * The ARN of the IAM Role used to access the stream.
     */
    roleArn: string;
}

export interface AnalyticsApplicationInputsKinesisStream {
    /**
     * The ARN of the Kinesis Stream.
     */
    resourceArn: string;
    /**
     * The ARN of the IAM Role used to access the stream.
     */
    roleArn: string;
}

export interface AnalyticsApplicationInputsParallelism {
    /**
     * The Count of streams.
     */
    count: number;
}

export interface AnalyticsApplicationInputsProcessingConfiguration {
    /**
     * The Lambda function configuration. See Lambda below for more details.
     */
    lambda: outputs.kinesis.AnalyticsApplicationInputsProcessingConfigurationLambda;
}

export interface AnalyticsApplicationInputsProcessingConfigurationLambda {
    /**
     * The ARN of the Lambda function.
     */
    resourceArn: string;
    /**
     * The ARN of the IAM Role used to access the Lambda function.
     */
    roleArn: string;
}

export interface AnalyticsApplicationInputsSchema {
    /**
     * The Record Column mapping for the streaming source data element.
     * See Record Columns below for more details.
     */
    recordColumns: outputs.kinesis.AnalyticsApplicationInputsSchemaRecordColumn[];
    /**
     * The Encoding of the record in the streaming source.
     */
    recordEncoding?: string;
    /**
     * The Record Format and mapping information to schematize a record.
     * See Record Format below for more details.
     */
    recordFormat: outputs.kinesis.AnalyticsApplicationInputsSchemaRecordFormat;
}

export interface AnalyticsApplicationInputsSchemaRecordColumn {
    /**
     * The Mapping reference to the data element.
     */
    mapping?: string;
    /**
     * Name of the column.
     */
    name: string;
    /**
     * The SQL Type of the column.
     */
    sqlType: string;
}

export interface AnalyticsApplicationInputsSchemaRecordFormat {
    /**
     * The Mapping Information for the record format.
     * See Mapping Parameters below for more details.
     */
    mappingParameters?: outputs.kinesis.AnalyticsApplicationInputsSchemaRecordFormatMappingParameters;
    /**
     * The type of Record Format. Can be `CSV` or `JSON`.
     */
    recordFormatType: string;
}

export interface AnalyticsApplicationInputsSchemaRecordFormatMappingParameters {
    /**
     * Mapping information when the record format uses delimiters.
     * See CSV Mapping Parameters below for more details.
     */
    csv?: outputs.kinesis.AnalyticsApplicationInputsSchemaRecordFormatMappingParametersCsv;
    /**
     * Mapping information when JSON is the record format on the streaming source.
     * See JSON Mapping Parameters below for more details.
     */
    json?: outputs.kinesis.AnalyticsApplicationInputsSchemaRecordFormatMappingParametersJson;
}

export interface AnalyticsApplicationInputsSchemaRecordFormatMappingParametersCsv {
    /**
     * The Column Delimiter.
     */
    recordColumnDelimiter: string;
    /**
     * The Row Delimiter.
     */
    recordRowDelimiter: string;
}

export interface AnalyticsApplicationInputsSchemaRecordFormatMappingParametersJson {
    /**
     * Path to the top-level parent that contains the records.
     */
    recordRowPath: string;
}

export interface AnalyticsApplicationInputsStartingPositionConfiguration {
    /**
     * The starting position on the stream. Valid values: `LAST_STOPPED_POINT`, `NOW`, `TRIM_HORIZON`.
     */
    startingPosition: string;
}

export interface AnalyticsApplicationOutput {
    /**
     * The ARN of the Kinesis Analytics Application.
     */
    id: string;
    /**
     * The Kinesis Firehose configuration for the destination stream. Conflicts with `kinesisStream`.
     * See Kinesis Firehose below for more details.
     */
    kinesisFirehose?: outputs.kinesis.AnalyticsApplicationOutputKinesisFirehose;
    /**
     * The Kinesis Stream configuration for the destination stream. Conflicts with `kinesisFirehose`.
     * See Kinesis Stream below for more details.
     */
    kinesisStream?: outputs.kinesis.AnalyticsApplicationOutputKinesisStream;
    /**
     * The Lambda function destination. See Lambda below for more details.
     */
    lambda?: outputs.kinesis.AnalyticsApplicationOutputLambda;
    /**
     * The Name of the in-application stream.
     */
    name: string;
    /**
     * The Schema format of the data written to the destination. See Destination Schema below for more details.
     */
    schema: outputs.kinesis.AnalyticsApplicationOutputSchema;
}

export interface AnalyticsApplicationOutputKinesisFirehose {
    /**
     * The ARN of the Kinesis Firehose delivery stream.
     */
    resourceArn: string;
    /**
     * The ARN of the IAM Role used to access the stream.
     */
    roleArn: string;
}

export interface AnalyticsApplicationOutputKinesisStream {
    /**
     * The ARN of the Kinesis Stream.
     */
    resourceArn: string;
    /**
     * The ARN of the IAM Role used to access the stream.
     */
    roleArn: string;
}

export interface AnalyticsApplicationOutputLambda {
    /**
     * The ARN of the Lambda function.
     */
    resourceArn: string;
    /**
     * The ARN of the IAM Role used to access the Lambda function.
     */
    roleArn: string;
}

export interface AnalyticsApplicationOutputSchema {
    /**
     * The Format Type of the records on the output stream. Can be `CSV` or `JSON`.
     */
    recordFormatType: string;
}

export interface AnalyticsApplicationReferenceDataSources {
    /**
     * The ARN of the Kinesis Analytics Application.
     */
    id: string;
    /**
     * The S3 configuration for the reference data source. See S3 Reference below for more details.
     */
    s3: outputs.kinesis.AnalyticsApplicationReferenceDataSourcesS3;
    /**
     * The Schema format of the data in the streaming source. See Source Schema below for more details.
     */
    schema: outputs.kinesis.AnalyticsApplicationReferenceDataSourcesSchema;
    /**
     * The in-application Table Name.
     */
    tableName: string;
}

export interface AnalyticsApplicationReferenceDataSourcesS3 {
    /**
     * The S3 Bucket ARN.
     */
    bucketArn: string;
    /**
     * The File Key name containing reference data.
     */
    fileKey: string;
    /**
     * The ARN of the IAM Role used to send application messages.
     */
    roleArn: string;
}

export interface AnalyticsApplicationReferenceDataSourcesSchema {
    /**
     * The Record Column mapping for the streaming source data element.
     * See Record Columns below for more details.
     */
    recordColumns: outputs.kinesis.AnalyticsApplicationReferenceDataSourcesSchemaRecordColumn[];
    /**
     * The Encoding of the record in the streaming source.
     */
    recordEncoding?: string;
    /**
     * The Record Format and mapping information to schematize a record.
     * See Record Format below for more details.
     */
    recordFormat: outputs.kinesis.AnalyticsApplicationReferenceDataSourcesSchemaRecordFormat;
}

export interface AnalyticsApplicationReferenceDataSourcesSchemaRecordColumn {
    /**
     * The Mapping reference to the data element.
     */
    mapping?: string;
    /**
     * Name of the column.
     */
    name: string;
    /**
     * The SQL Type of the column.
     */
    sqlType: string;
}

export interface AnalyticsApplicationReferenceDataSourcesSchemaRecordFormat {
    /**
     * The Mapping Information for the record format.
     * See Mapping Parameters below for more details.
     */
    mappingParameters?: outputs.kinesis.AnalyticsApplicationReferenceDataSourcesSchemaRecordFormatMappingParameters;
    /**
     * The type of Record Format. Can be `CSV` or `JSON`.
     */
    recordFormatType: string;
}

export interface AnalyticsApplicationReferenceDataSourcesSchemaRecordFormatMappingParameters {
    /**
     * Mapping information when the record format uses delimiters.
     * See CSV Mapping Parameters below for more details.
     */
    csv?: outputs.kinesis.AnalyticsApplicationReferenceDataSourcesSchemaRecordFormatMappingParametersCsv;
    /**
     * Mapping information when JSON is the record format on the streaming source.
     * See JSON Mapping Parameters below for more details.
     */
    json?: outputs.kinesis.AnalyticsApplicationReferenceDataSourcesSchemaRecordFormatMappingParametersJson;
}

export interface AnalyticsApplicationReferenceDataSourcesSchemaRecordFormatMappingParametersCsv {
    /**
     * The Column Delimiter.
     */
    recordColumnDelimiter: string;
    /**
     * The Row Delimiter.
     */
    recordRowDelimiter: string;
}

export interface AnalyticsApplicationReferenceDataSourcesSchemaRecordFormatMappingParametersJson {
    /**
     * Path to the top-level parent that contains the records.
     */
    recordRowPath: string;
}

export interface FirehoseDeliveryStreamElasticsearchConfiguration {
    /**
     * Buffer incoming data for the specified period of time, in seconds between 60 to 900, before delivering it to the destination.  The default value is 300s.
     */
    bufferingInterval?: number;
    /**
     * Buffer incoming data to the specified size, in MBs between 1 to 100, before delivering it to the destination.  The default value is 5MB.
     */
    bufferingSize?: number;
    /**
     * The CloudWatch Logging Options for the delivery stream. More details are given below
     */
    cloudwatchLoggingOptions: outputs.kinesis.FirehoseDeliveryStreamElasticsearchConfigurationCloudwatchLoggingOptions;
    /**
     * The endpoint to use when communicating with the cluster. Conflicts with `domainArn`.
     */
    clusterEndpoint?: string;
    /**
     * The ARN of the Amazon ES domain.  The pattern needs to be `arn:.*`.  Conflicts with `clusterEndpoint`.
     */
    domainArn?: string;
    /**
     * The Elasticsearch index name.
     */
    indexName: string;
    /**
     * The Elasticsearch index rotation period.  Index rotation appends a timestamp to the IndexName to facilitate expiration of old data.  Valid values are `NoRotation`, `OneHour`, `OneDay`, `OneWeek`, and `OneMonth`.  The default value is `OneDay`.
     */
    indexRotationPeriod?: string;
    /**
     * The data processing configuration.  More details are given below.
     */
    processingConfiguration?: outputs.kinesis.FirehoseDeliveryStreamElasticsearchConfigurationProcessingConfiguration;
    /**
     * After an initial failure to deliver to Amazon Elasticsearch, the total amount of time, in seconds between 0 to 7200, during which Firehose re-attempts delivery (including the first attempt).  After this time has elapsed, the failed documents are written to Amazon S3.  The default value is 300s.  There will be no retry if the value is 0.
     */
    retryDuration?: number;
    /**
     * The ARN of the IAM role to be assumed by Firehose for calling the Amazon ES Configuration API and for indexing documents.  The IAM role must have permission for `DescribeElasticsearchDomain`, `DescribeElasticsearchDomains`, and `DescribeElasticsearchDomainConfig`.  The pattern needs to be `arn:.*`.
     */
    roleArn: string;
    /**
     * Defines how documents should be delivered to Amazon S3.  Valid values are `FailedDocumentsOnly` and `AllDocuments`.  Default value is `FailedDocumentsOnly`.
     */
    s3BackupMode?: string;
    /**
     * The Elasticsearch type name with maximum length of 100 characters.
     */
    typeName?: string;
    /**
     * The VPC configuration for the delivery stream to connect to Elastic Search associated with the VPC. More details are given below
     */
    vpcConfig?: outputs.kinesis.FirehoseDeliveryStreamElasticsearchConfigurationVpcConfig;
}

export interface FirehoseDeliveryStreamElasticsearchConfigurationCloudwatchLoggingOptions {
    /**
     * Enables or disables the logging. Defaults to `false`.
     */
    enabled?: boolean;
    /**
     * The CloudWatch group name for logging. This value is required if `enabled` is true.
     */
    logGroupName?: string;
    /**
     * The CloudWatch log stream name for logging. This value is required if `enabled` is true.
     */
    logStreamName?: string;
}

export interface FirehoseDeliveryStreamElasticsearchConfigurationProcessingConfiguration {
    /**
     * Enables or disables data processing.
     */
    enabled?: boolean;
    /**
     * Array of data processors. More details are given below
     */
    processors?: outputs.kinesis.FirehoseDeliveryStreamElasticsearchConfigurationProcessingConfigurationProcessor[];
}

export interface FirehoseDeliveryStreamElasticsearchConfigurationProcessingConfigurationProcessor {
    /**
     * Array of processor parameters. More details are given below
     */
    parameters?: outputs.kinesis.FirehoseDeliveryStreamElasticsearchConfigurationProcessingConfigurationProcessorParameter[];
    /**
     * The type of processor. Valid Values: `RecordDeAggregation`, `Lambda`, `MetadataExtraction`, `AppendDelimiterToRecord`. Validation is done against [AWS SDK constants](https://docs.aws.amazon.com/sdk-for-go/api/service/firehose/#pkg-constants); so that values not explicitly listed may also work.
     */
    type: string;
}

export interface FirehoseDeliveryStreamElasticsearchConfigurationProcessingConfigurationProcessorParameter {
    /**
     * Parameter name. Valid Values: `LambdaArn`, `NumberOfRetries`, `MetadataExtractionQuery`, `JsonParsingEngine`, `RoleArn`, `BufferSizeInMBs`, `BufferIntervalInSeconds`, `SubRecordType`, `Delimiter`. Validation is done against [AWS SDK constants](https://docs.aws.amazon.com/sdk-for-go/api/service/firehose/#pkg-constants); so that values not explicitly listed may also work.
     */
    parameterName: string;
    /**
     * Parameter value. Must be between 1 and 512 length (inclusive). When providing a Lambda ARN, you should specify the resource version as well.
     */
    parameterValue: string;
}

export interface FirehoseDeliveryStreamElasticsearchConfigurationVpcConfig {
    /**
     * The ARN of the IAM role to be assumed by Firehose for calling the Amazon EC2 configuration API and for creating network interfaces. Make sure role has necessary [IAM permissions](https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-es-vpc)
     */
    roleArn: string;
    /**
     * A list of security group IDs to associate with Kinesis Firehose.
     */
    securityGroupIds: string[];
    /**
     * A list of subnet IDs to associate with Kinesis Firehose.
     */
    subnetIds: string[];
    vpcId: string;
}

export interface FirehoseDeliveryStreamExtendedS3Configuration {
    /**
     * The ARN of the S3 bucket
     */
    bucketArn: string;
    /**
     * Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300.
     */
    bufferInterval?: number;
    /**
     * Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5.
     * We recommend setting SizeInMBs to a value greater than the amount of data you typically ingest into the delivery stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec set SizeInMBs to be 10 MB or higher.
     */
    bufferSize?: number;
    /**
     * The CloudWatch Logging Options for the delivery stream. More details are given below
     */
    cloudwatchLoggingOptions: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationCloudwatchLoggingOptions;
    /**
     * The compression format. If no value is specified, the default is `UNCOMPRESSED`. Other supported values are `GZIP`, `ZIP`, `Snappy`, & `HADOOP_SNAPPY`.
     */
    compressionFormat?: string;
    /**
     * Nested argument for the serializer, deserializer, and schema for converting data from the JSON format to the Parquet or ORC format before writing it to Amazon S3. More details given below.
     */
    dataFormatConversionConfiguration?: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfiguration;
    /**
     * The configuration for dynamic partitioning. See Dynamic Partitioning Configuration below for more details.
     */
    dynamicPartitioningConfiguration?: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationDynamicPartitioningConfiguration;
    /**
     * Prefix added to failed records before writing them to S3. Not currently supported for `redshift` destination. This prefix appears immediately following the bucket name. For information about how to specify this prefix, see [Custom Prefixes for Amazon S3 Objects](https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
     */
    errorOutputPrefix?: string;
    /**
     * Specifies the KMS key ARN the stream will use to encrypt data. If not set, no encryption will
     * be used.
     */
    kmsKeyArn?: string;
    /**
     * The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket
     */
    prefix?: string;
    /**
     * The data processing configuration.  More details are given below.
     */
    processingConfiguration?: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationProcessingConfiguration;
    /**
     * The role that Kinesis Data Firehose can use to access AWS Glue. This role must be in the same account you use for Kinesis Data Firehose. Cross-account roles aren't allowed.
     */
    roleArn: string;
    /**
     * The configuration for backup in Amazon S3. Required if `s3BackupMode` is `Enabled`. Supports the same fields as `s3Configuration` object.
     */
    s3BackupConfiguration?: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationS3BackupConfiguration;
    /**
     * The Amazon S3 backup mode.  Valid values are `Disabled` and `Enabled`.  Default value is `Disabled`.
     */
    s3BackupMode?: string;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationCloudwatchLoggingOptions {
    /**
     * Enables or disables the logging. Defaults to `false`.
     */
    enabled?: boolean;
    /**
     * The CloudWatch group name for logging. This value is required if `enabled` is true.
     */
    logGroupName?: string;
    /**
     * The CloudWatch log stream name for logging. This value is required if `enabled` is true.
     */
    logStreamName?: string;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfiguration {
    /**
     * Enables or disables [dynamic partitioning](https://docs.aws.amazon.com/firehose/latest/dev/dynamic-partitioning.html). Defaults to `false`.
     */
    enabled?: boolean;
    /**
     * Nested argument that specifies the deserializer that you want Kinesis Data Firehose to use to convert the format of your data from JSON. More details below.
     */
    inputFormatConfiguration: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationInputFormatConfiguration;
    /**
     * Nested argument that specifies the serializer that you want Kinesis Data Firehose to use to convert the format of your data to the Parquet or ORC format. More details below.
     */
    outputFormatConfiguration: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfiguration;
    /**
     * Nested argument that specifies the AWS Glue Data Catalog table that contains the column information. More details below.
     */
    schemaConfiguration: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationSchemaConfiguration;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationInputFormatConfiguration {
    /**
     * Nested argument that specifies which deserializer to use. You can choose either the Apache Hive JSON SerDe or the OpenX JSON SerDe. More details below.
     */
    deserializer: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationInputFormatConfigurationDeserializer;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationInputFormatConfigurationDeserializer {
    /**
     * Nested argument that specifies the native Hive / HCatalog JsonSerDe. More details below.
     */
    hiveJsonSerDe?: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationInputFormatConfigurationDeserializerHiveJsonSerDe;
    /**
     * Nested argument that specifies the OpenX SerDe. More details below.
     */
    openXJsonSerDe?: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationInputFormatConfigurationDeserializerOpenXJsonSerDe;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationInputFormatConfigurationDeserializerHiveJsonSerDe {
    /**
     * A list of how you want Kinesis Data Firehose to parse the date and time stamps that may be present in your input data JSON. To specify these format strings, follow the pattern syntax of JodaTime's DateTimeFormat format strings. For more information, see [Class DateTimeFormat](https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html). You can also use the special value millis to parse time stamps in epoch milliseconds. If you don't specify a format, Kinesis Data Firehose uses java.sql.Timestamp::valueOf by default.
     */
    timestampFormats?: string[];
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationInputFormatConfigurationDeserializerOpenXJsonSerDe {
    /**
     * When set to true, which is the default, Kinesis Data Firehose converts JSON keys to lowercase before deserializing them.
     */
    caseInsensitive?: boolean;
    /**
     * A map of column names to JSON keys that aren't identical to the column names. This is useful when the JSON contains keys that are Hive keywords. For example, timestamp is a Hive keyword. If you have a JSON key named timestamp, set this parameter to `{ ts = "timestamp" }` to map this key to a column named ts.
     */
    columnToJsonKeyMappings?: {[key: string]: string};
    /**
     * When set to `true`, specifies that the names of the keys include dots and that you want Kinesis Data Firehose to replace them with underscores. This is useful because Apache Hive does not allow dots in column names. For example, if the JSON contains a key whose name is "a.b", you can define the column name to be "aB" when using this option. Defaults to `false`.
     */
    convertDotsInJsonKeysToUnderscores?: boolean;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfiguration {
    /**
     * Nested argument that specifies which serializer to use. You can choose either the ORC SerDe or the Parquet SerDe. More details below.
     */
    serializer: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializer;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializer {
    /**
     * Nested argument that specifies converting data to the ORC format before storing it in Amazon S3. For more information, see [Apache ORC](https://orc.apache.org/docs/). More details below.
     */
    orcSerDe?: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializerOrcSerDe;
    /**
     * Nested argument that specifies converting data to the Parquet format before storing it in Amazon S3. For more information, see [Apache Parquet](https://parquet.apache.org/documentation/latest/). More details below.
     */
    parquetSerDe?: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializerParquetSerDe;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializerOrcSerDe {
    /**
     * The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.
     */
    blockSizeBytes?: number;
    /**
     * A list of column names for which you want Kinesis Data Firehose to create bloom filters.
     */
    bloomFilterColumns?: string[];
    /**
     * The Bloom filter false positive probability (FPP). The lower the FPP, the bigger the Bloom filter. The default value is `0.05`, the minimum is `0`, and the maximum is `1`.
     */
    bloomFilterFalsePositiveProbability?: number;
    /**
     * The compression code to use over data blocks. The possible values are `UNCOMPRESSED`, `SNAPPY`, and `GZIP`, with the default being `SNAPPY`. Use `SNAPPY` for higher decompression speed. Use `GZIP` if the compression ratio is more important than speed.
     */
    compression?: string;
    /**
     * A float that represents the fraction of the total number of non-null rows. To turn off dictionary encoding, set this fraction to a number that is less than the number of distinct keys in a dictionary. To always use dictionary encoding, set this threshold to `1`.
     */
    dictionaryKeyThreshold?: number;
    /**
     * Set this to `true` to indicate that you want stripes to be padded to the HDFS block boundaries. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is `false`.
     */
    enablePadding?: boolean;
    /**
     * The version of the file to write. The possible values are `V0_11` and `V0_12`. The default is `V0_12`.
     */
    formatVersion?: string;
    /**
     * A float between 0 and 1 that defines the tolerance for block padding as a decimal fraction of stripe size. The default value is `0.05`, which means 5 percent of stripe size. For the default values of 64 MiB ORC stripes and 256 MiB HDFS blocks, the default block padding tolerance of 5 percent reserves a maximum of 3.2 MiB for padding within the 256 MiB block. In such a case, if the available size within the block is more than 3.2 MiB, a new, smaller stripe is inserted to fit within that space. This ensures that no stripe crosses block boundaries and causes remote reads within a node-local task. Kinesis Data Firehose ignores this parameter when `enablePadding` is `false`.
     */
    paddingTolerance?: number;
    /**
     * The number of rows between index entries. The default is `10000` and the minimum is `1000`.
     */
    rowIndexStride?: number;
    /**
     * The number of bytes in each stripe. The default is 64 MiB and the minimum is 8 MiB.
     */
    stripeSizeBytes?: number;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationOutputFormatConfigurationSerializerParquetSerDe {
    /**
     * The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.
     */
    blockSizeBytes?: number;
    /**
     * The compression code to use over data blocks. The possible values are `UNCOMPRESSED`, `SNAPPY`, and `GZIP`, with the default being `SNAPPY`. Use `SNAPPY` for higher decompression speed. Use `GZIP` if the compression ratio is more important than speed.
     */
    compression?: string;
    /**
     * Indicates whether to enable dictionary compression.
     */
    enableDictionaryCompression?: boolean;
    /**
     * The maximum amount of padding to apply. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is `0`.
     */
    maxPaddingBytes?: number;
    /**
     * The Parquet page size. Column chunks are divided into pages. A page is conceptually an indivisible unit (in terms of compression and encoding). The minimum value is 64 KiB and the default is 1 MiB.
     */
    pageSizeBytes?: number;
    /**
     * Indicates the version of row format to output. The possible values are `V1` and `V2`. The default is `V1`.
     */
    writerVersion?: string;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationDataFormatConversionConfigurationSchemaConfiguration {
    /**
     * The ID of the AWS Glue Data Catalog. If you don't supply this, the AWS account ID is used by default.
     */
    catalogId: string;
    /**
     * Specifies the name of the AWS Glue database that contains the schema for the output data.
     */
    databaseName: string;
    /**
     * If you don't specify an AWS Region, the default is the current region.
     */
    region: string;
    /**
     * The role that Kinesis Data Firehose can use to access AWS Glue. This role must be in the same account you use for Kinesis Data Firehose. Cross-account roles aren't allowed.
     */
    roleArn: string;
    /**
     * Specifies the AWS Glue table that contains the column information that constitutes your data schema.
     */
    tableName: string;
    /**
     * Specifies the table version for the output data schema. Defaults to `LATEST`.
     */
    versionId?: string;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationDynamicPartitioningConfiguration {
    /**
     * Enables or disables [dynamic partitioning](https://docs.aws.amazon.com/firehose/latest/dev/dynamic-partitioning.html). Defaults to `false`.
     */
    enabled?: boolean;
    /**
     * Total amount of seconds Firehose spends on retries. Valid values between 0 and 7200. Default is 300.
     */
    retryDuration?: number;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationProcessingConfiguration {
    /**
     * Enables or disables data processing.
     */
    enabled?: boolean;
    /**
     * Array of data processors. More details are given below
     */
    processors?: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationProcessingConfigurationProcessor[];
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationProcessingConfigurationProcessor {
    /**
     * Array of processor parameters. More details are given below
     */
    parameters?: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationProcessingConfigurationProcessorParameter[];
    /**
     * The type of processor. Valid Values: `RecordDeAggregation`, `Lambda`, `MetadataExtraction`, `AppendDelimiterToRecord`. Validation is done against [AWS SDK constants](https://docs.aws.amazon.com/sdk-for-go/api/service/firehose/#pkg-constants); so that values not explicitly listed may also work.
     */
    type: string;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationProcessingConfigurationProcessorParameter {
    /**
     * Parameter name. Valid Values: `LambdaArn`, `NumberOfRetries`, `MetadataExtractionQuery`, `JsonParsingEngine`, `RoleArn`, `BufferSizeInMBs`, `BufferIntervalInSeconds`, `SubRecordType`, `Delimiter`. Validation is done against [AWS SDK constants](https://docs.aws.amazon.com/sdk-for-go/api/service/firehose/#pkg-constants); so that values not explicitly listed may also work.
     */
    parameterName: string;
    /**
     * Parameter value. Must be between 1 and 512 length (inclusive). When providing a Lambda ARN, you should specify the resource version as well.
     */
    parameterValue: string;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationS3BackupConfiguration {
    /**
     * The ARN of the S3 bucket
     */
    bucketArn: string;
    /**
     * Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300.
     */
    bufferInterval?: number;
    /**
     * Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5.
     * We recommend setting SizeInMBs to a value greater than the amount of data you typically ingest into the delivery stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec set SizeInMBs to be 10 MB or higher.
     */
    bufferSize?: number;
    /**
     * The CloudWatch Logging Options for the delivery stream. More details are given below
     */
    cloudwatchLoggingOptions: outputs.kinesis.FirehoseDeliveryStreamExtendedS3ConfigurationS3BackupConfigurationCloudwatchLoggingOptions;
    /**
     * The compression format. If no value is specified, the default is `UNCOMPRESSED`. Other supported values are `GZIP`, `ZIP`, `Snappy`, & `HADOOP_SNAPPY`.
     */
    compressionFormat?: string;
    /**
     * Prefix added to failed records before writing them to S3. Not currently supported for `redshift` destination. This prefix appears immediately following the bucket name. For information about how to specify this prefix, see [Custom Prefixes for Amazon S3 Objects](https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
     */
    errorOutputPrefix?: string;
    /**
     * Specifies the KMS key ARN the stream will use to encrypt data. If not set, no encryption will
     * be used.
     */
    kmsKeyArn?: string;
    /**
     * The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket
     */
    prefix?: string;
    /**
     * The role that Kinesis Data Firehose can use to access AWS Glue. This role must be in the same account you use for Kinesis Data Firehose. Cross-account roles aren't allowed.
     */
    roleArn: string;
}

export interface FirehoseDeliveryStreamExtendedS3ConfigurationS3BackupConfigurationCloudwatchLoggingOptions {
    /**
     * Enables or disables the logging. Defaults to `false`.
     */
    enabled?: boolean;
    /**
     * The CloudWatch group name for logging. This value is required if `enabled` is true.
     */
    logGroupName?: string;
    /**
     * The CloudWatch log stream name for logging. This value is required if `enabled` is true.
     */
    logStreamName?: string;
}

export interface FirehoseDeliveryStreamHttpEndpointConfiguration {
    /**
     * The access key required for Kinesis Firehose to authenticate with the HTTP endpoint selected as the destination.
     */
    accessKey?: string;
    /**
     * Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300 (5 minutes).
     */
    bufferingInterval?: number;
    /**
     * Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5.
     */
    bufferingSize?: number;
    /**
     * The CloudWatch Logging Options for the delivery stream. More details are given below.
     */
    cloudwatchLoggingOptions: outputs.kinesis.FirehoseDeliveryStreamHttpEndpointConfigurationCloudwatchLoggingOptions;
    /**
     * The HTTP endpoint name.
     */
    name?: string;
    /**
     * The data processing configuration.  More details are given below.
     */
    processingConfiguration?: outputs.kinesis.FirehoseDeliveryStreamHttpEndpointConfigurationProcessingConfiguration;
    /**
     * The request configuration.  More details are given below.
     */
    requestConfiguration: outputs.kinesis.FirehoseDeliveryStreamHttpEndpointConfigurationRequestConfiguration;
    /**
     * Total amount of seconds Firehose spends on retries. This duration starts after the initial attempt fails, It does not include the time periods during which Firehose waits for acknowledgment from the specified destination after each attempt. Valid values between `0` and `7200`. Default is `300`.
     */
    retryDuration?: number;
    /**
     * Kinesis Data Firehose uses this IAM role for all the permissions that the delivery stream needs. The pattern needs to be `arn:.*`.
     */
    roleArn?: string;
    /**
     * Defines how documents should be delivered to Amazon S3.  Valid values are `FailedDataOnly` and `AllData`.  Default value is `FailedDataOnly`.
     */
    s3BackupMode?: string;
    /**
     * The HTTP endpoint URL to which Kinesis Firehose sends your data.
     */
    url: string;
}

export interface FirehoseDeliveryStreamHttpEndpointConfigurationCloudwatchLoggingOptions {
    /**
     * Enables or disables the logging. Defaults to `false`.
     */
    enabled?: boolean;
    /**
     * The CloudWatch group name for logging. This value is required if `enabled` is true.
     */
    logGroupName?: string;
    /**
     * The CloudWatch log stream name for logging. This value is required if `enabled` is true.
     */
    logStreamName?: string;
}

export interface FirehoseDeliveryStreamHttpEndpointConfigurationProcessingConfiguration {
    /**
     * Enables or disables data processing.
     */
    enabled?: boolean;
    /**
     * Array of data processors. More details are given below
     */
    processors?: outputs.kinesis.FirehoseDeliveryStreamHttpEndpointConfigurationProcessingConfigurationProcessor[];
}

export interface FirehoseDeliveryStreamHttpEndpointConfigurationProcessingConfigurationProcessor {
    /**
     * Array of processor parameters. More details are given below
     */
    parameters?: outputs.kinesis.FirehoseDeliveryStreamHttpEndpointConfigurationProcessingConfigurationProcessorParameter[];
    /**
     * The type of processor. Valid Values: `RecordDeAggregation`, `Lambda`, `MetadataExtraction`, `AppendDelimiterToRecord`. Validation is done against [AWS SDK constants](https://docs.aws.amazon.com/sdk-for-go/api/service/firehose/#pkg-constants); so that values not explicitly listed may also work.
     */
    type: string;
}

export interface FirehoseDeliveryStreamHttpEndpointConfigurationProcessingConfigurationProcessorParameter {
    /**
     * Parameter name. Valid Values: `LambdaArn`, `NumberOfRetries`, `MetadataExtractionQuery`, `JsonParsingEngine`, `RoleArn`, `BufferSizeInMBs`, `BufferIntervalInSeconds`, `SubRecordType`, `Delimiter`. Validation is done against [AWS SDK constants](https://docs.aws.amazon.com/sdk-for-go/api/service/firehose/#pkg-constants); so that values not explicitly listed may also work.
     */
    parameterName: string;
    /**
     * Parameter value. Must be between 1 and 512 length (inclusive). When providing a Lambda ARN, you should specify the resource version as well.
     */
    parameterValue: string;
}

export interface FirehoseDeliveryStreamHttpEndpointConfigurationRequestConfiguration {
    /**
     * Describes the metadata sent to the HTTP endpoint destination. More details are given below
     */
    commonAttributes?: outputs.kinesis.FirehoseDeliveryStreamHttpEndpointConfigurationRequestConfigurationCommonAttribute[];
    /**
     * Kinesis Data Firehose uses the content encoding to compress the body of a request before sending the request to the destination. Valid values are `NONE` and `GZIP`.  Default value is `NONE`.
     */
    contentEncoding?: string;
}

export interface FirehoseDeliveryStreamHttpEndpointConfigurationRequestConfigurationCommonAttribute {
    /**
     * The name of the HTTP endpoint common attribute.
     */
    name: string;
    /**
     * The value of the HTTP endpoint common attribute.
     */
    value: string;
}

export interface FirehoseDeliveryStreamKinesisSourceConfiguration {
    /**
     * The kinesis stream used as the source of the firehose delivery stream.
     */
    kinesisStreamArn: string;
    /**
     * The ARN of the role that provides access to the source Kinesis stream.
     */
    roleArn: string;
}

export interface FirehoseDeliveryStreamRedshiftConfiguration {
    /**
     * The CloudWatch Logging Options for the delivery stream. More details are given below
     */
    cloudwatchLoggingOptions: outputs.kinesis.FirehoseDeliveryStreamRedshiftConfigurationCloudwatchLoggingOptions;
    /**
     * The jdbcurl of the redshift cluster.
     */
    clusterJdbcurl: string;
    /**
     * Copy options for copying the data from the s3 intermediate bucket into redshift, for example to change the default delimiter. For valid values, see the [AWS documentation](http://docs.aws.amazon.com/firehose/latest/APIReference/API_CopyCommand.html)
     */
    copyOptions?: string;
    /**
     * The data table columns that will be targeted by the copy command.
     */
    dataTableColumns?: string;
    /**
     * The name of the table in the redshift cluster that the s3 bucket will copy to.
     */
    dataTableName: string;
    /**
     * The password for the username above.
     */
    password: string;
    /**
     * The data processing configuration.  More details are given below.
     */
    processingConfiguration?: outputs.kinesis.FirehoseDeliveryStreamRedshiftConfigurationProcessingConfiguration;
    /**
     * The length of time during which Firehose retries delivery after a failure, starting from the initial request and including the first attempt. The default value is 3600 seconds (60 minutes). Firehose does not retry if the value of DurationInSeconds is 0 (zero) or if the first delivery attempt takes longer than the current value.
     */
    retryDuration?: number;
    /**
     * The arn of the role the stream assumes.
     */
    roleArn: string;
    /**
     * The configuration for backup in Amazon S3. Required if `s3BackupMode` is `Enabled`. Supports the same fields as `s3Configuration` object.
     */
    s3BackupConfiguration?: outputs.kinesis.FirehoseDeliveryStreamRedshiftConfigurationS3BackupConfiguration;
    /**
     * The Amazon S3 backup mode.  Valid values are `Disabled` and `Enabled`.  Default value is `Disabled`.
     */
    s3BackupMode?: string;
    /**
     * The username that the firehose delivery stream will assume. It is strongly recommended that the username and password provided is used exclusively for Amazon Kinesis Firehose purposes, and that the permissions for the account are restricted for Amazon Redshift INSERT permissions.
     */
    username: string;
}

export interface FirehoseDeliveryStreamRedshiftConfigurationCloudwatchLoggingOptions {
    /**
     * Enables or disables the logging. Defaults to `false`.
     */
    enabled?: boolean;
    /**
     * The CloudWatch group name for logging. This value is required if `enabled` is true.
     */
    logGroupName?: string;
    /**
     * The CloudWatch log stream name for logging. This value is required if `enabled` is true.
     */
    logStreamName?: string;
}

export interface FirehoseDeliveryStreamRedshiftConfigurationProcessingConfiguration {
    /**
     * Enables or disables data processing.
     */
    enabled?: boolean;
    /**
     * Array of data processors. More details are given below
     */
    processors?: outputs.kinesis.FirehoseDeliveryStreamRedshiftConfigurationProcessingConfigurationProcessor[];
}

export interface FirehoseDeliveryStreamRedshiftConfigurationProcessingConfigurationProcessor {
    /**
     * Array of processor parameters. More details are given below
     */
    parameters?: outputs.kinesis.FirehoseDeliveryStreamRedshiftConfigurationProcessingConfigurationProcessorParameter[];
    /**
     * The type of processor. Valid Values: `RecordDeAggregation`, `Lambda`, `MetadataExtraction`, `AppendDelimiterToRecord`. Validation is done against [AWS SDK constants](https://docs.aws.amazon.com/sdk-for-go/api/service/firehose/#pkg-constants); so that values not explicitly listed may also work.
     */
    type: string;
}

export interface FirehoseDeliveryStreamRedshiftConfigurationProcessingConfigurationProcessorParameter {
    /**
     * Parameter name. Valid Values: `LambdaArn`, `NumberOfRetries`, `MetadataExtractionQuery`, `JsonParsingEngine`, `RoleArn`, `BufferSizeInMBs`, `BufferIntervalInSeconds`, `SubRecordType`, `Delimiter`. Validation is done against [AWS SDK constants](https://docs.aws.amazon.com/sdk-for-go/api/service/firehose/#pkg-constants); so that values not explicitly listed may also work.
     */
    parameterName: string;
    /**
     * Parameter value. Must be between 1 and 512 length (inclusive). When providing a Lambda ARN, you should specify the resource version as well.
     */
    parameterValue: string;
}

export interface FirehoseDeliveryStreamRedshiftConfigurationS3BackupConfiguration {
    /**
     * The ARN of the S3 bucket
     */
    bucketArn: string;
    /**
     * Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300.
     */
    bufferInterval?: number;
    /**
     * Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5.
     * We recommend setting SizeInMBs to a value greater than the amount of data you typically ingest into the delivery stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec set SizeInMBs to be 10 MB or higher.
     */
    bufferSize?: number;
    /**
     * The CloudWatch Logging Options for the delivery stream. More details are given below
     */
    cloudwatchLoggingOptions: outputs.kinesis.FirehoseDeliveryStreamRedshiftConfigurationS3BackupConfigurationCloudwatchLoggingOptions;
    /**
     * The compression format. If no value is specified, the default is `UNCOMPRESSED`. Other supported values are `GZIP`, `ZIP`, `Snappy`, & `HADOOP_SNAPPY`.
     */
    compressionFormat?: string;
    /**
     * Prefix added to failed records before writing them to S3. Not currently supported for `redshift` destination. This prefix appears immediately following the bucket name. For information about how to specify this prefix, see [Custom Prefixes for Amazon S3 Objects](https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
     */
    errorOutputPrefix?: string;
    /**
     * Specifies the KMS key ARN the stream will use to encrypt data. If not set, no encryption will
     * be used.
     */
    kmsKeyArn?: string;
    /**
     * The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket
     */
    prefix?: string;
    /**
     * The role that Kinesis Data Firehose can use to access AWS Glue. This role must be in the same account you use for Kinesis Data Firehose. Cross-account roles aren't allowed.
     */
    roleArn: string;
}

export interface FirehoseDeliveryStreamRedshiftConfigurationS3BackupConfigurationCloudwatchLoggingOptions {
    /**
     * Enables or disables the logging. Defaults to `false`.
     */
    enabled?: boolean;
    /**
     * The CloudWatch group name for logging. This value is required if `enabled` is true.
     */
    logGroupName?: string;
    /**
     * The CloudWatch log stream name for logging. This value is required if `enabled` is true.
     */
    logStreamName?: string;
}

export interface FirehoseDeliveryStreamS3Configuration {
    /**
     * The ARN of the S3 bucket
     */
    bucketArn: string;
    /**
     * Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300.
     */
    bufferInterval?: number;
    /**
     * Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5.
     * We recommend setting SizeInMBs to a value greater than the amount of data you typically ingest into the delivery stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec set SizeInMBs to be 10 MB or higher.
     */
    bufferSize?: number;
    /**
     * The CloudWatch Logging Options for the delivery stream. More details are given below
     */
    cloudwatchLoggingOptions: outputs.kinesis.FirehoseDeliveryStreamS3ConfigurationCloudwatchLoggingOptions;
    /**
     * The compression format. If no value is specified, the default is `UNCOMPRESSED`. Other supported values are `GZIP`, `ZIP`, `Snappy`, & `HADOOP_SNAPPY`.
     */
    compressionFormat?: string;
    /**
     * Prefix added to failed records before writing them to S3. Not currently supported for `redshift` destination. This prefix appears immediately following the bucket name. For information about how to specify this prefix, see [Custom Prefixes for Amazon S3 Objects](https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
     */
    errorOutputPrefix?: string;
    /**
     * Specifies the KMS key ARN the stream will use to encrypt data. If not set, no encryption will
     * be used.
     */
    kmsKeyArn?: string;
    /**
     * The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket
     */
    prefix?: string;
    /**
     * The role that Kinesis Data Firehose can use to access AWS Glue. This role must be in the same account you use for Kinesis Data Firehose. Cross-account roles aren't allowed.
     */
    roleArn: string;
}

export interface FirehoseDeliveryStreamS3ConfigurationCloudwatchLoggingOptions {
    /**
     * Enables or disables the logging. Defaults to `false`.
     */
    enabled?: boolean;
    /**
     * The CloudWatch group name for logging. This value is required if `enabled` is true.
     */
    logGroupName?: string;
    /**
     * The CloudWatch log stream name for logging. This value is required if `enabled` is true.
     */
    logStreamName?: string;
}

export interface FirehoseDeliveryStreamServerSideEncryption {
    /**
     * Whether to enable encryption at rest. Default is `false`.
     */
    enabled?: boolean;
    /**
     * Amazon Resource Name (ARN) of the encryption key. Required when `keyType` is `CUSTOMER_MANAGED_CMK`.
     */
    keyArn?: string;
    /**
     * Type of encryption key. Default is `AWS_OWNED_CMK`. Valid values are `AWS_OWNED_CMK` and `CUSTOMER_MANAGED_CMK`
     */
    keyType?: string;
}

export interface FirehoseDeliveryStreamSplunkConfiguration {
    /**
     * The CloudWatch Logging Options for the delivery stream. More details are given below.
     */
    cloudwatchLoggingOptions: outputs.kinesis.FirehoseDeliveryStreamSplunkConfigurationCloudwatchLoggingOptions;
    /**
     * The amount of time, in seconds between 180 and 600, that Kinesis Firehose waits to receive an acknowledgment from Splunk after it sends it data.
     */
    hecAcknowledgmentTimeout?: number;
    /**
     * The HTTP Event Collector (HEC) endpoint to which Kinesis Firehose sends your data.
     */
    hecEndpoint: string;
    /**
     * The HEC endpoint type. Valid values are `Raw` or `Event`. The default value is `Raw`.
     */
    hecEndpointType?: string;
    /**
     * The GUID that you obtain from your Splunk cluster when you create a new HEC endpoint.
     */
    hecToken: string;
    /**
     * The data processing configuration.  More details are given below.
     */
    processingConfiguration?: outputs.kinesis.FirehoseDeliveryStreamSplunkConfigurationProcessingConfiguration;
    /**
     * After an initial failure to deliver to Splunk, the total amount of time, in seconds between 0 to 7200, during which Firehose re-attempts delivery (including the first attempt).  After this time has elapsed, the failed documents are written to Amazon S3.  The default value is 300s.  There will be no retry if the value is 0.
     */
    retryDuration?: number;
    /**
     * Defines how documents should be delivered to Amazon S3.  Valid values are `FailedEventsOnly` and `AllEvents`.  Default value is `FailedEventsOnly`.
     */
    s3BackupMode?: string;
}

export interface FirehoseDeliveryStreamSplunkConfigurationCloudwatchLoggingOptions {
    /**
     * Enables or disables the logging. Defaults to `false`.
     */
    enabled?: boolean;
    /**
     * The CloudWatch group name for logging. This value is required if `enabled` is true.
     */
    logGroupName?: string;
    /**
     * The CloudWatch log stream name for logging. This value is required if `enabled` is true.
     */
    logStreamName?: string;
}

export interface FirehoseDeliveryStreamSplunkConfigurationProcessingConfiguration {
    /**
     * Enables or disables data processing.
     */
    enabled?: boolean;
    /**
     * Array of data processors. More details are given below
     */
    processors?: outputs.kinesis.FirehoseDeliveryStreamSplunkConfigurationProcessingConfigurationProcessor[];
}

export interface FirehoseDeliveryStreamSplunkConfigurationProcessingConfigurationProcessor {
    /**
     * Array of processor parameters. More details are given below
     */
    parameters?: outputs.kinesis.FirehoseDeliveryStreamSplunkConfigurationProcessingConfigurationProcessorParameter[];
    /**
     * The type of processor. Valid Values: `RecordDeAggregation`, `Lambda`, `MetadataExtraction`, `AppendDelimiterToRecord`. Validation is done against [AWS SDK constants](https://docs.aws.amazon.com/sdk-for-go/api/service/firehose/#pkg-constants); so that values not explicitly listed may also work.
     */
    type: string;
}

export interface FirehoseDeliveryStreamSplunkConfigurationProcessingConfigurationProcessorParameter {
    /**
     * Parameter name. Valid Values: `LambdaArn`, `NumberOfRetries`, `MetadataExtractionQuery`, `JsonParsingEngine`, `RoleArn`, `BufferSizeInMBs`, `BufferIntervalInSeconds`, `SubRecordType`, `Delimiter`. Validation is done against [AWS SDK constants](https://docs.aws.amazon.com/sdk-for-go/api/service/firehose/#pkg-constants); so that values not explicitly listed may also work.
     */
    parameterName: string;
    /**
     * Parameter value. Must be between 1 and 512 length (inclusive). When providing a Lambda ARN, you should specify the resource version as well.
     */
    parameterValue: string;
}

export interface GetStreamStreamModeDetail {
    /**
     * Capacity mode of the stream. Either `ON_DEMAND` or `PROVISIONED`.
     */
    streamMode: string;
}

export interface StreamStreamModeDetails {
    /**
     * Specifies the capacity mode of the stream. Must be either `PROVISIONED` or `ON_DEMAND`.
     */
    streamMode: string;
}

