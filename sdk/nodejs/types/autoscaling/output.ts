// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../../types/input";
import * as outputs from "../../types/output";
import * as enums from "../../types/enums";
import * as utilities from "../../utilities";

import {RoutingRule} from "@/s3";

export interface GetAmiIdsFilter {
    /**
     * Name of the DescribeAutoScalingGroup filter. The recommended values are: `tag-key`, `tag-value`, and `tag:<tag name>`
     */
    name: string;
    /**
     * Value of the filter.
     */
    values: string[];
}

export interface GetGroupLaunchTemplate {
    /**
     * Name of the Auto Scaling Group.
     */
    id: string;
    /**
     * Specify the exact name of the desired autoscaling group.
     */
    name: string;
    version: string;
}

export interface GroupInitialLifecycleHook {
    defaultResult: string;
    heartbeatTimeout?: number;
    lifecycleTransition: string;
    /**
     * Name of the Auto Scaling Group. By default generated by the provider. Conflicts with `namePrefix`.
     */
    name: string;
    notificationMetadata?: string;
    notificationTargetArn?: string;
    roleArn?: string;
}

export interface GroupInstanceRefresh {
    /**
     * Override default parameters for Instance Refresh.
     */
    preferences?: outputs.autoscaling.GroupInstanceRefreshPreferences;
    /**
     * Strategy to use for instance refresh. The only allowed value is `Rolling`. See [StartInstanceRefresh Action](https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_StartInstanceRefresh.html#API_StartInstanceRefresh_RequestParameters) for more information.
     */
    strategy: string;
    /**
     * Set of additional property names that will trigger an Instance Refresh. A refresh will always be triggered by a change in any of `launchConfiguration`, `launchTemplate`, or `mixedInstancesPolicy`.
     */
    triggers?: string[];
}

export interface GroupInstanceRefreshPreferences {
    /**
     * Number of seconds to wait after a checkpoint. Defaults to `3600`.
     */
    checkpointDelay?: string;
    /**
     * List of percentages for each checkpoint. Values must be unique and in ascending order. To replace all instances, the final number must be `100`.
     */
    checkpointPercentages?: number[];
    /**
     * Number of seconds until a newly launched instance is configured and ready to use. Default behavior is to use the Auto Scaling Group's health check grace period.
     */
    instanceWarmup?: string;
    /**
     * Amount of capacity in the Auto Scaling group that must remain healthy during an instance refresh to allow the operation to continue, as a percentage of the desired capacity of the Auto Scaling group. Defaults to `90`.
     */
    minHealthyPercentage?: number;
    /**
     * Replace instances that already have your desired configuration. Defaults to `false`.
     */
    skipMatching?: boolean;
}

export interface GroupLaunchTemplate {
    /**
     * ID of the launch template. Conflicts with `name`.
     */
    id: string;
    /**
     * Name of the Auto Scaling Group. By default generated by the provider. Conflicts with `namePrefix`.
     */
    name: string;
    /**
     * Template version. Can be version number, `$Latest`, or `$Default`. (Default: `$Default`).
     */
    version?: string;
}

export interface GroupMixedInstancesPolicy {
    /**
     * Nested argument containing settings on how to mix on-demand and Spot instances in the Auto Scaling group. Defined below.
     */
    instancesDistribution: outputs.autoscaling.GroupMixedInstancesPolicyInstancesDistribution;
    /**
     * Nested argument containing launch template settings along with the overrides to specify multiple instance types and weights. Defined below.
     */
    launchTemplate: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplate;
}

export interface GroupMixedInstancesPolicyInstancesDistribution {
    /**
     * Strategy to use when launching on-demand instances. Valid values: `prioritized`. Default: `prioritized`.
     */
    onDemandAllocationStrategy: string;
    /**
     * Absolute minimum amount of desired capacity that must be fulfilled by on-demand instances. Default: `0`.
     */
    onDemandBaseCapacity: number;
    /**
     * Percentage split between on-demand and Spot instances above the base on-demand capacity. Default: `100`.
     */
    onDemandPercentageAboveBaseCapacity: number;
    /**
     * How to allocate capacity across the Spot pools. Valid values: `lowest-price`, `capacity-optimized`, `capacity-optimized-prioritized`, and `price-capacity-optimized`. Default: `lowest-price`.
     */
    spotAllocationStrategy: string;
    /**
     * Number of Spot pools per availability zone to allocate capacity. EC2 Auto Scaling selects the cheapest Spot pools and evenly allocates Spot capacity across the number of Spot pools that you specify. Only available with `spotAllocationStrategy` set to `lowest-price`. Otherwise it must be set to `0`, if it has been defined before. Default: `2`.
     */
    spotInstancePools: number;
    /**
     * Maximum price per unit hour that the user is willing to pay for the Spot instances. Default: an empty string which means the on-demand price.
     */
    spotMaxPrice?: string;
}

export interface GroupMixedInstancesPolicyLaunchTemplate {
    /**
     * Override the instance launch template specification in the Launch Template.
     */
    launchTemplateSpecification: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateLaunchTemplateSpecification;
    /**
     * List of nested arguments provides the ability to specify multiple instance types. This will override the same parameter in the launch template. For on-demand instances, Auto Scaling considers the order of preference of instance types to launch based on the order specified in the overrides list. Defined below.
     */
    overrides?: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateOverride[];
}

export interface GroupMixedInstancesPolicyLaunchTemplateLaunchTemplateSpecification {
    /**
     * ID of the launch template. Conflicts with `launchTemplateName`.
     */
    launchTemplateId: string;
    /**
     * Name of the launch template. Conflicts with `launchTemplateId`.
     */
    launchTemplateName: string;
    /**
     * Template version. Can be version number, `$Latest`, or `$Default`. (Default: `$Default`).
     */
    version?: string;
}

export interface GroupMixedInstancesPolicyLaunchTemplateOverride {
    /**
     * Override the instance type in the Launch Template with instance types that satisfy the requirements.
     */
    instanceRequirements?: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirements;
    /**
     * Override the instance type in the Launch Template.
     */
    instanceType?: string;
    /**
     * Override the instance launch template specification in the Launch Template.
     */
    launchTemplateSpecification?: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateOverrideLaunchTemplateSpecification;
    /**
     * Number of capacity units, which gives the instance type a proportional weight to other instance types.
     */
    weightedCapacity?: string;
}

export interface GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirements {
    /**
     * Block describing the minimum and maximum number of accelerators (GPUs, FPGAs, or AWS Inferentia chips). Default is no minimum or maximum.
     */
    acceleratorCount?: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsAcceleratorCount;
    /**
     * List of accelerator manufacturer names. Default is any manufacturer.
     */
    acceleratorManufacturers?: string[];
    /**
     * List of accelerator names. Default is any acclerator.
     */
    acceleratorNames?: string[];
    /**
     * Block describing the minimum and maximum total memory of the accelerators. Default is no minimum or maximum.
     */
    acceleratorTotalMemoryMib?: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsAcceleratorTotalMemoryMib;
    /**
     * List of accelerator types. Default is any accelerator type.
     */
    acceleratorTypes?: string[];
    /**
     * Indicate whether bare metal instace types should be `included`, `excluded`, or `required`. Default is `excluded`.
     */
    bareMetal?: string;
    /**
     * Block describing the minimum and maximum baseline EBS bandwidth, in Mbps. Default is no minimum or maximum.
     */
    baselineEbsBandwidthMbps?: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsBaselineEbsBandwidthMbps;
    /**
     * Indicate whether burstable performance instance types should be `included`, `excluded`, or `required`. Default is `excluded`.
     */
    burstablePerformance?: string;
    /**
     * List of CPU manufacturer names. Default is any manufacturer.
     */
    cpuManufacturers?: string[];
    /**
     * List of instance types to exclude. You can use strings with one or more wild cards, represented by an asterisk (\*). The following are examples: `c5*`, `m5a.*`, `r*`, `*3*`. For example, if you specify `c5*`, you are excluding the entire C5 instance family, which includes all C5a and C5n instance types. If you specify `m5a.*`, you are excluding all the M5a instance types, but not the M5n instance types. Maximum of 400 entries in the list; each entry is limited to 30 characters. Default is no excluded instance types.
     */
    excludedInstanceTypes?: string[];
    /**
     * List of instance generation names. Default is any generation.
     */
    instanceGenerations?: string[];
    /**
     * Indicate whether instance types with local storage volumes are `included`, `excluded`, or `required`. Default is `included`.
     */
    localStorage?: string;
    /**
     * List of local storage type names. Default any storage type.
     */
    localStorageTypes?: string[];
    /**
     * Block describing the minimum and maximum amount of memory (GiB) per vCPU. Default is no minimum or maximum.
     */
    memoryGibPerVcpu?: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsMemoryGibPerVcpu;
    /**
     * Block describing the minimum and maximum amount of memory (MiB). Default is no maximum.
     */
    memoryMib?: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsMemoryMib;
    /**
     * Block describing the minimum and maximum number of network interfaces. Default is no minimum or maximum.
     */
    networkInterfaceCount?: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsNetworkInterfaceCount;
    /**
     * Price protection threshold for On-Demand Instances. This is the maximum you’ll pay for an On-Demand Instance, expressed as a percentage higher than the cheapest M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as 999999. Default is 20.
     */
    onDemandMaxPricePercentageOverLowestPrice?: number;
    /**
     * Indicate whether instance types must support On-Demand Instance Hibernation, either `true` or `false`. Default is `false`.
     */
    requireHibernateSupport?: boolean;
    /**
     * Price protection threshold for Spot Instances. This is the maximum you’ll pay for a Spot Instance, expressed as a percentage higher than the cheapest M, C, or R instance type with your specified attributes. When Amazon EC2 Auto Scaling selects instance types with your attributes, we will exclude instance types whose price is higher than your threshold. The parameter accepts an integer, which Amazon EC2 Auto Scaling interprets as a percentage. To turn off price protection, specify a high value, such as 999999. Default is 100.
     */
    spotMaxPricePercentageOverLowestPrice?: number;
    /**
     * Block describing the minimum and maximum total local storage (GB). Default is no minimum or maximum.
     */
    totalLocalStorageGb?: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsTotalLocalStorageGb;
    /**
     * Block describing the minimum and maximum number of vCPUs. Default is no maximum.
     */
    vcpuCount?: outputs.autoscaling.GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsVcpuCount;
}

export interface GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsAcceleratorCount {
    /**
     * Maximum.
     */
    max?: number;
    /**
     * Minimum.
     */
    min?: number;
}

export interface GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsAcceleratorTotalMemoryMib {
    /**
     * Maximum.
     */
    max?: number;
    /**
     * Minimum.
     */
    min?: number;
}

export interface GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsBaselineEbsBandwidthMbps {
    /**
     * Maximum.
     */
    max?: number;
    /**
     * Minimum.
     */
    min?: number;
}

export interface GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsMemoryGibPerVcpu {
    /**
     * Maximum.
     */
    max?: number;
    /**
     * Minimum.
     */
    min?: number;
}

export interface GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsMemoryMib {
    /**
     * Maximum.
     */
    max?: number;
    /**
     * Minimum.
     */
    min?: number;
}

export interface GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsNetworkInterfaceCount {
    /**
     * Maximum.
     */
    max?: number;
    /**
     * Minimum.
     */
    min?: number;
}

export interface GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsTotalLocalStorageGb {
    /**
     * Maximum.
     */
    max?: number;
    /**
     * Minimum.
     */
    min?: number;
}

export interface GroupMixedInstancesPolicyLaunchTemplateOverrideInstanceRequirementsVcpuCount {
    /**
     * Maximum.
     */
    max?: number;
    /**
     * Minimum.
     */
    min?: number;
}

export interface GroupMixedInstancesPolicyLaunchTemplateOverrideLaunchTemplateSpecification {
    /**
     * ID of the launch template. Conflicts with `launchTemplateName`.
     */
    launchTemplateId: string;
    /**
     * Name of the launch template. Conflicts with `launchTemplateId`.
     */
    launchTemplateName: string;
    /**
     * Template version. Can be version number, `$Latest`, or `$Default`. (Default: `$Default`).
     */
    version?: string;
}

export interface GroupTag {
    /**
     * Key
     */
    key: string;
    /**
     * Enables propagation of the tag to
     * Amazon EC2 instances launched via this ASG
     */
    propagateAtLaunch: boolean;
    /**
     * Value
     */
    value: string;
}

export interface GroupWarmPool {
    /**
     * Whether instances in the Auto Scaling group can be returned to the warm pool on scale in. The default is to terminate instances in the Auto Scaling group when the group scales in.
     */
    instanceReusePolicy?: outputs.autoscaling.GroupWarmPoolInstanceReusePolicy;
    /**
     * Total maximum number of instances that are allowed to be in the warm pool or in any state except Terminated for the Auto Scaling group.
     */
    maxGroupPreparedCapacity?: number;
    /**
     * Minimum number of instances to maintain in the warm pool. This helps you to ensure that there is always a certain number of warmed instances available to handle traffic spikes. Defaults to 0 if not specified.
     */
    minSize?: number;
    /**
     * Sets the instance state to transition to after the lifecycle hooks finish. Valid values are: Stopped (default), Running or Hibernated.
     */
    poolState?: string;
}

export interface GroupWarmPoolInstanceReusePolicy {
    /**
     * Whether instances in the Auto Scaling group can be returned to the warm pool on scale in.
     */
    reuseOnScaleIn?: boolean;
}

export interface PolicyPredictiveScalingConfiguration {
    /**
     * Defines the behavior that should be applied if the forecast capacity approaches or exceeds the maximum capacity of the Auto Scaling group. Valid values are `HonorMaxCapacity` or `IncreaseMaxCapacity`. Default is `HonorMaxCapacity`.
     */
    maxCapacityBreachBehavior?: string;
    /**
     * Size of the capacity buffer to use when the forecast capacity is close to or exceeds the maximum capacity. Valid range is `0` to `100`. If set to `0`, Amazon EC2 Auto Scaling may scale capacity higher than the maximum capacity to equal but not exceed forecast capacity.
     */
    maxCapacityBuffer?: string;
    /**
     * This structure includes the metrics and target utilization to use for predictive scaling.
     */
    metricSpecification: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecification;
    /**
     * Predictive scaling mode. Valid values are `ForecastAndScale` and `ForecastOnly`. Default is `ForecastOnly`.
     */
    mode?: string;
    /**
     * Amount of time, in seconds, by which the instance launch time can be advanced. Minimum is `0`.
     */
    schedulingBufferTime?: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecification {
    /**
     * Customized capacity metric specification. The field is only valid when you use `customizedLoadMetricSpecification`
     */
    customizedCapacityMetricSpecification?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedCapacityMetricSpecification;
    /**
     * Customized load metric specification.
     */
    customizedLoadMetricSpecification?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedLoadMetricSpecification;
    /**
     * Customized scaling metric specification.
     */
    customizedScalingMetricSpecification?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedScalingMetricSpecification;
    /**
     * Predefined load metric specification.
     */
    predefinedLoadMetricSpecification?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationPredefinedLoadMetricSpecification;
    /**
     * Metric pair specification from which Amazon EC2 Auto Scaling determines the appropriate scaling metric and load metric to use.
     */
    predefinedMetricPairSpecification?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationPredefinedMetricPairSpecification;
    /**
     * Predefined scaling metric specification.
     */
    predefinedScalingMetricSpecification?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationPredefinedScalingMetricSpecification;
    /**
     * Target value for the metric.
     */
    targetValue: number;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedCapacityMetricSpecification {
    /**
     * List of up to 10 structures that defines custom capacity metric in predictive scaling policy
     */
    metricDataQueries: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedCapacityMetricSpecificationMetricDataQuery[];
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedCapacityMetricSpecificationMetricDataQuery {
    /**
     * Math expression used on the returned metric. You must specify either `expression` or `metricStat`, but not both.
     */
    expression?: string;
    /**
     * Short name for the metric used in predictive scaling policy.
     */
    id: string;
    /**
     * Human-readable label for this metric or expression.
     */
    label?: string;
    /**
     * Structure that defines CloudWatch metric to be used in predictive scaling policy. You must specify either `expression` or `metricStat`, but not both.
     */
    metricStat?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedCapacityMetricSpecificationMetricDataQueryMetricStat;
    /**
     * Boolean that indicates whether to return the timestamps and raw data values of this metric, the default it true
     */
    returnData?: boolean;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedCapacityMetricSpecificationMetricDataQueryMetricStat {
    /**
     * Structure that defines the CloudWatch metric to return, including the metric name, namespace, and dimensions.
     */
    metric: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedCapacityMetricSpecificationMetricDataQueryMetricStatMetric;
    /**
     * Statistic of the metrics to return.
     */
    stat: string;
    /**
     * Unit of the metrics to return.
     */
    unit?: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedCapacityMetricSpecificationMetricDataQueryMetricStatMetric {
    /**
     * Dimensions of the metric.
     */
    dimensions?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedCapacityMetricSpecificationMetricDataQueryMetricStatMetricDimension[];
    /**
     * Name of the metric.
     */
    metricName: string;
    /**
     * Namespace of the metric.
     */
    namespace: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedCapacityMetricSpecificationMetricDataQueryMetricStatMetricDimension {
    /**
     * Name of the dimension.
     */
    name: string;
    /**
     * Value of the dimension.
     */
    value: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedLoadMetricSpecification {
    /**
     * List of up to 10 structures that defines custom capacity metric in predictive scaling policy
     */
    metricDataQueries: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedLoadMetricSpecificationMetricDataQuery[];
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedLoadMetricSpecificationMetricDataQuery {
    /**
     * Math expression used on the returned metric. You must specify either `expression` or `metricStat`, but not both.
     */
    expression?: string;
    /**
     * Short name for the metric used in predictive scaling policy.
     */
    id: string;
    /**
     * Human-readable label for this metric or expression.
     */
    label?: string;
    /**
     * Structure that defines CloudWatch metric to be used in predictive scaling policy. You must specify either `expression` or `metricStat`, but not both.
     */
    metricStat?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedLoadMetricSpecificationMetricDataQueryMetricStat;
    /**
     * Boolean that indicates whether to return the timestamps and raw data values of this metric, the default it true
     */
    returnData?: boolean;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedLoadMetricSpecificationMetricDataQueryMetricStat {
    /**
     * Structure that defines the CloudWatch metric to return, including the metric name, namespace, and dimensions.
     */
    metric: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedLoadMetricSpecificationMetricDataQueryMetricStatMetric;
    /**
     * Statistic of the metrics to return.
     */
    stat: string;
    /**
     * Unit of the metrics to return.
     */
    unit?: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedLoadMetricSpecificationMetricDataQueryMetricStatMetric {
    /**
     * Dimensions of the metric.
     */
    dimensions?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedLoadMetricSpecificationMetricDataQueryMetricStatMetricDimension[];
    /**
     * Name of the metric.
     */
    metricName: string;
    /**
     * Namespace of the metric.
     */
    namespace: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedLoadMetricSpecificationMetricDataQueryMetricStatMetricDimension {
    /**
     * Name of the dimension.
     */
    name: string;
    /**
     * Value of the dimension.
     */
    value: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedScalingMetricSpecification {
    /**
     * List of up to 10 structures that defines custom capacity metric in predictive scaling policy
     */
    metricDataQueries: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedScalingMetricSpecificationMetricDataQuery[];
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedScalingMetricSpecificationMetricDataQuery {
    /**
     * Math expression used on the returned metric. You must specify either `expression` or `metricStat`, but not both.
     */
    expression?: string;
    /**
     * Short name for the metric used in predictive scaling policy.
     */
    id: string;
    /**
     * Human-readable label for this metric or expression.
     */
    label?: string;
    /**
     * Structure that defines CloudWatch metric to be used in predictive scaling policy. You must specify either `expression` or `metricStat`, but not both.
     */
    metricStat?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedScalingMetricSpecificationMetricDataQueryMetricStat;
    /**
     * Boolean that indicates whether to return the timestamps and raw data values of this metric, the default it true
     */
    returnData?: boolean;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedScalingMetricSpecificationMetricDataQueryMetricStat {
    /**
     * Structure that defines the CloudWatch metric to return, including the metric name, namespace, and dimensions.
     */
    metric: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedScalingMetricSpecificationMetricDataQueryMetricStatMetric;
    /**
     * Statistic of the metrics to return.
     */
    stat: string;
    /**
     * Unit of the metrics to return.
     */
    unit?: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedScalingMetricSpecificationMetricDataQueryMetricStatMetric {
    /**
     * Dimensions of the metric.
     */
    dimensions?: outputs.autoscaling.PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedScalingMetricSpecificationMetricDataQueryMetricStatMetricDimension[];
    /**
     * Name of the metric.
     */
    metricName: string;
    /**
     * Namespace of the metric.
     */
    namespace: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationCustomizedScalingMetricSpecificationMetricDataQueryMetricStatMetricDimension {
    /**
     * Name of the dimension.
     */
    name: string;
    /**
     * Value of the dimension.
     */
    value: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationPredefinedLoadMetricSpecification {
    /**
     * Describes a scaling metric for a predictive scaling policy. Valid values are `ASGAverageCPUUtilization`, `ASGAverageNetworkIn`, `ASGAverageNetworkOut`, or `ALBRequestCountPerTarget`.
     */
    predefinedMetricType: string;
    /**
     * Label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group.
     */
    resourceLabel: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationPredefinedMetricPairSpecification {
    /**
     * Describes a scaling metric for a predictive scaling policy. Valid values are `ASGAverageCPUUtilization`, `ASGAverageNetworkIn`, `ASGAverageNetworkOut`, or `ALBRequestCountPerTarget`.
     */
    predefinedMetricType: string;
    /**
     * Label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group.
     */
    resourceLabel: string;
}

export interface PolicyPredictiveScalingConfigurationMetricSpecificationPredefinedScalingMetricSpecification {
    /**
     * Describes a scaling metric for a predictive scaling policy. Valid values are `ASGAverageCPUUtilization`, `ASGAverageNetworkIn`, `ASGAverageNetworkOut`, or `ALBRequestCountPerTarget`.
     */
    predefinedMetricType: string;
    /**
     * Label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group.
     */
    resourceLabel: string;
}

export interface PolicyStepAdjustment {
    /**
     * Lower bound for the
     * difference between the alarm threshold and the CloudWatch metric.
     * Without a value, AWS will treat this bound as negative infinity.
     */
    metricIntervalLowerBound?: string;
    /**
     * Upper bound for the
     * difference between the alarm threshold and the CloudWatch metric.
     * Without a value, AWS will treat this bound as positive infinity. The upper bound
     * must be greater than the lower bound.
     */
    metricIntervalUpperBound?: string;
    /**
     * Number of members by which to
     * scale, when the adjustment bounds are breached. A positive value scales
     * up. A negative value scales down.
     */
    scalingAdjustment: number;
}

export interface PolicyTargetTrackingConfiguration {
    /**
     * Customized metric. Conflicts with `predefinedMetricSpecification`.
     */
    customizedMetricSpecification?: outputs.autoscaling.PolicyTargetTrackingConfigurationCustomizedMetricSpecification;
    /**
     * Whether scale in by the target tracking policy is disabled.
     */
    disableScaleIn?: boolean;
    /**
     * Predefined metric. Conflicts with `customizedMetricSpecification`.
     */
    predefinedMetricSpecification?: outputs.autoscaling.PolicyTargetTrackingConfigurationPredefinedMetricSpecification;
    /**
     * Target value for the metric.
     */
    targetValue: number;
}

export interface PolicyTargetTrackingConfigurationCustomizedMetricSpecification {
    /**
     * Dimensions of the metric.
     */
    metricDimensions?: outputs.autoscaling.PolicyTargetTrackingConfigurationCustomizedMetricSpecificationMetricDimension[];
    /**
     * Name of the metric.
     */
    metricName: string;
    /**
     * Namespace of the metric.
     */
    namespace: string;
    /**
     * Statistic of the metric.
     */
    statistic: string;
    /**
     * Unit of the metrics to return.
     */
    unit?: string;
}

export interface PolicyTargetTrackingConfigurationCustomizedMetricSpecificationMetricDimension {
    /**
     * Name of the dimension.
     */
    name: string;
    /**
     * Value of the dimension.
     */
    value: string;
}

export interface PolicyTargetTrackingConfigurationPredefinedMetricSpecification {
    /**
     * Describes a scaling metric for a predictive scaling policy. Valid values are `ASGAverageCPUUtilization`, `ASGAverageNetworkIn`, `ASGAverageNetworkOut`, or `ALBRequestCountPerTarget`.
     */
    predefinedMetricType: string;
    /**
     * Label that uniquely identifies a specific Application Load Balancer target group from which to determine the request count served by your Auto Scaling group.
     */
    resourceLabel?: string;
}

export interface TagTag {
    /**
     * Tag name.
     */
    key: string;
    /**
     * Whether to propagate the tags to instances launched by the ASG.
     */
    propagateAtLaunch: boolean;
    /**
     * Tag value.
     */
    value: string;
}

