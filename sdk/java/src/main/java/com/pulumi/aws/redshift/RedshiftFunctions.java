// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.redshift;

import com.pulumi.aws.Utilities;
import com.pulumi.aws.redshift.inputs.GetClusterArgs;
import com.pulumi.aws.redshift.inputs.GetClusterCredentialsArgs;
import com.pulumi.aws.redshift.inputs.GetClusterCredentialsPlainArgs;
import com.pulumi.aws.redshift.inputs.GetClusterPlainArgs;
import com.pulumi.aws.redshift.inputs.GetDataSharesArgs;
import com.pulumi.aws.redshift.inputs.GetDataSharesPlainArgs;
import com.pulumi.aws.redshift.inputs.GetOrderableClusterArgs;
import com.pulumi.aws.redshift.inputs.GetOrderableClusterPlainArgs;
import com.pulumi.aws.redshift.inputs.GetProducerDataSharesArgs;
import com.pulumi.aws.redshift.inputs.GetProducerDataSharesPlainArgs;
import com.pulumi.aws.redshift.inputs.GetSubnetGroupArgs;
import com.pulumi.aws.redshift.inputs.GetSubnetGroupPlainArgs;
import com.pulumi.aws.redshift.outputs.GetClusterCredentialsResult;
import com.pulumi.aws.redshift.outputs.GetClusterResult;
import com.pulumi.aws.redshift.outputs.GetDataSharesResult;
import com.pulumi.aws.redshift.outputs.GetOrderableClusterResult;
import com.pulumi.aws.redshift.outputs.GetProducerDataSharesResult;
import com.pulumi.aws.redshift.outputs.GetSubnetGroupResult;
import com.pulumi.core.Output;
import com.pulumi.core.TypeShape;
import com.pulumi.deployment.Deployment;
import com.pulumi.deployment.InvokeOptions;
import com.pulumi.deployment.InvokeOutputOptions;
import java.util.concurrent.CompletableFuture;

public final class RedshiftFunctions {
    /**
     * Provides details about a specific redshift cluster.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetClusterArgs;
     * import com.pulumi.aws.kinesis.FirehoseDeliveryStream;
     * import com.pulumi.aws.kinesis.FirehoseDeliveryStreamArgs;
     * import com.pulumi.aws.kinesis.inputs.FirehoseDeliveryStreamRedshiftConfigurationArgs;
     * import com.pulumi.aws.kinesis.inputs.FirehoseDeliveryStreamRedshiftConfigurationS3ConfigurationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getCluster(GetClusterArgs.builder()
     *             .clusterIdentifier("example-cluster")
     *             .build());
     * 
     *         var exampleStream = new FirehoseDeliveryStream("exampleStream", FirehoseDeliveryStreamArgs.builder()
     *             .name("kinesis-firehose-example-stream")
     *             .destination("redshift")
     *             .redshiftConfiguration(FirehoseDeliveryStreamRedshiftConfigurationArgs.builder()
     *                 .roleArn(firehoseRole.arn())
     *                 .clusterJdbcurl(String.format("jdbc:redshift://%s/%s", example.endpoint(),example.databaseName()))
     *                 .username("exampleuser")
     *                 .password("Exampl3Pass")
     *                 .dataTableName("example-table")
     *                 .copyOptions("delimiter '|'")
     *                 .dataTableColumns("example-col")
     *                 .s3Configuration(FirehoseDeliveryStreamRedshiftConfigurationS3ConfigurationArgs.builder()
     *                     .roleArn(firehoseRole.arn())
     *                     .bucketArn(bucket.arn())
     *                     .bufferSize(10)
     *                     .bufferInterval(400)
     *                     .compressionFormat("GZIP")
     *                     .build())
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetClusterResult> getCluster(GetClusterArgs args) {
        return getCluster(args, InvokeOptions.Empty);
    }
    /**
     * Provides details about a specific redshift cluster.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetClusterArgs;
     * import com.pulumi.aws.kinesis.FirehoseDeliveryStream;
     * import com.pulumi.aws.kinesis.FirehoseDeliveryStreamArgs;
     * import com.pulumi.aws.kinesis.inputs.FirehoseDeliveryStreamRedshiftConfigurationArgs;
     * import com.pulumi.aws.kinesis.inputs.FirehoseDeliveryStreamRedshiftConfigurationS3ConfigurationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getCluster(GetClusterArgs.builder()
     *             .clusterIdentifier("example-cluster")
     *             .build());
     * 
     *         var exampleStream = new FirehoseDeliveryStream("exampleStream", FirehoseDeliveryStreamArgs.builder()
     *             .name("kinesis-firehose-example-stream")
     *             .destination("redshift")
     *             .redshiftConfiguration(FirehoseDeliveryStreamRedshiftConfigurationArgs.builder()
     *                 .roleArn(firehoseRole.arn())
     *                 .clusterJdbcurl(String.format("jdbc:redshift://%s/%s", example.endpoint(),example.databaseName()))
     *                 .username("exampleuser")
     *                 .password("Exampl3Pass")
     *                 .dataTableName("example-table")
     *                 .copyOptions("delimiter '|'")
     *                 .dataTableColumns("example-col")
     *                 .s3Configuration(FirehoseDeliveryStreamRedshiftConfigurationS3ConfigurationArgs.builder()
     *                     .roleArn(firehoseRole.arn())
     *                     .bucketArn(bucket.arn())
     *                     .bufferSize(10)
     *                     .bufferInterval(400)
     *                     .compressionFormat("GZIP")
     *                     .build())
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetClusterResult> getClusterPlain(GetClusterPlainArgs args) {
        return getClusterPlain(args, InvokeOptions.Empty);
    }
    /**
     * Provides details about a specific redshift cluster.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetClusterArgs;
     * import com.pulumi.aws.kinesis.FirehoseDeliveryStream;
     * import com.pulumi.aws.kinesis.FirehoseDeliveryStreamArgs;
     * import com.pulumi.aws.kinesis.inputs.FirehoseDeliveryStreamRedshiftConfigurationArgs;
     * import com.pulumi.aws.kinesis.inputs.FirehoseDeliveryStreamRedshiftConfigurationS3ConfigurationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getCluster(GetClusterArgs.builder()
     *             .clusterIdentifier("example-cluster")
     *             .build());
     * 
     *         var exampleStream = new FirehoseDeliveryStream("exampleStream", FirehoseDeliveryStreamArgs.builder()
     *             .name("kinesis-firehose-example-stream")
     *             .destination("redshift")
     *             .redshiftConfiguration(FirehoseDeliveryStreamRedshiftConfigurationArgs.builder()
     *                 .roleArn(firehoseRole.arn())
     *                 .clusterJdbcurl(String.format("jdbc:redshift://%s/%s", example.endpoint(),example.databaseName()))
     *                 .username("exampleuser")
     *                 .password("Exampl3Pass")
     *                 .dataTableName("example-table")
     *                 .copyOptions("delimiter '|'")
     *                 .dataTableColumns("example-col")
     *                 .s3Configuration(FirehoseDeliveryStreamRedshiftConfigurationS3ConfigurationArgs.builder()
     *                     .roleArn(firehoseRole.arn())
     *                     .bucketArn(bucket.arn())
     *                     .bufferSize(10)
     *                     .bufferInterval(400)
     *                     .compressionFormat("GZIP")
     *                     .build())
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetClusterResult> getCluster(GetClusterArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getCluster:getCluster", TypeShape.of(GetClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Provides details about a specific redshift cluster.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetClusterArgs;
     * import com.pulumi.aws.kinesis.FirehoseDeliveryStream;
     * import com.pulumi.aws.kinesis.FirehoseDeliveryStreamArgs;
     * import com.pulumi.aws.kinesis.inputs.FirehoseDeliveryStreamRedshiftConfigurationArgs;
     * import com.pulumi.aws.kinesis.inputs.FirehoseDeliveryStreamRedshiftConfigurationS3ConfigurationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getCluster(GetClusterArgs.builder()
     *             .clusterIdentifier("example-cluster")
     *             .build());
     * 
     *         var exampleStream = new FirehoseDeliveryStream("exampleStream", FirehoseDeliveryStreamArgs.builder()
     *             .name("kinesis-firehose-example-stream")
     *             .destination("redshift")
     *             .redshiftConfiguration(FirehoseDeliveryStreamRedshiftConfigurationArgs.builder()
     *                 .roleArn(firehoseRole.arn())
     *                 .clusterJdbcurl(String.format("jdbc:redshift://%s/%s", example.endpoint(),example.databaseName()))
     *                 .username("exampleuser")
     *                 .password("Exampl3Pass")
     *                 .dataTableName("example-table")
     *                 .copyOptions("delimiter '|'")
     *                 .dataTableColumns("example-col")
     *                 .s3Configuration(FirehoseDeliveryStreamRedshiftConfigurationS3ConfigurationArgs.builder()
     *                     .roleArn(firehoseRole.arn())
     *                     .bucketArn(bucket.arn())
     *                     .bufferSize(10)
     *                     .bufferInterval(400)
     *                     .compressionFormat("GZIP")
     *                     .build())
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetClusterResult> getCluster(GetClusterArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getCluster:getCluster", TypeShape.of(GetClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Provides details about a specific redshift cluster.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetClusterArgs;
     * import com.pulumi.aws.kinesis.FirehoseDeliveryStream;
     * import com.pulumi.aws.kinesis.FirehoseDeliveryStreamArgs;
     * import com.pulumi.aws.kinesis.inputs.FirehoseDeliveryStreamRedshiftConfigurationArgs;
     * import com.pulumi.aws.kinesis.inputs.FirehoseDeliveryStreamRedshiftConfigurationS3ConfigurationArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getCluster(GetClusterArgs.builder()
     *             .clusterIdentifier("example-cluster")
     *             .build());
     * 
     *         var exampleStream = new FirehoseDeliveryStream("exampleStream", FirehoseDeliveryStreamArgs.builder()
     *             .name("kinesis-firehose-example-stream")
     *             .destination("redshift")
     *             .redshiftConfiguration(FirehoseDeliveryStreamRedshiftConfigurationArgs.builder()
     *                 .roleArn(firehoseRole.arn())
     *                 .clusterJdbcurl(String.format("jdbc:redshift://%s/%s", example.endpoint(),example.databaseName()))
     *                 .username("exampleuser")
     *                 .password("Exampl3Pass")
     *                 .dataTableName("example-table")
     *                 .copyOptions("delimiter '|'")
     *                 .dataTableColumns("example-col")
     *                 .s3Configuration(FirehoseDeliveryStreamRedshiftConfigurationS3ConfigurationArgs.builder()
     *                     .roleArn(firehoseRole.arn())
     *                     .bucketArn(bucket.arn())
     *                     .bufferSize(10)
     *                     .bufferInterval(400)
     *                     .compressionFormat("GZIP")
     *                     .build())
     *                 .build())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetClusterResult> getClusterPlain(GetClusterPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("aws:redshift/getCluster:getCluster", TypeShape.of(GetClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Provides redshift cluster temporary credentials.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetClusterCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getClusterCredentials(GetClusterCredentialsArgs.builder()
     *             .clusterIdentifier(exampleAwsRedshiftCluster.clusterIdentifier())
     *             .dbUser(exampleAwsRedshiftCluster.masterUsername())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetClusterCredentialsResult> getClusterCredentials(GetClusterCredentialsArgs args) {
        return getClusterCredentials(args, InvokeOptions.Empty);
    }
    /**
     * Provides redshift cluster temporary credentials.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetClusterCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getClusterCredentials(GetClusterCredentialsArgs.builder()
     *             .clusterIdentifier(exampleAwsRedshiftCluster.clusterIdentifier())
     *             .dbUser(exampleAwsRedshiftCluster.masterUsername())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetClusterCredentialsResult> getClusterCredentialsPlain(GetClusterCredentialsPlainArgs args) {
        return getClusterCredentialsPlain(args, InvokeOptions.Empty);
    }
    /**
     * Provides redshift cluster temporary credentials.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetClusterCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getClusterCredentials(GetClusterCredentialsArgs.builder()
     *             .clusterIdentifier(exampleAwsRedshiftCluster.clusterIdentifier())
     *             .dbUser(exampleAwsRedshiftCluster.masterUsername())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetClusterCredentialsResult> getClusterCredentials(GetClusterCredentialsArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getClusterCredentials:getClusterCredentials", TypeShape.of(GetClusterCredentialsResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Provides redshift cluster temporary credentials.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetClusterCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getClusterCredentials(GetClusterCredentialsArgs.builder()
     *             .clusterIdentifier(exampleAwsRedshiftCluster.clusterIdentifier())
     *             .dbUser(exampleAwsRedshiftCluster.masterUsername())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetClusterCredentialsResult> getClusterCredentials(GetClusterCredentialsArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getClusterCredentials:getClusterCredentials", TypeShape.of(GetClusterCredentialsResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Provides redshift cluster temporary credentials.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetClusterCredentialsArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getClusterCredentials(GetClusterCredentialsArgs.builder()
     *             .clusterIdentifier(exampleAwsRedshiftCluster.clusterIdentifier())
     *             .dbUser(exampleAwsRedshiftCluster.masterUsername())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetClusterCredentialsResult> getClusterCredentialsPlain(GetClusterCredentialsPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("aws:redshift/getClusterCredentials:getClusterCredentials", TypeShape.of(GetClusterCredentialsResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Data source for managing AWS Redshift Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getDataShares(GetDataSharesArgs.builder()
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetDataSharesResult> getDataShares() {
        return getDataShares(GetDataSharesArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * Data source for managing AWS Redshift Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getDataShares(GetDataSharesArgs.builder()
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetDataSharesResult> getDataSharesPlain() {
        return getDataSharesPlain(GetDataSharesPlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * Data source for managing AWS Redshift Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getDataShares(GetDataSharesArgs.builder()
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetDataSharesResult> getDataShares(GetDataSharesArgs args) {
        return getDataShares(args, InvokeOptions.Empty);
    }
    /**
     * Data source for managing AWS Redshift Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getDataShares(GetDataSharesArgs.builder()
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetDataSharesResult> getDataSharesPlain(GetDataSharesPlainArgs args) {
        return getDataSharesPlain(args, InvokeOptions.Empty);
    }
    /**
     * Data source for managing AWS Redshift Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getDataShares(GetDataSharesArgs.builder()
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetDataSharesResult> getDataShares(GetDataSharesArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getDataShares:getDataShares", TypeShape.of(GetDataSharesResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Data source for managing AWS Redshift Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getDataShares(GetDataSharesArgs.builder()
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetDataSharesResult> getDataShares(GetDataSharesArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getDataShares:getDataShares", TypeShape.of(GetDataSharesResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Data source for managing AWS Redshift Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getDataShares(GetDataSharesArgs.builder()
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetDataSharesResult> getDataSharesPlain(GetDataSharesPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("aws:redshift/getDataShares:getDataShares", TypeShape.of(GetDataSharesResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Information about Redshift Orderable Clusters and valid parameter combinations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetOrderableClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var test = RedshiftFunctions.getOrderableCluster(GetOrderableClusterArgs.builder()
     *             .clusterType("multi-node")
     *             .preferredNodeTypes(            
     *                 "dc2.large",
     *                 "ds2.xlarge")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetOrderableClusterResult> getOrderableCluster() {
        return getOrderableCluster(GetOrderableClusterArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * Information about Redshift Orderable Clusters and valid parameter combinations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetOrderableClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var test = RedshiftFunctions.getOrderableCluster(GetOrderableClusterArgs.builder()
     *             .clusterType("multi-node")
     *             .preferredNodeTypes(            
     *                 "dc2.large",
     *                 "ds2.xlarge")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetOrderableClusterResult> getOrderableClusterPlain() {
        return getOrderableClusterPlain(GetOrderableClusterPlainArgs.Empty, InvokeOptions.Empty);
    }
    /**
     * Information about Redshift Orderable Clusters and valid parameter combinations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetOrderableClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var test = RedshiftFunctions.getOrderableCluster(GetOrderableClusterArgs.builder()
     *             .clusterType("multi-node")
     *             .preferredNodeTypes(            
     *                 "dc2.large",
     *                 "ds2.xlarge")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetOrderableClusterResult> getOrderableCluster(GetOrderableClusterArgs args) {
        return getOrderableCluster(args, InvokeOptions.Empty);
    }
    /**
     * Information about Redshift Orderable Clusters and valid parameter combinations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetOrderableClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var test = RedshiftFunctions.getOrderableCluster(GetOrderableClusterArgs.builder()
     *             .clusterType("multi-node")
     *             .preferredNodeTypes(            
     *                 "dc2.large",
     *                 "ds2.xlarge")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetOrderableClusterResult> getOrderableClusterPlain(GetOrderableClusterPlainArgs args) {
        return getOrderableClusterPlain(args, InvokeOptions.Empty);
    }
    /**
     * Information about Redshift Orderable Clusters and valid parameter combinations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetOrderableClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var test = RedshiftFunctions.getOrderableCluster(GetOrderableClusterArgs.builder()
     *             .clusterType("multi-node")
     *             .preferredNodeTypes(            
     *                 "dc2.large",
     *                 "ds2.xlarge")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetOrderableClusterResult> getOrderableCluster(GetOrderableClusterArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getOrderableCluster:getOrderableCluster", TypeShape.of(GetOrderableClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Information about Redshift Orderable Clusters and valid parameter combinations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetOrderableClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var test = RedshiftFunctions.getOrderableCluster(GetOrderableClusterArgs.builder()
     *             .clusterType("multi-node")
     *             .preferredNodeTypes(            
     *                 "dc2.large",
     *                 "ds2.xlarge")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetOrderableClusterResult> getOrderableCluster(GetOrderableClusterArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getOrderableCluster:getOrderableCluster", TypeShape.of(GetOrderableClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Information about Redshift Orderable Clusters and valid parameter combinations.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetOrderableClusterArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var test = RedshiftFunctions.getOrderableCluster(GetOrderableClusterArgs.builder()
     *             .clusterType("multi-node")
     *             .preferredNodeTypes(            
     *                 "dc2.large",
     *                 "ds2.xlarge")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetOrderableClusterResult> getOrderableClusterPlain(GetOrderableClusterPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("aws:redshift/getOrderableCluster:getOrderableCluster", TypeShape.of(GetOrderableClusterResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Data source for managing AWS Redshift Producer Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetProducerDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getProducerDataShares(GetProducerDataSharesArgs.builder()
     *             .producerArn("")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetProducerDataSharesResult> getProducerDataShares(GetProducerDataSharesArgs args) {
        return getProducerDataShares(args, InvokeOptions.Empty);
    }
    /**
     * Data source for managing AWS Redshift Producer Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetProducerDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getProducerDataShares(GetProducerDataSharesArgs.builder()
     *             .producerArn("")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetProducerDataSharesResult> getProducerDataSharesPlain(GetProducerDataSharesPlainArgs args) {
        return getProducerDataSharesPlain(args, InvokeOptions.Empty);
    }
    /**
     * Data source for managing AWS Redshift Producer Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetProducerDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getProducerDataShares(GetProducerDataSharesArgs.builder()
     *             .producerArn("")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetProducerDataSharesResult> getProducerDataShares(GetProducerDataSharesArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getProducerDataShares:getProducerDataShares", TypeShape.of(GetProducerDataSharesResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Data source for managing AWS Redshift Producer Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetProducerDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getProducerDataShares(GetProducerDataSharesArgs.builder()
     *             .producerArn("")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetProducerDataSharesResult> getProducerDataShares(GetProducerDataSharesArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getProducerDataShares:getProducerDataShares", TypeShape.of(GetProducerDataSharesResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Data source for managing AWS Redshift Producer Data Shares.
     * 
     * ## Example Usage
     * 
     * ### Basic Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetProducerDataSharesArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getProducerDataShares(GetProducerDataSharesArgs.builder()
     *             .producerArn("")
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetProducerDataSharesResult> getProducerDataSharesPlain(GetProducerDataSharesPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("aws:redshift/getProducerDataShares:getProducerDataShares", TypeShape.of(GetProducerDataSharesResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Provides details about a specific redshift subnet group.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetSubnetGroupArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getSubnetGroup(GetSubnetGroupArgs.builder()
     *             .name(exampleAwsRedshiftSubnetGroup.name())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSubnetGroupResult> getSubnetGroup(GetSubnetGroupArgs args) {
        return getSubnetGroup(args, InvokeOptions.Empty);
    }
    /**
     * Provides details about a specific redshift subnet group.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetSubnetGroupArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getSubnetGroup(GetSubnetGroupArgs.builder()
     *             .name(exampleAwsRedshiftSubnetGroup.name())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSubnetGroupResult> getSubnetGroupPlain(GetSubnetGroupPlainArgs args) {
        return getSubnetGroupPlain(args, InvokeOptions.Empty);
    }
    /**
     * Provides details about a specific redshift subnet group.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetSubnetGroupArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getSubnetGroup(GetSubnetGroupArgs.builder()
     *             .name(exampleAwsRedshiftSubnetGroup.name())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSubnetGroupResult> getSubnetGroup(GetSubnetGroupArgs args, InvokeOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getSubnetGroup:getSubnetGroup", TypeShape.of(GetSubnetGroupResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Provides details about a specific redshift subnet group.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetSubnetGroupArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getSubnetGroup(GetSubnetGroupArgs.builder()
     *             .name(exampleAwsRedshiftSubnetGroup.name())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static Output<GetSubnetGroupResult> getSubnetGroup(GetSubnetGroupArgs args, InvokeOutputOptions options) {
        return Deployment.getInstance().invoke("aws:redshift/getSubnetGroup:getSubnetGroup", TypeShape.of(GetSubnetGroupResult.class), args, Utilities.withVersion(options));
    }
    /**
     * Provides details about a specific redshift subnet group.
     * 
     * ## Example Usage
     * 
     * <pre>
     * {@code
     * package generated_program;
     * 
     * import com.pulumi.Context;
     * import com.pulumi.Pulumi;
     * import com.pulumi.core.Output;
     * import com.pulumi.aws.redshift.RedshiftFunctions;
     * import com.pulumi.aws.redshift.inputs.GetSubnetGroupArgs;
     * import java.util.List;
     * import java.util.ArrayList;
     * import java.util.Map;
     * import java.io.File;
     * import java.nio.file.Files;
     * import java.nio.file.Paths;
     * 
     * public class App {
     *     public static void main(String[] args) {
     *         Pulumi.run(App::stack);
     *     }
     * 
     *     public static void stack(Context ctx) {
     *         final var example = RedshiftFunctions.getSubnetGroup(GetSubnetGroupArgs.builder()
     *             .name(exampleAwsRedshiftSubnetGroup.name())
     *             .build());
     * 
     *     }
     * }
     * }
     * </pre>
     * 
     */
    public static CompletableFuture<GetSubnetGroupResult> getSubnetGroupPlain(GetSubnetGroupPlainArgs args, InvokeOptions options) {
        return Deployment.getInstance().invokeAsync("aws:redshift/getSubnetGroup:getSubnetGroup", TypeShape.of(GetSubnetGroupResult.class), args, Utilities.withVersion(options));
    }
}
