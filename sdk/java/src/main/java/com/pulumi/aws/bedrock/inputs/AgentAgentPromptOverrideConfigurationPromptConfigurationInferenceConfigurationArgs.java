// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.bedrock.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Double;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;


public final class AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs extends com.pulumi.resources.ResourceArgs {

    public static final AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs Empty = new AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs();

    /**
     * Maximum number of tokens to allow in the generated response.
     * 
     */
    @Import(name="maxLength", required=true)
    private Output<Integer> maxLength;

    /**
     * @return Maximum number of tokens to allow in the generated response.
     * 
     */
    public Output<Integer> maxLength() {
        return this.maxLength;
    }

    /**
     * List of stop sequences. A stop sequence is a sequence of characters that causes the model to stop generating the response.
     * 
     */
    @Import(name="stopSequences", required=true)
    private Output<List<String>> stopSequences;

    /**
     * @return List of stop sequences. A stop sequence is a sequence of characters that causes the model to stop generating the response.
     * 
     */
    public Output<List<String>> stopSequences() {
        return this.stopSequences;
    }

    /**
     * Likelihood of the model selecting higher-probability options while generating a response. A lower value makes the model more likely to choose higher-probability options, while a higher value makes the model more likely to choose lower-probability options.
     * 
     */
    @Import(name="temperature", required=true)
    private Output<Double> temperature;

    /**
     * @return Likelihood of the model selecting higher-probability options while generating a response. A lower value makes the model more likely to choose higher-probability options, while a higher value makes the model more likely to choose lower-probability options.
     * 
     */
    public Output<Double> temperature() {
        return this.temperature;
    }

    /**
     * Number of top most-likely candidates, between 0 and 500, from which the model chooses the next token in the sequence.
     * 
     */
    @Import(name="topK", required=true)
    private Output<Integer> topK;

    /**
     * @return Number of top most-likely candidates, between 0 and 500, from which the model chooses the next token in the sequence.
     * 
     */
    public Output<Integer> topK() {
        return this.topK;
    }

    /**
     * Top percentage of the probability distribution of next tokens, between 0 and 1 (denoting 0% and 100%), from which the model chooses the next token in the sequence.
     * 
     */
    @Import(name="topP", required=true)
    private Output<Double> topP;

    /**
     * @return Top percentage of the probability distribution of next tokens, between 0 and 1 (denoting 0% and 100%), from which the model chooses the next token in the sequence.
     * 
     */
    public Output<Double> topP() {
        return this.topP;
    }

    private AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs() {}

    private AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs(AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs $) {
        this.maxLength = $.maxLength;
        this.stopSequences = $.stopSequences;
        this.temperature = $.temperature;
        this.topK = $.topK;
        this.topP = $.topP;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs $;

        public Builder() {
            $ = new AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs();
        }

        public Builder(AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs defaults) {
            $ = new AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param maxLength Maximum number of tokens to allow in the generated response.
         * 
         * @return builder
         * 
         */
        public Builder maxLength(Output<Integer> maxLength) {
            $.maxLength = maxLength;
            return this;
        }

        /**
         * @param maxLength Maximum number of tokens to allow in the generated response.
         * 
         * @return builder
         * 
         */
        public Builder maxLength(Integer maxLength) {
            return maxLength(Output.of(maxLength));
        }

        /**
         * @param stopSequences List of stop sequences. A stop sequence is a sequence of characters that causes the model to stop generating the response.
         * 
         * @return builder
         * 
         */
        public Builder stopSequences(Output<List<String>> stopSequences) {
            $.stopSequences = stopSequences;
            return this;
        }

        /**
         * @param stopSequences List of stop sequences. A stop sequence is a sequence of characters that causes the model to stop generating the response.
         * 
         * @return builder
         * 
         */
        public Builder stopSequences(List<String> stopSequences) {
            return stopSequences(Output.of(stopSequences));
        }

        /**
         * @param stopSequences List of stop sequences. A stop sequence is a sequence of characters that causes the model to stop generating the response.
         * 
         * @return builder
         * 
         */
        public Builder stopSequences(String... stopSequences) {
            return stopSequences(List.of(stopSequences));
        }

        /**
         * @param temperature Likelihood of the model selecting higher-probability options while generating a response. A lower value makes the model more likely to choose higher-probability options, while a higher value makes the model more likely to choose lower-probability options.
         * 
         * @return builder
         * 
         */
        public Builder temperature(Output<Double> temperature) {
            $.temperature = temperature;
            return this;
        }

        /**
         * @param temperature Likelihood of the model selecting higher-probability options while generating a response. A lower value makes the model more likely to choose higher-probability options, while a higher value makes the model more likely to choose lower-probability options.
         * 
         * @return builder
         * 
         */
        public Builder temperature(Double temperature) {
            return temperature(Output.of(temperature));
        }

        /**
         * @param topK Number of top most-likely candidates, between 0 and 500, from which the model chooses the next token in the sequence.
         * 
         * @return builder
         * 
         */
        public Builder topK(Output<Integer> topK) {
            $.topK = topK;
            return this;
        }

        /**
         * @param topK Number of top most-likely candidates, between 0 and 500, from which the model chooses the next token in the sequence.
         * 
         * @return builder
         * 
         */
        public Builder topK(Integer topK) {
            return topK(Output.of(topK));
        }

        /**
         * @param topP Top percentage of the probability distribution of next tokens, between 0 and 1 (denoting 0% and 100%), from which the model chooses the next token in the sequence.
         * 
         * @return builder
         * 
         */
        public Builder topP(Output<Double> topP) {
            $.topP = topP;
            return this;
        }

        /**
         * @param topP Top percentage of the probability distribution of next tokens, between 0 and 1 (denoting 0% and 100%), from which the model chooses the next token in the sequence.
         * 
         * @return builder
         * 
         */
        public Builder topP(Double topP) {
            return topP(Output.of(topP));
        }

        public AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs build() {
            if ($.maxLength == null) {
                throw new MissingRequiredPropertyException("AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs", "maxLength");
            }
            if ($.stopSequences == null) {
                throw new MissingRequiredPropertyException("AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs", "stopSequences");
            }
            if ($.temperature == null) {
                throw new MissingRequiredPropertyException("AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs", "temperature");
            }
            if ($.topK == null) {
                throw new MissingRequiredPropertyException("AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs", "topK");
            }
            if ($.topP == null) {
                throw new MissingRequiredPropertyException("AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfigurationArgs", "topP");
            }
            return $;
        }
    }

}
