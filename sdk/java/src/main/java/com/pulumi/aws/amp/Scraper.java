// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.amp;

import com.pulumi.aws.Utilities;
import com.pulumi.aws.amp.ScraperArgs;
import com.pulumi.aws.amp.inputs.ScraperState;
import com.pulumi.aws.amp.outputs.ScraperDestination;
import com.pulumi.aws.amp.outputs.ScraperRoleConfiguration;
import com.pulumi.aws.amp.outputs.ScraperSource;
import com.pulumi.aws.amp.outputs.ScraperTimeouts;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import java.lang.String;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * &gt; **Note:** If you change a Scraper&#39;s source (EKS cluster), Terraform
 * will delete the current Scraper and create a new one.
 * 
 * Provides an Amazon Managed Service for Prometheus fully managed collector
 * (scraper).
 * 
 * Read more in the [Amazon Managed Service for Prometheus user guide](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector.html).
 * 
 * ## Example Usage
 * 
 * ### Basic Usage
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.amp.Scraper;
 * import com.pulumi.aws.amp.ScraperArgs;
 * import com.pulumi.aws.amp.inputs.ScraperSourceArgs;
 * import com.pulumi.aws.amp.inputs.ScraperSourceEksArgs;
 * import com.pulumi.aws.amp.inputs.ScraperDestinationArgs;
 * import com.pulumi.aws.amp.inputs.ScraperDestinationAmpArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new Scraper("example", ScraperArgs.builder()
 *             .source(ScraperSourceArgs.builder()
 *                 .eks(ScraperSourceEksArgs.builder()
 *                     .clusterArn(exampleAwsEksCluster.arn())
 *                     .subnetIds(exampleAwsEksCluster.vpcConfig()[0].subnetIds())
 *                     .build())
 *                 .build())
 *             .destination(ScraperDestinationArgs.builder()
 *                 .amp(ScraperDestinationAmpArgs.builder()
 *                     .workspaceArn(exampleAwsPrometheusWorkspace.arn())
 *                     .build())
 *                 .build())
 *             .scrapeConfiguration("""
 * global:
 *   scrape_interval: 30s
 * scrape_configs:
 *   # pod metrics
 *   - job_name: pod_exporter
 *     kubernetes_sd_configs:
 *       - role: pod
 *   # container metrics
 *   - job_name: cadvisor
 *     scheme: https
 *     authorization:
 *       credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token
 *     kubernetes_sd_configs:
 *       - role: node
 *     relabel_configs:
 *       - action: labelmap
 *         regex: __meta_kubernetes_node_label_(.+)
 *       - replacement: kubernetes.default.svc:443
 *         target_label: __address__
 *       - source_labels: [__meta_kubernetes_node_name]
 *         regex: (.+)
 *         target_label: __metrics_path__
 *         replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
 *   # apiserver metrics
 *   - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
 *     job_name: kubernetes-apiservers
 *     kubernetes_sd_configs:
 *     - role: endpoints
 *     relabel_configs:
 *     - action: keep
 *       regex: default;kubernetes;https
 *       source_labels:
 *       - __meta_kubernetes_namespace
 *       - __meta_kubernetes_service_name
 *       - __meta_kubernetes_endpoint_port_name
 *     scheme: https
 *   # kube proxy metrics
 *   - job_name: kube-proxy
 *     honor_labels: true
 *     kubernetes_sd_configs:
 *     - role: pod
 *     relabel_configs:
 *     - action: keep
 *       source_labels:
 *       - __meta_kubernetes_namespace
 *       - __meta_kubernetes_pod_name
 *       separator: '/'
 *       regex: 'kube-system/kube-proxy.+'
 *     - source_labels:
 *       - __address__
 *       action: replace
 *       target_label: __address__
 *       regex: (.+?)(\\\\:\\\\d+)?
 *       replacement: $1:10249
 *             """)
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Use default EKS scraper configuration
 * 
 * You can use the data source `awsPrometheusScraperConfiguration` to use a
 * service managed scrape configuration.
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.amp.AmpFunctions;
 * import com.pulumi.aws.amp.inputs.GetDefaultScraperConfigurationArgs;
 * import com.pulumi.aws.amp.Scraper;
 * import com.pulumi.aws.amp.ScraperArgs;
 * import com.pulumi.aws.amp.inputs.ScraperDestinationArgs;
 * import com.pulumi.aws.amp.inputs.ScraperDestinationAmpArgs;
 * import com.pulumi.aws.amp.inputs.ScraperSourceArgs;
 * import com.pulumi.aws.amp.inputs.ScraperSourceEksArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         final var example = AmpFunctions.getDefaultScraperConfiguration(GetDefaultScraperConfigurationArgs.builder()
 *             .build());
 * 
 *         var exampleScraper = new Scraper("exampleScraper", ScraperArgs.builder()
 *             .destination(ScraperDestinationArgs.builder()
 *                 .amp(ScraperDestinationAmpArgs.builder()
 *                     .workspaceArn(exampleAwsPrometheusWorkspace.arn())
 *                     .build())
 *                 .build())
 *             .scrapeConfiguration(exampleAwsPrometheusScraperConfiguration.configuration())
 *             .source(ScraperSourceArgs.builder()
 *                 .eks(ScraperSourceEksArgs.builder()
 *                     .clusterArn(exampleAwsEksCluster.arn())
 *                     .subnetIds(exampleAwsEksCluster.vpcConfig()[0].subnetIds())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Ignoring changes to Prometheus Workspace destination
 * 
 * A managed scraper will add a `AMPAgentlessScraper` tag to its Prometheus workspace
 * destination. To avoid Terraform state forcing removing the tag from the workspace,
 * you can add this tag to the destination workspace (preferred) or ignore tags
 * changes with `lifecycle`. See example below.
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.eks.EksFunctions;
 * import com.pulumi.aws.eks.inputs.GetClusterArgs;
 * import com.pulumi.aws.amp.Workspace;
 * import com.pulumi.aws.amp.WorkspaceArgs;
 * import com.pulumi.aws.amp.Scraper;
 * import com.pulumi.aws.amp.ScraperArgs;
 * import com.pulumi.aws.amp.inputs.ScraperSourceArgs;
 * import com.pulumi.aws.amp.inputs.ScraperSourceEksArgs;
 * import com.pulumi.aws.amp.inputs.ScraperDestinationArgs;
 * import com.pulumi.aws.amp.inputs.ScraperDestinationAmpArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         final var this = EksFunctions.getCluster(GetClusterArgs.builder()
 *             .name("example")
 *             .build());
 * 
 *         var example = new Workspace("example", WorkspaceArgs.builder()
 *             .tags(Map.of("AMPAgentlessScraper", ""))
 *             .build());
 * 
 *         var exampleScraper = new Scraper("exampleScraper", ScraperArgs.builder()
 *             .source(ScraperSourceArgs.builder()
 *                 .eks(ScraperSourceEksArgs.builder()
 *                     .clusterArn(exampleAwsEksCluster.arn())
 *                     .subnetIds(exampleAwsEksCluster.vpcConfig()[0].subnetIds())
 *                     .build())
 *                 .build())
 *             .scrapeConfiguration("...")
 *             .destination(ScraperDestinationArgs.builder()
 *                 .amp(ScraperDestinationAmpArgs.builder()
 *                     .workspaceArn(example.arn())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Configure aws-auth
 * 
 * Your source Amazon EKS cluster must be configured to allow the scraper to access
 * metrics. Follow the [user guide](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector-how-to.html#AMP-collector-eks-setup)
 * to setup the appropriate Kubernetes permissions.
 * 
 * ### Cross-Account Configuration
 * 
 * This setup allows the scraper, running in a source account, to remote write its collected metrics to a workspace in a target account. Note that:
 * 
 * - The target Role and target Workspace must be in the same account
 * - The source Scraper and target Workspace must be in the same Region
 * 
 * Follow [the AWS Best Practices guide](https://aws-observability.github.io/observability-best-practices/patterns/ampxa) to learn about the IAM roles configuration and overall setup.
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.amp.Scraper;
 * import com.pulumi.aws.amp.ScraperArgs;
 * import com.pulumi.aws.amp.inputs.ScraperSourceArgs;
 * import com.pulumi.aws.amp.inputs.ScraperSourceEksArgs;
 * import com.pulumi.aws.amp.inputs.ScraperDestinationArgs;
 * import com.pulumi.aws.amp.inputs.ScraperDestinationAmpArgs;
 * import com.pulumi.aws.amp.inputs.ScraperRoleConfigurationArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new Scraper("example", ScraperArgs.builder()
 *             .source(ScraperSourceArgs.builder()
 *                 .eks(ScraperSourceEksArgs.builder()
 *                     .clusterArn(exampleAwsEksCluster.arn())
 *                     .subnetIds(exampleAwsEksCluster.vpcConfig()[0].subnetIds())
 *                     .build())
 *                 .build())
 *             .destination(ScraperDestinationArgs.builder()
 *                 .amp(ScraperDestinationAmpArgs.builder()
 *                     .workspaceArn("<target_account_workspace_arn>")
 *                     .build())
 *                 .build())
 *             .roleConfiguration(ScraperRoleConfigurationArgs.builder()
 *                 .sourceRoleArn(source.arn())
 *                 .targetRoleArn("arn:aws:iam::ACCOUNT-ID:role/target-role-name")
 *                 .build())
 *             .scrapeConfiguration("...")
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Import
 * 
 * Using `pulumi import`, import the Managed Scraper using its identifier.
 * For example:
 * 
 * ```sh
 * $ pulumi import aws:amp/scraper:Scraper example s-0123abc-0000-0123-a000-000000000000
 * ```
 * 
 */
@ResourceType(type="aws:amp/scraper:Scraper")
public class Scraper extends com.pulumi.resources.CustomResource {
    /**
     * a name to associate with the managed scraper. This is for your use, and does not need to be unique.
     * 
     */
    @Export(name="alias", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> alias;

    /**
     * @return a name to associate with the managed scraper. This is for your use, and does not need to be unique.
     * 
     */
    public Output<Optional<String>> alias() {
        return Codegen.optional(this.alias);
    }
    /**
     * The Amazon Resource Name (ARN) of the new scraper.
     * 
     */
    @Export(name="arn", refs={String.class}, tree="[0]")
    private Output<String> arn;

    /**
     * @return The Amazon Resource Name (ARN) of the new scraper.
     * 
     */
    public Output<String> arn() {
        return this.arn;
    }
    /**
     * Configuration block for the managed scraper to send metrics to. See `destination`.
     * 
     */
    @Export(name="destination", refs={ScraperDestination.class}, tree="[0]")
    private Output<ScraperDestination> destination;

    /**
     * @return Configuration block for the managed scraper to send metrics to. See `destination`.
     * 
     */
    public Output<ScraperDestination> destination() {
        return this.destination;
    }
    /**
     * Region where this resource will be [managed](https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints). Defaults to the Region set in the provider configuration.
     * 
     */
    @Export(name="region", refs={String.class}, tree="[0]")
    private Output<String> region;

    /**
     * @return Region where this resource will be [managed](https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints). Defaults to the Region set in the provider configuration.
     * 
     */
    public Output<String> region() {
        return this.region;
    }
    /**
     * The Amazon Resource Name (ARN) of the IAM role that provides permissions for the scraper to discover, collect, and produce metrics
     * 
     */
    @Export(name="roleArn", refs={String.class}, tree="[0]")
    private Output<String> roleArn;

    /**
     * @return The Amazon Resource Name (ARN) of the IAM role that provides permissions for the scraper to discover, collect, and produce metrics
     * 
     */
    public Output<String> roleArn() {
        return this.roleArn;
    }
    /**
     * Configuration block to enable writing to an Amazon Managed Service for Prometheus workspace in a different account. See `roleConfiguration` below.
     * 
     */
    @Export(name="roleConfiguration", refs={ScraperRoleConfiguration.class}, tree="[0]")
    private Output</* @Nullable */ ScraperRoleConfiguration> roleConfiguration;

    /**
     * @return Configuration block to enable writing to an Amazon Managed Service for Prometheus workspace in a different account. See `roleConfiguration` below.
     * 
     */
    public Output<Optional<ScraperRoleConfiguration>> roleConfiguration() {
        return Codegen.optional(this.roleConfiguration);
    }
    /**
     * The configuration file to use in the new scraper. For more information, see [Scraper configuration](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector-how-to.html#AMP-collector-configuration).
     * 
     */
    @Export(name="scrapeConfiguration", refs={String.class}, tree="[0]")
    private Output<String> scrapeConfiguration;

    /**
     * @return The configuration file to use in the new scraper. For more information, see [Scraper configuration](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector-how-to.html#AMP-collector-configuration).
     * 
     */
    public Output<String> scrapeConfiguration() {
        return this.scrapeConfiguration;
    }
    /**
     * Configuration block to specify where the managed scraper will collect metrics from. See `source`.
     * 
     * The following arguments are optional:
     * 
     */
    @Export(name="source", refs={ScraperSource.class}, tree="[0]")
    private Output</* @Nullable */ ScraperSource> source;

    /**
     * @return Configuration block to specify where the managed scraper will collect metrics from. See `source`.
     * 
     * The following arguments are optional:
     * 
     */
    public Output<Optional<ScraperSource>> source() {
        return Codegen.optional(this.source);
    }
    @Export(name="tags", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> tags;

    public Output<Optional<Map<String,String>>> tags() {
        return Codegen.optional(this.tags);
    }
    @Export(name="tagsAll", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> tagsAll;

    public Output<Map<String,String>> tagsAll() {
        return this.tagsAll;
    }
    @Export(name="timeouts", refs={ScraperTimeouts.class}, tree="[0]")
    private Output</* @Nullable */ ScraperTimeouts> timeouts;

    public Output<Optional<ScraperTimeouts>> timeouts() {
        return Codegen.optional(this.timeouts);
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public Scraper(java.lang.String name) {
        this(name, ScraperArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public Scraper(java.lang.String name, ScraperArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public Scraper(java.lang.String name, ScraperArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("aws:amp/scraper:Scraper", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private Scraper(java.lang.String name, Output<java.lang.String> id, @Nullable ScraperState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("aws:amp/scraper:Scraper", name, state, makeResourceOptions(options, id), false);
    }

    private static ScraperArgs makeArgs(ScraperArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? ScraperArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static Scraper get(java.lang.String name, Output<java.lang.String> id, @Nullable ScraperState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new Scraper(name, id, state, options);
    }
}
