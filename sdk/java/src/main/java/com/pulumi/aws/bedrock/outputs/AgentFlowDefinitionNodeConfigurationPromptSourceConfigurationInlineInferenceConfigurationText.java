// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.bedrock.outputs;

import com.pulumi.core.annotations.CustomType;
import java.lang.Double;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class AgentFlowDefinitionNodeConfigurationPromptSourceConfigurationInlineInferenceConfigurationText {
    /**
     * @return Maximum number of tokens to return in the response.
     * 
     */
    private @Nullable Integer maxTokens;
    /**
     * @return List of strings that define sequences after which the model will stop generating.
     * 
     */
    private @Nullable List<String> stopSequences;
    /**
     * @return Controls the randomness of the response. Choose a lower value for more predictable outputs and a higher value for more surprising outputs.
     * 
     */
    private @Nullable Double temperature;
    /**
     * @return Percentage of most-likely candidates that the model considers for the next token.
     * 
     */
    private @Nullable Double topP;

    private AgentFlowDefinitionNodeConfigurationPromptSourceConfigurationInlineInferenceConfigurationText() {}
    /**
     * @return Maximum number of tokens to return in the response.
     * 
     */
    public Optional<Integer> maxTokens() {
        return Optional.ofNullable(this.maxTokens);
    }
    /**
     * @return List of strings that define sequences after which the model will stop generating.
     * 
     */
    public List<String> stopSequences() {
        return this.stopSequences == null ? List.of() : this.stopSequences;
    }
    /**
     * @return Controls the randomness of the response. Choose a lower value for more predictable outputs and a higher value for more surprising outputs.
     * 
     */
    public Optional<Double> temperature() {
        return Optional.ofNullable(this.temperature);
    }
    /**
     * @return Percentage of most-likely candidates that the model considers for the next token.
     * 
     */
    public Optional<Double> topP() {
        return Optional.ofNullable(this.topP);
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(AgentFlowDefinitionNodeConfigurationPromptSourceConfigurationInlineInferenceConfigurationText defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable Integer maxTokens;
        private @Nullable List<String> stopSequences;
        private @Nullable Double temperature;
        private @Nullable Double topP;
        public Builder() {}
        public Builder(AgentFlowDefinitionNodeConfigurationPromptSourceConfigurationInlineInferenceConfigurationText defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.maxTokens = defaults.maxTokens;
    	      this.stopSequences = defaults.stopSequences;
    	      this.temperature = defaults.temperature;
    	      this.topP = defaults.topP;
        }

        @CustomType.Setter
        public Builder maxTokens(@Nullable Integer maxTokens) {

            this.maxTokens = maxTokens;
            return this;
        }
        @CustomType.Setter
        public Builder stopSequences(@Nullable List<String> stopSequences) {

            this.stopSequences = stopSequences;
            return this;
        }
        public Builder stopSequences(String... stopSequences) {
            return stopSequences(List.of(stopSequences));
        }
        @CustomType.Setter
        public Builder temperature(@Nullable Double temperature) {

            this.temperature = temperature;
            return this;
        }
        @CustomType.Setter
        public Builder topP(@Nullable Double topP) {

            this.topP = topP;
            return this;
        }
        public AgentFlowDefinitionNodeConfigurationPromptSourceConfigurationInlineInferenceConfigurationText build() {
            final var _resultValue = new AgentFlowDefinitionNodeConfigurationPromptSourceConfigurationInlineInferenceConfigurationText();
            _resultValue.maxTokens = maxTokens;
            _resultValue.stopSequences = stopSequences;
            _resultValue.temperature = temperature;
            _resultValue.topP = topP;
            return _resultValue;
        }
    }
}
