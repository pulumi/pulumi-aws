// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.bedrock.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import java.lang.Double;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class AgentPromptVariantInferenceConfigurationTextArgs extends com.pulumi.resources.ResourceArgs {

    public static final AgentPromptVariantInferenceConfigurationTextArgs Empty = new AgentPromptVariantInferenceConfigurationTextArgs();

    /**
     * Maximum number of tokens to return in the response.
     * 
     */
    @Import(name="maxTokens")
    private @Nullable Output<Integer> maxTokens;

    /**
     * @return Maximum number of tokens to return in the response.
     * 
     */
    public Optional<Output<Integer>> maxTokens() {
        return Optional.ofNullable(this.maxTokens);
    }

    /**
     * List of strings that define sequences after which the model will stop generating.
     * 
     */
    @Import(name="stopSequences")
    private @Nullable Output<List<String>> stopSequences;

    /**
     * @return List of strings that define sequences after which the model will stop generating.
     * 
     */
    public Optional<Output<List<String>>> stopSequences() {
        return Optional.ofNullable(this.stopSequences);
    }

    /**
     * Controls the randomness of the response. Choose a lower value for more predictable outputs and a higher value for more surprising outputs.
     * 
     */
    @Import(name="temperature")
    private @Nullable Output<Double> temperature;

    /**
     * @return Controls the randomness of the response. Choose a lower value for more predictable outputs and a higher value for more surprising outputs.
     * 
     */
    public Optional<Output<Double>> temperature() {
        return Optional.ofNullable(this.temperature);
    }

    /**
     * Percentage of most-likely candidates that the model considers for the next token.
     * 
     */
    @Import(name="topP")
    private @Nullable Output<Double> topP;

    /**
     * @return Percentage of most-likely candidates that the model considers for the next token.
     * 
     */
    public Optional<Output<Double>> topP() {
        return Optional.ofNullable(this.topP);
    }

    private AgentPromptVariantInferenceConfigurationTextArgs() {}

    private AgentPromptVariantInferenceConfigurationTextArgs(AgentPromptVariantInferenceConfigurationTextArgs $) {
        this.maxTokens = $.maxTokens;
        this.stopSequences = $.stopSequences;
        this.temperature = $.temperature;
        this.topP = $.topP;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(AgentPromptVariantInferenceConfigurationTextArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private AgentPromptVariantInferenceConfigurationTextArgs $;

        public Builder() {
            $ = new AgentPromptVariantInferenceConfigurationTextArgs();
        }

        public Builder(AgentPromptVariantInferenceConfigurationTextArgs defaults) {
            $ = new AgentPromptVariantInferenceConfigurationTextArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param maxTokens Maximum number of tokens to return in the response.
         * 
         * @return builder
         * 
         */
        public Builder maxTokens(@Nullable Output<Integer> maxTokens) {
            $.maxTokens = maxTokens;
            return this;
        }

        /**
         * @param maxTokens Maximum number of tokens to return in the response.
         * 
         * @return builder
         * 
         */
        public Builder maxTokens(Integer maxTokens) {
            return maxTokens(Output.of(maxTokens));
        }

        /**
         * @param stopSequences List of strings that define sequences after which the model will stop generating.
         * 
         * @return builder
         * 
         */
        public Builder stopSequences(@Nullable Output<List<String>> stopSequences) {
            $.stopSequences = stopSequences;
            return this;
        }

        /**
         * @param stopSequences List of strings that define sequences after which the model will stop generating.
         * 
         * @return builder
         * 
         */
        public Builder stopSequences(List<String> stopSequences) {
            return stopSequences(Output.of(stopSequences));
        }

        /**
         * @param stopSequences List of strings that define sequences after which the model will stop generating.
         * 
         * @return builder
         * 
         */
        public Builder stopSequences(String... stopSequences) {
            return stopSequences(List.of(stopSequences));
        }

        /**
         * @param temperature Controls the randomness of the response. Choose a lower value for more predictable outputs and a higher value for more surprising outputs.
         * 
         * @return builder
         * 
         */
        public Builder temperature(@Nullable Output<Double> temperature) {
            $.temperature = temperature;
            return this;
        }

        /**
         * @param temperature Controls the randomness of the response. Choose a lower value for more predictable outputs and a higher value for more surprising outputs.
         * 
         * @return builder
         * 
         */
        public Builder temperature(Double temperature) {
            return temperature(Output.of(temperature));
        }

        /**
         * @param topP Percentage of most-likely candidates that the model considers for the next token.
         * 
         * @return builder
         * 
         */
        public Builder topP(@Nullable Output<Double> topP) {
            $.topP = topP;
            return this;
        }

        /**
         * @param topP Percentage of most-likely candidates that the model considers for the next token.
         * 
         * @return builder
         * 
         */
        public Builder topP(Double topP) {
            return topP(Output.of(topP));
        }

        public AgentPromptVariantInferenceConfigurationTextArgs build() {
            return $;
        }
    }

}
