// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.bedrock;

import com.pulumi.aws.Utilities;
import com.pulumi.aws.bedrock.InferenceProfileArgs;
import com.pulumi.aws.bedrock.inputs.InferenceProfileState;
import com.pulumi.aws.bedrock.outputs.InferenceProfileModel;
import com.pulumi.aws.bedrock.outputs.InferenceProfileModelSource;
import com.pulumi.aws.bedrock.outputs.InferenceProfileTimeouts;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * Resource for managing an AWS Bedrock Inference Profile.
 * 
 * ## Example Usage
 * 
 * ### Basic Usage
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.AwsFunctions;
 * import com.pulumi.aws.inputs.GetCallerIdentityArgs;
 * import com.pulumi.aws.bedrock.InferenceProfile;
 * import com.pulumi.aws.bedrock.InferenceProfileArgs;
 * import com.pulumi.aws.bedrock.inputs.InferenceProfileModelSourceArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         final var current = AwsFunctions.getCallerIdentity(GetCallerIdentityArgs.builder()
 *             .build());
 * 
 *         var example = new InferenceProfile("example", InferenceProfileArgs.builder()
 *             .name("Claude Sonnet for Project 123")
 *             .description("Profile with tag for cost allocation tracking")
 *             .modelSource(InferenceProfileModelSourceArgs.builder()
 *                 .copyFrom("arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-5-sonnet-20241022-v2:0")
 *                 .build())
 *             .tags(Map.of("ProjectID", "123"))
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * ## Import
 * 
 * Using `pulumi import`, import Bedrock Inference Profile using the `example_id_arg`. For example:
 * 
 * ```sh
 * $ pulumi import aws:bedrock/inferenceProfile:InferenceProfile example inference_profile-id-12345678
 * ```
 * 
 */
@ResourceType(type="aws:bedrock/inferenceProfile:InferenceProfile")
public class InferenceProfile extends com.pulumi.resources.CustomResource {
    /**
     * The Amazon Resource Name (ARN) of the inference profile.
     * 
     */
    @Export(name="arn", refs={String.class}, tree="[0]")
    private Output<String> arn;

    /**
     * @return The Amazon Resource Name (ARN) of the inference profile.
     * 
     */
    public Output<String> arn() {
        return this.arn;
    }
    /**
     * The time at which the inference profile was created.
     * 
     */
    @Export(name="createdAt", refs={String.class}, tree="[0]")
    private Output<String> createdAt;

    /**
     * @return The time at which the inference profile was created.
     * 
     */
    public Output<String> createdAt() {
        return this.createdAt;
    }
    /**
     * The description of the inference profile.
     * 
     */
    @Export(name="description", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> description;

    /**
     * @return The description of the inference profile.
     * 
     */
    public Output<Optional<String>> description() {
        return Codegen.optional(this.description);
    }
    /**
     * The source of the model this inference profile will track metrics and cost for. See `model_source`.
     * 
     * The following arguments are optional:
     * 
     */
    @Export(name="modelSource", refs={InferenceProfileModelSource.class}, tree="[0]")
    private Output</* @Nullable */ InferenceProfileModelSource> modelSource;

    /**
     * @return The source of the model this inference profile will track metrics and cost for. See `model_source`.
     * 
     * The following arguments are optional:
     * 
     */
    public Output<Optional<InferenceProfileModelSource>> modelSource() {
        return Codegen.optional(this.modelSource);
    }
    /**
     * A list of information about each model in the inference profile. See `models`.
     * 
     */
    @Export(name="models", refs={List.class,InferenceProfileModel.class}, tree="[0,1]")
    private Output<List<InferenceProfileModel>> models;

    /**
     * @return A list of information about each model in the inference profile. See `models`.
     * 
     */
    public Output<List<InferenceProfileModel>> models() {
        return this.models;
    }
    /**
     * The name of the inference profile.
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return The name of the inference profile.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * The AWS Region to use for API operations. Overrides the Region set in the provider configuration.
     * 
     */
    @Export(name="region", refs={String.class}, tree="[0]")
    private Output<String> region;

    /**
     * @return The AWS Region to use for API operations. Overrides the Region set in the provider configuration.
     * 
     */
    public Output<String> region() {
        return this.region;
    }
    /**
     * The status of the inference profile. `ACTIVE` means that the inference profile is available to use.
     * 
     */
    @Export(name="status", refs={String.class}, tree="[0]")
    private Output<String> status;

    /**
     * @return The status of the inference profile. `ACTIVE` means that the inference profile is available to use.
     * 
     */
    public Output<String> status() {
        return this.status;
    }
    /**
     * Key-value mapping of resource tags for the inference profile.
     * 
     */
    @Export(name="tags", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> tags;

    /**
     * @return Key-value mapping of resource tags for the inference profile.
     * 
     */
    public Output<Optional<Map<String,String>>> tags() {
        return Codegen.optional(this.tags);
    }
    @Export(name="tagsAll", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> tagsAll;

    public Output<Map<String,String>> tagsAll() {
        return this.tagsAll;
    }
    @Export(name="timeouts", refs={InferenceProfileTimeouts.class}, tree="[0]")
    private Output</* @Nullable */ InferenceProfileTimeouts> timeouts;

    public Output<Optional<InferenceProfileTimeouts>> timeouts() {
        return Codegen.optional(this.timeouts);
    }
    /**
     * The type of the inference profile. `SYSTEM_DEFINED` means that the inference profile is defined by Amazon Bedrock. `APPLICATION` means that the inference profile is defined by the user.
     * 
     */
    @Export(name="type", refs={String.class}, tree="[0]")
    private Output<String> type;

    /**
     * @return The type of the inference profile. `SYSTEM_DEFINED` means that the inference profile is defined by Amazon Bedrock. `APPLICATION` means that the inference profile is defined by the user.
     * 
     */
    public Output<String> type() {
        return this.type;
    }
    /**
     * The time at which the inference profile was last updated.
     * 
     */
    @Export(name="updatedAt", refs={String.class}, tree="[0]")
    private Output<String> updatedAt;

    /**
     * @return The time at which the inference profile was last updated.
     * 
     */
    public Output<String> updatedAt() {
        return this.updatedAt;
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public InferenceProfile(java.lang.String name) {
        this(name, InferenceProfileArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public InferenceProfile(java.lang.String name, @Nullable InferenceProfileArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public InferenceProfile(java.lang.String name, @Nullable InferenceProfileArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("aws:bedrock/inferenceProfile:InferenceProfile", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private InferenceProfile(java.lang.String name, Output<java.lang.String> id, @Nullable InferenceProfileState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("aws:bedrock/inferenceProfile:InferenceProfile", name, state, makeResourceOptions(options, id), false);
    }

    private static InferenceProfileArgs makeArgs(@Nullable InferenceProfileArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? InferenceProfileArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static InferenceProfile get(java.lang.String name, Output<java.lang.String> id, @Nullable InferenceProfileState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new InferenceProfile(name, id, state, options);
    }
}
