// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.sagemaker.inputs;

import com.pulumi.aws.sagemaker.inputs.EndpointConfigurationShadowProductionVariantCoreDumpConfigArgs;
import com.pulumi.aws.sagemaker.inputs.EndpointConfigurationShadowProductionVariantManagedInstanceScalingArgs;
import com.pulumi.aws.sagemaker.inputs.EndpointConfigurationShadowProductionVariantRoutingConfigArgs;
import com.pulumi.aws.sagemaker.inputs.EndpointConfigurationShadowProductionVariantServerlessConfigArgs;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import java.lang.Boolean;
import java.lang.Double;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class EndpointConfigurationShadowProductionVariantArgs extends com.pulumi.resources.ResourceArgs {

    public static final EndpointConfigurationShadowProductionVariantArgs Empty = new EndpointConfigurationShadowProductionVariantArgs();

    /**
     * Size of the Elastic Inference (EI) instance to use for the production variant.
     * 
     */
    @Import(name="acceleratorType")
    private @Nullable Output<String> acceleratorType;

    /**
     * @return Size of the Elastic Inference (EI) instance to use for the production variant.
     * 
     */
    public Optional<Output<String>> acceleratorType() {
        return Optional.ofNullable(this.acceleratorType);
    }

    /**
     * Timeout value, in seconds, for your inference container to pass health check by SageMaker AI Hosting. For more information about health check, see [How Your Container Should Respond to Health Check (Ping) Requests](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests). Valid values between `60` and `3600`.
     * 
     */
    @Import(name="containerStartupHealthCheckTimeoutInSeconds")
    private @Nullable Output<Integer> containerStartupHealthCheckTimeoutInSeconds;

    /**
     * @return Timeout value, in seconds, for your inference container to pass health check by SageMaker AI Hosting. For more information about health check, see [How Your Container Should Respond to Health Check (Ping) Requests](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests). Valid values between `60` and `3600`.
     * 
     */
    public Optional<Output<Integer>> containerStartupHealthCheckTimeoutInSeconds() {
        return Optional.ofNullable(this.containerStartupHealthCheckTimeoutInSeconds);
    }

    /**
     * Core dump configuration from the model container when the process crashes. Fields are documented below.
     * 
     */
    @Import(name="coreDumpConfig")
    private @Nullable Output<EndpointConfigurationShadowProductionVariantCoreDumpConfigArgs> coreDumpConfig;

    /**
     * @return Core dump configuration from the model container when the process crashes. Fields are documented below.
     * 
     */
    public Optional<Output<EndpointConfigurationShadowProductionVariantCoreDumpConfigArgs>> coreDumpConfig() {
        return Optional.ofNullable(this.coreDumpConfig);
    }

    /**
     * Whether to turn on native AWS SSM access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind endpoints. Ignored if `modelName` is not set (Inference Components endpoint).
     * 
     */
    @Import(name="enableSsmAccess")
    private @Nullable Output<Boolean> enableSsmAccess;

    /**
     * @return Whether to turn on native AWS SSM access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind endpoints. Ignored if `modelName` is not set (Inference Components endpoint).
     * 
     */
    public Optional<Output<Boolean>> enableSsmAccess() {
        return Optional.ofNullable(this.enableSsmAccess);
    }

    /**
     * Option from a collection of preconfigured AMI images. Each image is configured by AWS with a set of software and driver versions. AWS optimizes these configurations for different machine learning workloads.
     * 
     */
    @Import(name="inferenceAmiVersion")
    private @Nullable Output<String> inferenceAmiVersion;

    /**
     * @return Option from a collection of preconfigured AMI images. Each image is configured by AWS with a set of software and driver versions. AWS optimizes these configurations for different machine learning workloads.
     * 
     */
    public Optional<Output<String>> inferenceAmiVersion() {
        return Optional.ofNullable(this.inferenceAmiVersion);
    }

    /**
     * Initial number of instances used for auto-scaling.
     * 
     */
    @Import(name="initialInstanceCount")
    private @Nullable Output<Integer> initialInstanceCount;

    /**
     * @return Initial number of instances used for auto-scaling.
     * 
     */
    public Optional<Output<Integer>> initialInstanceCount() {
        return Optional.ofNullable(this.initialInstanceCount);
    }

    /**
     * Initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, defaults to `1.0`. Ignored if `modelName` is not set (Inference Components endpoint).
     * 
     */
    @Import(name="initialVariantWeight")
    private @Nullable Output<Double> initialVariantWeight;

    /**
     * @return Initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, defaults to `1.0`. Ignored if `modelName` is not set (Inference Components endpoint).
     * 
     */
    public Optional<Output<Double>> initialVariantWeight() {
        return Optional.ofNullable(this.initialVariantWeight);
    }

    /**
     * Type of instance to start.
     * 
     */
    @Import(name="instanceType")
    private @Nullable Output<String> instanceType;

    /**
     * @return Type of instance to start.
     * 
     */
    public Optional<Output<String>> instanceType() {
        return Optional.ofNullable(this.instanceType);
    }

    /**
     * Control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
     * 
     */
    @Import(name="managedInstanceScaling")
    private @Nullable Output<EndpointConfigurationShadowProductionVariantManagedInstanceScalingArgs> managedInstanceScaling;

    /**
     * @return Control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
     * 
     */
    public Optional<Output<EndpointConfigurationShadowProductionVariantManagedInstanceScalingArgs>> managedInstanceScaling() {
        return Optional.ofNullable(this.managedInstanceScaling);
    }

    /**
     * Timeout value, in seconds, to download and extract the model that you want to host from S3 to the individual inference instance associated with this production variant. Valid values between `60` and `3600`.
     * 
     */
    @Import(name="modelDataDownloadTimeoutInSeconds")
    private @Nullable Output<Integer> modelDataDownloadTimeoutInSeconds;

    /**
     * @return Timeout value, in seconds, to download and extract the model that you want to host from S3 to the individual inference instance associated with this production variant. Valid values between `60` and `3600`.
     * 
     */
    public Optional<Output<Integer>> modelDataDownloadTimeoutInSeconds() {
        return Optional.ofNullable(this.modelDataDownloadTimeoutInSeconds);
    }

    /**
     * Name of the model to use. Required unless using Inference Components (in which case `executionRoleArn` must be specified at the endpoint configuration level).
     * 
     */
    @Import(name="modelName")
    private @Nullable Output<String> modelName;

    /**
     * @return Name of the model to use. Required unless using Inference Components (in which case `executionRoleArn` must be specified at the endpoint configuration level).
     * 
     */
    public Optional<Output<String>> modelName() {
        return Optional.ofNullable(this.modelName);
    }

    /**
     * How the endpoint routes incoming traffic. See routingConfig below.
     * 
     */
    @Import(name="routingConfigs")
    private @Nullable Output<List<EndpointConfigurationShadowProductionVariantRoutingConfigArgs>> routingConfigs;

    /**
     * @return How the endpoint routes incoming traffic. See routingConfig below.
     * 
     */
    public Optional<Output<List<EndpointConfigurationShadowProductionVariantRoutingConfigArgs>>> routingConfigs() {
        return Optional.ofNullable(this.routingConfigs);
    }

    /**
     * How an endpoint performs asynchronous inference.
     * 
     */
    @Import(name="serverlessConfig")
    private @Nullable Output<EndpointConfigurationShadowProductionVariantServerlessConfigArgs> serverlessConfig;

    /**
     * @return How an endpoint performs asynchronous inference.
     * 
     */
    public Optional<Output<EndpointConfigurationShadowProductionVariantServerlessConfigArgs>> serverlessConfig() {
        return Optional.ofNullable(this.serverlessConfig);
    }

    /**
     * Name of the variant. If omitted, the provider will assign a random, unique name.
     * 
     */
    @Import(name="variantName")
    private @Nullable Output<String> variantName;

    /**
     * @return Name of the variant. If omitted, the provider will assign a random, unique name.
     * 
     */
    public Optional<Output<String>> variantName() {
        return Optional.ofNullable(this.variantName);
    }

    /**
     * Size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between `1` and `512`.
     * 
     */
    @Import(name="volumeSizeInGb")
    private @Nullable Output<Integer> volumeSizeInGb;

    /**
     * @return Size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between `1` and `512`.
     * 
     */
    public Optional<Output<Integer>> volumeSizeInGb() {
        return Optional.ofNullable(this.volumeSizeInGb);
    }

    private EndpointConfigurationShadowProductionVariantArgs() {}

    private EndpointConfigurationShadowProductionVariantArgs(EndpointConfigurationShadowProductionVariantArgs $) {
        this.acceleratorType = $.acceleratorType;
        this.containerStartupHealthCheckTimeoutInSeconds = $.containerStartupHealthCheckTimeoutInSeconds;
        this.coreDumpConfig = $.coreDumpConfig;
        this.enableSsmAccess = $.enableSsmAccess;
        this.inferenceAmiVersion = $.inferenceAmiVersion;
        this.initialInstanceCount = $.initialInstanceCount;
        this.initialVariantWeight = $.initialVariantWeight;
        this.instanceType = $.instanceType;
        this.managedInstanceScaling = $.managedInstanceScaling;
        this.modelDataDownloadTimeoutInSeconds = $.modelDataDownloadTimeoutInSeconds;
        this.modelName = $.modelName;
        this.routingConfigs = $.routingConfigs;
        this.serverlessConfig = $.serverlessConfig;
        this.variantName = $.variantName;
        this.volumeSizeInGb = $.volumeSizeInGb;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(EndpointConfigurationShadowProductionVariantArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private EndpointConfigurationShadowProductionVariantArgs $;

        public Builder() {
            $ = new EndpointConfigurationShadowProductionVariantArgs();
        }

        public Builder(EndpointConfigurationShadowProductionVariantArgs defaults) {
            $ = new EndpointConfigurationShadowProductionVariantArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param acceleratorType Size of the Elastic Inference (EI) instance to use for the production variant.
         * 
         * @return builder
         * 
         */
        public Builder acceleratorType(@Nullable Output<String> acceleratorType) {
            $.acceleratorType = acceleratorType;
            return this;
        }

        /**
         * @param acceleratorType Size of the Elastic Inference (EI) instance to use for the production variant.
         * 
         * @return builder
         * 
         */
        public Builder acceleratorType(String acceleratorType) {
            return acceleratorType(Output.of(acceleratorType));
        }

        /**
         * @param containerStartupHealthCheckTimeoutInSeconds Timeout value, in seconds, for your inference container to pass health check by SageMaker AI Hosting. For more information about health check, see [How Your Container Should Respond to Health Check (Ping) Requests](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests). Valid values between `60` and `3600`.
         * 
         * @return builder
         * 
         */
        public Builder containerStartupHealthCheckTimeoutInSeconds(@Nullable Output<Integer> containerStartupHealthCheckTimeoutInSeconds) {
            $.containerStartupHealthCheckTimeoutInSeconds = containerStartupHealthCheckTimeoutInSeconds;
            return this;
        }

        /**
         * @param containerStartupHealthCheckTimeoutInSeconds Timeout value, in seconds, for your inference container to pass health check by SageMaker AI Hosting. For more information about health check, see [How Your Container Should Respond to Health Check (Ping) Requests](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests). Valid values between `60` and `3600`.
         * 
         * @return builder
         * 
         */
        public Builder containerStartupHealthCheckTimeoutInSeconds(Integer containerStartupHealthCheckTimeoutInSeconds) {
            return containerStartupHealthCheckTimeoutInSeconds(Output.of(containerStartupHealthCheckTimeoutInSeconds));
        }

        /**
         * @param coreDumpConfig Core dump configuration from the model container when the process crashes. Fields are documented below.
         * 
         * @return builder
         * 
         */
        public Builder coreDumpConfig(@Nullable Output<EndpointConfigurationShadowProductionVariantCoreDumpConfigArgs> coreDumpConfig) {
            $.coreDumpConfig = coreDumpConfig;
            return this;
        }

        /**
         * @param coreDumpConfig Core dump configuration from the model container when the process crashes. Fields are documented below.
         * 
         * @return builder
         * 
         */
        public Builder coreDumpConfig(EndpointConfigurationShadowProductionVariantCoreDumpConfigArgs coreDumpConfig) {
            return coreDumpConfig(Output.of(coreDumpConfig));
        }

        /**
         * @param enableSsmAccess Whether to turn on native AWS SSM access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind endpoints. Ignored if `modelName` is not set (Inference Components endpoint).
         * 
         * @return builder
         * 
         */
        public Builder enableSsmAccess(@Nullable Output<Boolean> enableSsmAccess) {
            $.enableSsmAccess = enableSsmAccess;
            return this;
        }

        /**
         * @param enableSsmAccess Whether to turn on native AWS SSM access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind endpoints. Ignored if `modelName` is not set (Inference Components endpoint).
         * 
         * @return builder
         * 
         */
        public Builder enableSsmAccess(Boolean enableSsmAccess) {
            return enableSsmAccess(Output.of(enableSsmAccess));
        }

        /**
         * @param inferenceAmiVersion Option from a collection of preconfigured AMI images. Each image is configured by AWS with a set of software and driver versions. AWS optimizes these configurations for different machine learning workloads.
         * 
         * @return builder
         * 
         */
        public Builder inferenceAmiVersion(@Nullable Output<String> inferenceAmiVersion) {
            $.inferenceAmiVersion = inferenceAmiVersion;
            return this;
        }

        /**
         * @param inferenceAmiVersion Option from a collection of preconfigured AMI images. Each image is configured by AWS with a set of software and driver versions. AWS optimizes these configurations for different machine learning workloads.
         * 
         * @return builder
         * 
         */
        public Builder inferenceAmiVersion(String inferenceAmiVersion) {
            return inferenceAmiVersion(Output.of(inferenceAmiVersion));
        }

        /**
         * @param initialInstanceCount Initial number of instances used for auto-scaling.
         * 
         * @return builder
         * 
         */
        public Builder initialInstanceCount(@Nullable Output<Integer> initialInstanceCount) {
            $.initialInstanceCount = initialInstanceCount;
            return this;
        }

        /**
         * @param initialInstanceCount Initial number of instances used for auto-scaling.
         * 
         * @return builder
         * 
         */
        public Builder initialInstanceCount(Integer initialInstanceCount) {
            return initialInstanceCount(Output.of(initialInstanceCount));
        }

        /**
         * @param initialVariantWeight Initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, defaults to `1.0`. Ignored if `modelName` is not set (Inference Components endpoint).
         * 
         * @return builder
         * 
         */
        public Builder initialVariantWeight(@Nullable Output<Double> initialVariantWeight) {
            $.initialVariantWeight = initialVariantWeight;
            return this;
        }

        /**
         * @param initialVariantWeight Initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, defaults to `1.0`. Ignored if `modelName` is not set (Inference Components endpoint).
         * 
         * @return builder
         * 
         */
        public Builder initialVariantWeight(Double initialVariantWeight) {
            return initialVariantWeight(Output.of(initialVariantWeight));
        }

        /**
         * @param instanceType Type of instance to start.
         * 
         * @return builder
         * 
         */
        public Builder instanceType(@Nullable Output<String> instanceType) {
            $.instanceType = instanceType;
            return this;
        }

        /**
         * @param instanceType Type of instance to start.
         * 
         * @return builder
         * 
         */
        public Builder instanceType(String instanceType) {
            return instanceType(Output.of(instanceType));
        }

        /**
         * @param managedInstanceScaling Control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
         * 
         * @return builder
         * 
         */
        public Builder managedInstanceScaling(@Nullable Output<EndpointConfigurationShadowProductionVariantManagedInstanceScalingArgs> managedInstanceScaling) {
            $.managedInstanceScaling = managedInstanceScaling;
            return this;
        }

        /**
         * @param managedInstanceScaling Control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
         * 
         * @return builder
         * 
         */
        public Builder managedInstanceScaling(EndpointConfigurationShadowProductionVariantManagedInstanceScalingArgs managedInstanceScaling) {
            return managedInstanceScaling(Output.of(managedInstanceScaling));
        }

        /**
         * @param modelDataDownloadTimeoutInSeconds Timeout value, in seconds, to download and extract the model that you want to host from S3 to the individual inference instance associated with this production variant. Valid values between `60` and `3600`.
         * 
         * @return builder
         * 
         */
        public Builder modelDataDownloadTimeoutInSeconds(@Nullable Output<Integer> modelDataDownloadTimeoutInSeconds) {
            $.modelDataDownloadTimeoutInSeconds = modelDataDownloadTimeoutInSeconds;
            return this;
        }

        /**
         * @param modelDataDownloadTimeoutInSeconds Timeout value, in seconds, to download and extract the model that you want to host from S3 to the individual inference instance associated with this production variant. Valid values between `60` and `3600`.
         * 
         * @return builder
         * 
         */
        public Builder modelDataDownloadTimeoutInSeconds(Integer modelDataDownloadTimeoutInSeconds) {
            return modelDataDownloadTimeoutInSeconds(Output.of(modelDataDownloadTimeoutInSeconds));
        }

        /**
         * @param modelName Name of the model to use. Required unless using Inference Components (in which case `executionRoleArn` must be specified at the endpoint configuration level).
         * 
         * @return builder
         * 
         */
        public Builder modelName(@Nullable Output<String> modelName) {
            $.modelName = modelName;
            return this;
        }

        /**
         * @param modelName Name of the model to use. Required unless using Inference Components (in which case `executionRoleArn` must be specified at the endpoint configuration level).
         * 
         * @return builder
         * 
         */
        public Builder modelName(String modelName) {
            return modelName(Output.of(modelName));
        }

        /**
         * @param routingConfigs How the endpoint routes incoming traffic. See routingConfig below.
         * 
         * @return builder
         * 
         */
        public Builder routingConfigs(@Nullable Output<List<EndpointConfigurationShadowProductionVariantRoutingConfigArgs>> routingConfigs) {
            $.routingConfigs = routingConfigs;
            return this;
        }

        /**
         * @param routingConfigs How the endpoint routes incoming traffic. See routingConfig below.
         * 
         * @return builder
         * 
         */
        public Builder routingConfigs(List<EndpointConfigurationShadowProductionVariantRoutingConfigArgs> routingConfigs) {
            return routingConfigs(Output.of(routingConfigs));
        }

        /**
         * @param routingConfigs How the endpoint routes incoming traffic. See routingConfig below.
         * 
         * @return builder
         * 
         */
        public Builder routingConfigs(EndpointConfigurationShadowProductionVariantRoutingConfigArgs... routingConfigs) {
            return routingConfigs(List.of(routingConfigs));
        }

        /**
         * @param serverlessConfig How an endpoint performs asynchronous inference.
         * 
         * @return builder
         * 
         */
        public Builder serverlessConfig(@Nullable Output<EndpointConfigurationShadowProductionVariantServerlessConfigArgs> serverlessConfig) {
            $.serverlessConfig = serverlessConfig;
            return this;
        }

        /**
         * @param serverlessConfig How an endpoint performs asynchronous inference.
         * 
         * @return builder
         * 
         */
        public Builder serverlessConfig(EndpointConfigurationShadowProductionVariantServerlessConfigArgs serverlessConfig) {
            return serverlessConfig(Output.of(serverlessConfig));
        }

        /**
         * @param variantName Name of the variant. If omitted, the provider will assign a random, unique name.
         * 
         * @return builder
         * 
         */
        public Builder variantName(@Nullable Output<String> variantName) {
            $.variantName = variantName;
            return this;
        }

        /**
         * @param variantName Name of the variant. If omitted, the provider will assign a random, unique name.
         * 
         * @return builder
         * 
         */
        public Builder variantName(String variantName) {
            return variantName(Output.of(variantName));
        }

        /**
         * @param volumeSizeInGb Size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between `1` and `512`.
         * 
         * @return builder
         * 
         */
        public Builder volumeSizeInGb(@Nullable Output<Integer> volumeSizeInGb) {
            $.volumeSizeInGb = volumeSizeInGb;
            return this;
        }

        /**
         * @param volumeSizeInGb Size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between `1` and `512`.
         * 
         * @return builder
         * 
         */
        public Builder volumeSizeInGb(Integer volumeSizeInGb) {
            return volumeSizeInGb(Output.of(volumeSizeInGb));
        }

        public EndpointConfigurationShadowProductionVariantArgs build() {
            return $;
        }
    }

}
