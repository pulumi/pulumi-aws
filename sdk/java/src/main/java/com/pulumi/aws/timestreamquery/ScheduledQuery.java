// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.timestreamquery;

import com.pulumi.aws.Utilities;
import com.pulumi.aws.timestreamquery.ScheduledQueryArgs;
import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryState;
import com.pulumi.aws.timestreamquery.outputs.ScheduledQueryErrorReportConfiguration;
import com.pulumi.aws.timestreamquery.outputs.ScheduledQueryLastRunSummary;
import com.pulumi.aws.timestreamquery.outputs.ScheduledQueryNotificationConfiguration;
import com.pulumi.aws.timestreamquery.outputs.ScheduledQueryRecentlyFailedRun;
import com.pulumi.aws.timestreamquery.outputs.ScheduledQueryScheduleConfiguration;
import com.pulumi.aws.timestreamquery.outputs.ScheduledQueryTargetConfiguration;
import com.pulumi.aws.timestreamquery.outputs.ScheduledQueryTimeouts;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * Resource for managing an AWS Timestream Query Scheduled Query.
 * 
 * ## Example Usage
 * 
 * ### Basic Usage
 * 
 * Before creating a scheduled query, you must have a source database and table with ingested data. Below is a multi-step example, providing an opportunity for data ingestion.
 * 
 * If your infrastructure is already set up—including the source database and table with data, results database and table, error report S3 bucket, SNS topic, and IAM role—you can create a scheduled query as follows:
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.timestreamquery.ScheduledQuery;
 * import com.pulumi.aws.timestreamquery.ScheduledQueryArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryErrorReportConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryErrorReportConfigurationS3ConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryNotificationConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryNotificationConfigurationSnsConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryScheduleConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryTargetConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryTargetConfigurationTimestreamConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new ScheduledQuery("example", ScheduledQueryArgs.builder()
 *             .executionRoleArn(exampleAwsIamRole.arn())
 *             .name(exampleAwsTimestreamwriteTable.tableName())
 *             .queryString("""
 * SELECT region, az, hostname, BIN(time, 15s) AS binned_timestamp,
 * 	ROUND(AVG(cpu_utilization), 2) AS avg_cpu_utilization,
 * 	ROUND(APPROX_PERCENTILE(cpu_utilization, 0.9), 2) AS p90_cpu_utilization,
 * 	ROUND(APPROX_PERCENTILE(cpu_utilization, 0.95), 2) AS p95_cpu_utilization,
 * 	ROUND(APPROX_PERCENTILE(cpu_utilization, 0.99), 2) AS p99_cpu_utilization
 * FROM exampledatabase.exampletable
 * WHERE measure_name = 'metrics' AND time > ago(2h)
 * GROUP BY region, hostname, az, BIN(time, 15s)
 * ORDER BY binned_timestamp ASC
 * LIMIT 5
 *             """)
 *             .errorReportConfiguration(ScheduledQueryErrorReportConfigurationArgs.builder()
 *                 .s3Configuration(ScheduledQueryErrorReportConfigurationS3ConfigurationArgs.builder()
 *                     .bucketName(exampleAwsS3Bucket.bucket())
 *                     .build())
 *                 .build())
 *             .notificationConfiguration(ScheduledQueryNotificationConfigurationArgs.builder()
 *                 .snsConfiguration(ScheduledQueryNotificationConfigurationSnsConfigurationArgs.builder()
 *                     .topicArn(exampleAwsSnsTopic.arn())
 *                     .build())
 *                 .build())
 *             .scheduleConfiguration(ScheduledQueryScheduleConfigurationArgs.builder()
 *                 .scheduleExpression("rate(1 hour)")
 *                 .build())
 *             .targetConfiguration(ScheduledQueryTargetConfigurationArgs.builder()
 *                 .timestreamConfiguration(ScheduledQueryTargetConfigurationTimestreamConfigurationArgs.builder()
 *                     .databaseName(results.databaseName())
 *                     .tableName(resultsAwsTimestreamwriteTable.tableName())
 *                     .timeColumn("binned_timestamp")
 *                     .dimensionMappings(                    
 *                         ScheduledQueryTargetConfigurationTimestreamConfigurationDimensionMappingArgs.builder()
 *                             .dimensionValueType("VARCHAR")
 *                             .name("az")
 *                             .build(),
 *                         ScheduledQueryTargetConfigurationTimestreamConfigurationDimensionMappingArgs.builder()
 *                             .dimensionValueType("VARCHAR")
 *                             .name("region")
 *                             .build(),
 *                         ScheduledQueryTargetConfigurationTimestreamConfigurationDimensionMappingArgs.builder()
 *                             .dimensionValueType("VARCHAR")
 *                             .name("hostname")
 *                             .build())
 *                     .multiMeasureMappings(ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsArgs.builder()
 *                         .targetMultiMeasureName("multi-metrics")
 *                         .multiMeasureAttributeMappings(                        
 *                             ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsMultiMeasureAttributeMappingArgs.builder()
 *                                 .measureValueType("DOUBLE")
 *                                 .sourceColumn("avg_cpu_utilization")
 *                                 .build(),
 *                             ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsMultiMeasureAttributeMappingArgs.builder()
 *                                 .measureValueType("DOUBLE")
 *                                 .sourceColumn("p90_cpu_utilization")
 *                                 .build(),
 *                             ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsMultiMeasureAttributeMappingArgs.builder()
 *                                 .measureValueType("DOUBLE")
 *                                 .sourceColumn("p95_cpu_utilization")
 *                                 .build(),
 *                             ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsMultiMeasureAttributeMappingArgs.builder()
 *                                 .measureValueType("DOUBLE")
 *                                 .sourceColumn("p99_cpu_utilization")
 *                                 .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * ### Multi-step Example
 * 
 * To ingest data before creating a scheduled query, this example provides multiple steps:
 * 
 * 1. Create the prerequisite infrastructure
 * 2. Ingest data
 * 3. Create the scheduled query
 * 
 * ### Step 1. Create the prerequisite infrastructure
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.s3.BucketV2;
 * import com.pulumi.aws.s3.BucketV2Args;
 * import com.pulumi.aws.sns.Topic;
 * import com.pulumi.aws.sns.TopicArgs;
 * import com.pulumi.aws.sqs.Queue;
 * import com.pulumi.aws.sqs.QueueArgs;
 * import com.pulumi.aws.sns.TopicSubscription;
 * import com.pulumi.aws.sns.TopicSubscriptionArgs;
 * import com.pulumi.aws.sqs.QueuePolicy;
 * import com.pulumi.aws.sqs.QueuePolicyArgs;
 * import com.pulumi.aws.iam.Role;
 * import com.pulumi.aws.iam.RoleArgs;
 * import com.pulumi.aws.iam.RolePolicy;
 * import com.pulumi.aws.iam.RolePolicyArgs;
 * import com.pulumi.aws.timestreamwrite.Database;
 * import com.pulumi.aws.timestreamwrite.DatabaseArgs;
 * import com.pulumi.aws.timestreamwrite.Table;
 * import com.pulumi.aws.timestreamwrite.TableArgs;
 * import com.pulumi.aws.timestreamwrite.inputs.TableMagneticStoreWritePropertiesArgs;
 * import com.pulumi.aws.timestreamwrite.inputs.TableRetentionPropertiesArgs;
 * import static com.pulumi.codegen.internal.Serialization.*;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var test = new BucketV2("test", BucketV2Args.builder()
 *             .bucket("example")
 *             .forceDestroy(true)
 *             .build());
 * 
 *         var testTopic = new Topic("testTopic", TopicArgs.builder()
 *             .name("example")
 *             .build());
 * 
 *         var testQueue = new Queue("testQueue", QueueArgs.builder()
 *             .name("example")
 *             .sqsManagedSseEnabled(true)
 *             .build());
 * 
 *         var testTopicSubscription = new TopicSubscription("testTopicSubscription", TopicSubscriptionArgs.builder()
 *             .topic(testTopic.arn())
 *             .protocol("sqs")
 *             .endpoint(testQueue.arn())
 *             .build());
 * 
 *         var testQueuePolicy = new QueuePolicy("testQueuePolicy", QueuePolicyArgs.builder()
 *             .queueUrl(testQueue.id())
 *             .policy(Output.tuple(testQueue.arn(), testTopic.arn()).applyValue(values -> {
 *                 var testQueueArn = values.t1;
 *                 var testTopicArn = values.t2;
 *                 return serializeJson(
 *                     jsonObject(
 *                         jsonProperty("Version", "2012-10-17"),
 *                         jsonProperty("Statement", jsonArray(jsonObject(
 *                             jsonProperty("Effect", "Allow"),
 *                             jsonProperty("Principal", jsonObject(
 *                                 jsonProperty("AWS", "*")
 *                             )),
 *                             jsonProperty("Action", jsonArray("sqs:SendMessage")),
 *                             jsonProperty("Resource", testQueueArn),
 *                             jsonProperty("Condition", jsonObject(
 *                                 jsonProperty("ArnEquals", jsonObject(
 *                                     jsonProperty("aws:SourceArn", testTopicArn)
 *                                 ))
 *                             ))
 *                         )))
 *                     ));
 *             }))
 *             .build());
 * 
 *         var testRole = new Role("testRole", RoleArgs.builder()
 *             .name("example")
 *             .assumeRolePolicy(serializeJson(
 *                 jsonObject(
 *                     jsonProperty("Version", "2012-10-17"),
 *                     jsonProperty("Statement", jsonArray(jsonObject(
 *                         jsonProperty("Effect", "Allow"),
 *                         jsonProperty("Principal", jsonObject(
 *                             jsonProperty("Service", "timestream.amazonaws.com")
 *                         )),
 *                         jsonProperty("Action", "sts:AssumeRole")
 *                     )))
 *                 )))
 *             .tags(Map.of("Name", "example"))
 *             .build());
 * 
 *         var testRolePolicy = new RolePolicy("testRolePolicy", RolePolicyArgs.builder()
 *             .name("example")
 *             .role(testRole.id())
 *             .policy(serializeJson(
 *                 jsonObject(
 *                     jsonProperty("Version", "2012-10-17"),
 *                     jsonProperty("Statement", jsonArray(jsonObject(
 *                         jsonProperty("Action", jsonArray(
 *                             "kms:Decrypt", 
 *                             "sns:Publish", 
 *                             "timestream:describeEndpoints", 
 *                             "timestream:Select", 
 *                             "timestream:SelectValues", 
 *                             "timestream:WriteRecords", 
 *                             "s3:PutObject"
 *                         )),
 *                         jsonProperty("Resource", "*"),
 *                         jsonProperty("Effect", "Allow")
 *                     )))
 *                 )))
 *             .build());
 * 
 *         var testDatabase = new Database("testDatabase", DatabaseArgs.builder()
 *             .databaseName("exampledatabase")
 *             .build());
 * 
 *         var testTable = new Table("testTable", TableArgs.builder()
 *             .databaseName(testDatabase.databaseName())
 *             .tableName("exampletable")
 *             .magneticStoreWriteProperties(TableMagneticStoreWritePropertiesArgs.builder()
 *                 .enableMagneticStoreWrites(true)
 *                 .build())
 *             .retentionProperties(TableRetentionPropertiesArgs.builder()
 *                 .magneticStoreRetentionPeriodInDays(1)
 *                 .memoryStoreRetentionPeriodInHours(1)
 *                 .build())
 *             .build());
 * 
 *         var results = new Database("results", DatabaseArgs.builder()
 *             .databaseName("exampledatabase-results")
 *             .build());
 * 
 *         var resultsTable = new Table("resultsTable", TableArgs.builder()
 *             .databaseName(results.databaseName())
 *             .tableName("exampletable-results")
 *             .magneticStoreWriteProperties(TableMagneticStoreWritePropertiesArgs.builder()
 *                 .enableMagneticStoreWrites(true)
 *                 .build())
 *             .retentionProperties(TableRetentionPropertiesArgs.builder()
 *                 .magneticStoreRetentionPeriodInDays(1)
 *                 .memoryStoreRetentionPeriodInHours(1)
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * #### Step 2. Ingest data
 * 
 * This is done with Amazon Timestream Write [WriteRecords](https://docs.aws.amazon.com/timestream/latest/developerguide/API_WriteRecords.html).
 * 
 * ### Step 3. Create the scheduled query
 * 
 * &lt;!--Start PulumiCodeChooser --&gt;
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.timestreamquery.ScheduledQuery;
 * import com.pulumi.aws.timestreamquery.ScheduledQueryArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryErrorReportConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryErrorReportConfigurationS3ConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryNotificationConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryNotificationConfigurationSnsConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryScheduleConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryTargetConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryTargetConfigurationTimestreamConfigurationArgs;
 * import com.pulumi.aws.timestreamquery.inputs.ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new ScheduledQuery("example", ScheduledQueryArgs.builder()
 *             .executionRoleArn(exampleAwsIamRole.arn())
 *             .name(exampleAwsTimestreamwriteTable.tableName())
 *             .queryString("""
 * SELECT region, az, hostname, BIN(time, 15s) AS binned_timestamp,
 * 	ROUND(AVG(cpu_utilization), 2) AS avg_cpu_utilization,
 * 	ROUND(APPROX_PERCENTILE(cpu_utilization, 0.9), 2) AS p90_cpu_utilization,
 * 	ROUND(APPROX_PERCENTILE(cpu_utilization, 0.95), 2) AS p95_cpu_utilization,
 * 	ROUND(APPROX_PERCENTILE(cpu_utilization, 0.99), 2) AS p99_cpu_utilization
 * FROM exampledatabase.exampletable
 * WHERE measure_name = 'metrics' AND time > ago(2h)
 * GROUP BY region, hostname, az, BIN(time, 15s)
 * ORDER BY binned_timestamp ASC
 * LIMIT 5
 *             """)
 *             .errorReportConfiguration(ScheduledQueryErrorReportConfigurationArgs.builder()
 *                 .s3Configuration(ScheduledQueryErrorReportConfigurationS3ConfigurationArgs.builder()
 *                     .bucketName(exampleAwsS3Bucket.bucket())
 *                     .build())
 *                 .build())
 *             .notificationConfiguration(ScheduledQueryNotificationConfigurationArgs.builder()
 *                 .snsConfiguration(ScheduledQueryNotificationConfigurationSnsConfigurationArgs.builder()
 *                     .topicArn(exampleAwsSnsTopic.arn())
 *                     .build())
 *                 .build())
 *             .scheduleConfiguration(ScheduledQueryScheduleConfigurationArgs.builder()
 *                 .scheduleExpression("rate(1 hour)")
 *                 .build())
 *             .targetConfiguration(ScheduledQueryTargetConfigurationArgs.builder()
 *                 .timestreamConfiguration(ScheduledQueryTargetConfigurationTimestreamConfigurationArgs.builder()
 *                     .databaseName(results.databaseName())
 *                     .tableName(resultsAwsTimestreamwriteTable.tableName())
 *                     .timeColumn("binned_timestamp")
 *                     .dimensionMappings(                    
 *                         ScheduledQueryTargetConfigurationTimestreamConfigurationDimensionMappingArgs.builder()
 *                             .dimensionValueType("VARCHAR")
 *                             .name("az")
 *                             .build(),
 *                         ScheduledQueryTargetConfigurationTimestreamConfigurationDimensionMappingArgs.builder()
 *                             .dimensionValueType("VARCHAR")
 *                             .name("region")
 *                             .build(),
 *                         ScheduledQueryTargetConfigurationTimestreamConfigurationDimensionMappingArgs.builder()
 *                             .dimensionValueType("VARCHAR")
 *                             .name("hostname")
 *                             .build())
 *                     .multiMeasureMappings(ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsArgs.builder()
 *                         .targetMultiMeasureName("multi-metrics")
 *                         .multiMeasureAttributeMappings(                        
 *                             ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsMultiMeasureAttributeMappingArgs.builder()
 *                                 .measureValueType("DOUBLE")
 *                                 .sourceColumn("avg_cpu_utilization")
 *                                 .build(),
 *                             ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsMultiMeasureAttributeMappingArgs.builder()
 *                                 .measureValueType("DOUBLE")
 *                                 .sourceColumn("p90_cpu_utilization")
 *                                 .build(),
 *                             ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsMultiMeasureAttributeMappingArgs.builder()
 *                                 .measureValueType("DOUBLE")
 *                                 .sourceColumn("p95_cpu_utilization")
 *                                 .build(),
 *                             ScheduledQueryTargetConfigurationTimestreamConfigurationMultiMeasureMappingsMultiMeasureAttributeMappingArgs.builder()
 *                                 .measureValueType("DOUBLE")
 *                                 .sourceColumn("p99_cpu_utilization")
 *                                 .build())
 *                         .build())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * &lt;!--End PulumiCodeChooser --&gt;
 * 
 * ## Import
 * 
 * Using `pulumi import`, import Timestream Query Scheduled Query using the `arn`. For example:
 * 
 * ```sh
 * $ pulumi import aws:timestreamquery/scheduledQuery:ScheduledQuery example arn:aws:timestream:us-west-2:012345678901:scheduled-query/tf-acc-test-7774188528604787105-e13659544fe66c8d
 * ```
 * 
 */
@ResourceType(type="aws:timestreamquery/scheduledQuery:ScheduledQuery")
public class ScheduledQuery extends com.pulumi.resources.CustomResource {
    /**
     * ARN of the Scheduled Query.
     * 
     */
    @Export(name="arn", refs={String.class}, tree="[0]")
    private Output<String> arn;

    /**
     * @return ARN of the Scheduled Query.
     * 
     */
    public Output<String> arn() {
        return this.arn;
    }
    /**
     * Creation time for the scheduled query.
     * 
     */
    @Export(name="creationTime", refs={String.class}, tree="[0]")
    private Output<String> creationTime;

    /**
     * @return Creation time for the scheduled query.
     * 
     */
    public Output<String> creationTime() {
        return this.creationTime;
    }
    /**
     * Configuration block for error reporting configuration. See below.
     * 
     */
    @Export(name="errorReportConfiguration", refs={ScheduledQueryErrorReportConfiguration.class}, tree="[0]")
    private Output<ScheduledQueryErrorReportConfiguration> errorReportConfiguration;

    /**
     * @return Configuration block for error reporting configuration. See below.
     * 
     */
    public Output<ScheduledQueryErrorReportConfiguration> errorReportConfiguration() {
        return this.errorReportConfiguration;
    }
    /**
     * ARN for the IAM role that Timestream will assume when running the scheduled query.
     * 
     */
    @Export(name="executionRoleArn", refs={String.class}, tree="[0]")
    private Output<String> executionRoleArn;

    /**
     * @return ARN for the IAM role that Timestream will assume when running the scheduled query.
     * 
     */
    public Output<String> executionRoleArn() {
        return this.executionRoleArn;
    }
    /**
     * Amazon KMS key used to encrypt the scheduled query resource, at-rest. If not specified, the scheduled query resource will be encrypted with a Timestream owned Amazon KMS key. To specify a KMS key, use the key ID, key ARN, alias name, or alias ARN. When using an alias name, prefix the name with &#34;alias/&#34;. If `error_report_configuration` uses `SSE_KMS` as the encryption type, the same `kms_key_id` is used to encrypt the error report at rest.
     * 
     */
    @Export(name="kmsKeyId", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> kmsKeyId;

    /**
     * @return Amazon KMS key used to encrypt the scheduled query resource, at-rest. If not specified, the scheduled query resource will be encrypted with a Timestream owned Amazon KMS key. To specify a KMS key, use the key ID, key ARN, alias name, or alias ARN. When using an alias name, prefix the name with &#34;alias/&#34;. If `error_report_configuration` uses `SSE_KMS` as the encryption type, the same `kms_key_id` is used to encrypt the error report at rest.
     * 
     */
    public Output<Optional<String>> kmsKeyId() {
        return Codegen.optional(this.kmsKeyId);
    }
    /**
     * Runtime summary for the last scheduled query run.
     * 
     */
    @Export(name="lastRunSummaries", refs={List.class,ScheduledQueryLastRunSummary.class}, tree="[0,1]")
    private Output</* @Nullable */ List<ScheduledQueryLastRunSummary>> lastRunSummaries;

    /**
     * @return Runtime summary for the last scheduled query run.
     * 
     */
    public Output<Optional<List<ScheduledQueryLastRunSummary>>> lastRunSummaries() {
        return Codegen.optional(this.lastRunSummaries);
    }
    /**
     * Name of the scheduled query.
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return Name of the scheduled query.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * Next time the scheduled query is scheduled to run.
     * 
     */
    @Export(name="nextInvocationTime", refs={String.class}, tree="[0]")
    private Output<String> nextInvocationTime;

    /**
     * @return Next time the scheduled query is scheduled to run.
     * 
     */
    public Output<String> nextInvocationTime() {
        return this.nextInvocationTime;
    }
    /**
     * Configuration block for notification configuration for a scheduled query. A notification is sent by Timestream when a scheduled query is created, its state is updated, or when it is deleted. See below.
     * 
     */
    @Export(name="notificationConfiguration", refs={ScheduledQueryNotificationConfiguration.class}, tree="[0]")
    private Output<ScheduledQueryNotificationConfiguration> notificationConfiguration;

    /**
     * @return Configuration block for notification configuration for a scheduled query. A notification is sent by Timestream when a scheduled query is created, its state is updated, or when it is deleted. See below.
     * 
     */
    public Output<ScheduledQueryNotificationConfiguration> notificationConfiguration() {
        return this.notificationConfiguration;
    }
    /**
     * Last time the scheduled query was run.
     * 
     */
    @Export(name="previousInvocationTime", refs={String.class}, tree="[0]")
    private Output<String> previousInvocationTime;

    /**
     * @return Last time the scheduled query was run.
     * 
     */
    public Output<String> previousInvocationTime() {
        return this.previousInvocationTime;
    }
    /**
     * Query string to run. Parameter names can be specified in the query string using the `{@literal @}` character followed by an identifier. The named parameter `{@literal @}scheduled_runtime` is reserved and can be used in the query to get the time at which the query is scheduled to run. The timestamp calculated according to the `schedule_configuration` parameter, will be the value of `{@literal @}scheduled_runtime` paramater for each query run. For example, consider an instance of a scheduled query executing on 2021-12-01 00:00:00. For this instance, the `{@literal @}scheduled_runtime` parameter is initialized to the timestamp 2021-12-01 00:00:00 when invoking the query.
     * 
     */
    @Export(name="queryString", refs={String.class}, tree="[0]")
    private Output<String> queryString;

    /**
     * @return Query string to run. Parameter names can be specified in the query string using the `{@literal @}` character followed by an identifier. The named parameter `{@literal @}scheduled_runtime` is reserved and can be used in the query to get the time at which the query is scheduled to run. The timestamp calculated according to the `schedule_configuration` parameter, will be the value of `{@literal @}scheduled_runtime` paramater for each query run. For example, consider an instance of a scheduled query executing on 2021-12-01 00:00:00. For this instance, the `{@literal @}scheduled_runtime` parameter is initialized to the timestamp 2021-12-01 00:00:00 when invoking the query.
     * 
     */
    public Output<String> queryString() {
        return this.queryString;
    }
    /**
     * Runtime summary for the last five failed scheduled query runs.
     * 
     */
    @Export(name="recentlyFailedRuns", refs={List.class,ScheduledQueryRecentlyFailedRun.class}, tree="[0,1]")
    private Output</* @Nullable */ List<ScheduledQueryRecentlyFailedRun>> recentlyFailedRuns;

    /**
     * @return Runtime summary for the last five failed scheduled query runs.
     * 
     */
    public Output<Optional<List<ScheduledQueryRecentlyFailedRun>>> recentlyFailedRuns() {
        return Codegen.optional(this.recentlyFailedRuns);
    }
    /**
     * Configuration block for schedule configuration for the query. See below.
     * 
     */
    @Export(name="scheduleConfiguration", refs={ScheduledQueryScheduleConfiguration.class}, tree="[0]")
    private Output<ScheduledQueryScheduleConfiguration> scheduleConfiguration;

    /**
     * @return Configuration block for schedule configuration for the query. See below.
     * 
     */
    public Output<ScheduledQueryScheduleConfiguration> scheduleConfiguration() {
        return this.scheduleConfiguration;
    }
    /**
     * State of the scheduled query, either `ENABLED` or `DISABLED`.
     * 
     */
    @Export(name="state", refs={String.class}, tree="[0]")
    private Output<String> state;

    /**
     * @return State of the scheduled query, either `ENABLED` or `DISABLED`.
     * 
     */
    public Output<String> state() {
        return this.state;
    }
    /**
     * Map of tags assigned to the resource. If configured with a provider `default_tags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
     * 
     */
    @Export(name="tags", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> tags;

    /**
     * @return Map of tags assigned to the resource. If configured with a provider `default_tags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
     * 
     */
    public Output<Optional<Map<String,String>>> tags() {
        return Codegen.optional(this.tags);
    }
    /**
     * Map of tags assigned to the resource, including those inherited from the provider `default_tags` configuration block.
     * 
     * @deprecated
     * Please use `tags` instead.
     * 
     */
    @Deprecated /* Please use `tags` instead. */
    @Export(name="tagsAll", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> tagsAll;

    /**
     * @return Map of tags assigned to the resource, including those inherited from the provider `default_tags` configuration block.
     * 
     */
    public Output<Map<String,String>> tagsAll() {
        return this.tagsAll;
    }
    /**
     * Configuration block for writing the result of a query. See below.
     * 
     * The following arguments are optional:
     * 
     */
    @Export(name="targetConfiguration", refs={ScheduledQueryTargetConfiguration.class}, tree="[0]")
    private Output<ScheduledQueryTargetConfiguration> targetConfiguration;

    /**
     * @return Configuration block for writing the result of a query. See below.
     * 
     * The following arguments are optional:
     * 
     */
    public Output<ScheduledQueryTargetConfiguration> targetConfiguration() {
        return this.targetConfiguration;
    }
    @Export(name="timeouts", refs={ScheduledQueryTimeouts.class}, tree="[0]")
    private Output</* @Nullable */ ScheduledQueryTimeouts> timeouts;

    public Output<Optional<ScheduledQueryTimeouts>> timeouts() {
        return Codegen.optional(this.timeouts);
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public ScheduledQuery(java.lang.String name) {
        this(name, ScheduledQueryArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public ScheduledQuery(java.lang.String name, ScheduledQueryArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public ScheduledQuery(java.lang.String name, ScheduledQueryArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("aws:timestreamquery/scheduledQuery:ScheduledQuery", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private ScheduledQuery(java.lang.String name, Output<java.lang.String> id, @Nullable ScheduledQueryState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("aws:timestreamquery/scheduledQuery:ScheduledQuery", name, state, makeResourceOptions(options, id), false);
    }

    private static ScheduledQueryArgs makeArgs(ScheduledQueryArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? ScheduledQueryArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static ScheduledQuery get(java.lang.String name, Output<java.lang.String> id, @Nullable ScheduledQueryState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new ScheduledQuery(name, id, state, options);
    }
}
