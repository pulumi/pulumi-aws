// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.kinesis.inputs;

import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import java.lang.Boolean;
import java.lang.Double;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs extends com.pulumi.resources.ResourceArgs {

    public static final FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs Empty = new FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs();

    /**
     * The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.
     * 
     */
    @Import(name="blockSizeBytes")
    private @Nullable Output<Integer> blockSizeBytes;

    /**
     * @return The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.
     * 
     */
    public Optional<Output<Integer>> blockSizeBytes() {
        return Optional.ofNullable(this.blockSizeBytes);
    }

    /**
     * A list of column names for which you want Kinesis Data Firehose to create bloom filters.
     * 
     */
    @Import(name="bloomFilterColumns")
    private @Nullable Output<List<String>> bloomFilterColumns;

    /**
     * @return A list of column names for which you want Kinesis Data Firehose to create bloom filters.
     * 
     */
    public Optional<Output<List<String>>> bloomFilterColumns() {
        return Optional.ofNullable(this.bloomFilterColumns);
    }

    /**
     * The Bloom filter false positive probability (FPP). The lower the FPP, the bigger the Bloom filter. The default value is `0.05`, the minimum is `0`, and the maximum is `1`.
     * 
     */
    @Import(name="bloomFilterFalsePositiveProbability")
    private @Nullable Output<Double> bloomFilterFalsePositiveProbability;

    /**
     * @return The Bloom filter false positive probability (FPP). The lower the FPP, the bigger the Bloom filter. The default value is `0.05`, the minimum is `0`, and the maximum is `1`.
     * 
     */
    public Optional<Output<Double>> bloomFilterFalsePositiveProbability() {
        return Optional.ofNullable(this.bloomFilterFalsePositiveProbability);
    }

    /**
     * The compression code to use over data blocks. The default is `SNAPPY`.
     * 
     */
    @Import(name="compression")
    private @Nullable Output<String> compression;

    /**
     * @return The compression code to use over data blocks. The default is `SNAPPY`.
     * 
     */
    public Optional<Output<String>> compression() {
        return Optional.ofNullable(this.compression);
    }

    /**
     * A float that represents the fraction of the total number of non-null rows. To turn off dictionary encoding, set this fraction to a number that is less than the number of distinct keys in a dictionary. To always use dictionary encoding, set this threshold to `1`.
     * 
     */
    @Import(name="dictionaryKeyThreshold")
    private @Nullable Output<Double> dictionaryKeyThreshold;

    /**
     * @return A float that represents the fraction of the total number of non-null rows. To turn off dictionary encoding, set this fraction to a number that is less than the number of distinct keys in a dictionary. To always use dictionary encoding, set this threshold to `1`.
     * 
     */
    public Optional<Output<Double>> dictionaryKeyThreshold() {
        return Optional.ofNullable(this.dictionaryKeyThreshold);
    }

    /**
     * Set this to `true` to indicate that you want stripes to be padded to the HDFS block boundaries. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is `false`.
     * 
     */
    @Import(name="enablePadding")
    private @Nullable Output<Boolean> enablePadding;

    /**
     * @return Set this to `true` to indicate that you want stripes to be padded to the HDFS block boundaries. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is `false`.
     * 
     */
    public Optional<Output<Boolean>> enablePadding() {
        return Optional.ofNullable(this.enablePadding);
    }

    /**
     * The version of the file to write. The possible values are `V0_11` and `V0_12`. The default is `V0_12`.
     * 
     */
    @Import(name="formatVersion")
    private @Nullable Output<String> formatVersion;

    /**
     * @return The version of the file to write. The possible values are `V0_11` and `V0_12`. The default is `V0_12`.
     * 
     */
    public Optional<Output<String>> formatVersion() {
        return Optional.ofNullable(this.formatVersion);
    }

    /**
     * A float between 0 and 1 that defines the tolerance for block padding as a decimal fraction of stripe size. The default value is `0.05`, which means 5 percent of stripe size. For the default values of 64 MiB ORC stripes and 256 MiB HDFS blocks, the default block padding tolerance of 5 percent reserves a maximum of 3.2 MiB for padding within the 256 MiB block. In such a case, if the available size within the block is more than 3.2 MiB, a new, smaller stripe is inserted to fit within that space. This ensures that no stripe crosses block boundaries and causes remote reads within a node-local task. Kinesis Data Firehose ignores this parameter when `enable_padding` is `false`.
     * 
     */
    @Import(name="paddingTolerance")
    private @Nullable Output<Double> paddingTolerance;

    /**
     * @return A float between 0 and 1 that defines the tolerance for block padding as a decimal fraction of stripe size. The default value is `0.05`, which means 5 percent of stripe size. For the default values of 64 MiB ORC stripes and 256 MiB HDFS blocks, the default block padding tolerance of 5 percent reserves a maximum of 3.2 MiB for padding within the 256 MiB block. In such a case, if the available size within the block is more than 3.2 MiB, a new, smaller stripe is inserted to fit within that space. This ensures that no stripe crosses block boundaries and causes remote reads within a node-local task. Kinesis Data Firehose ignores this parameter when `enable_padding` is `false`.
     * 
     */
    public Optional<Output<Double>> paddingTolerance() {
        return Optional.ofNullable(this.paddingTolerance);
    }

    /**
     * The number of rows between index entries. The default is `10000` and the minimum is `1000`.
     * 
     */
    @Import(name="rowIndexStride")
    private @Nullable Output<Integer> rowIndexStride;

    /**
     * @return The number of rows between index entries. The default is `10000` and the minimum is `1000`.
     * 
     */
    public Optional<Output<Integer>> rowIndexStride() {
        return Optional.ofNullable(this.rowIndexStride);
    }

    /**
     * The number of bytes in each stripe. The default is 64 MiB and the minimum is 8 MiB.
     * 
     */
    @Import(name="stripeSizeBytes")
    private @Nullable Output<Integer> stripeSizeBytes;

    /**
     * @return The number of bytes in each stripe. The default is 64 MiB and the minimum is 8 MiB.
     * 
     */
    public Optional<Output<Integer>> stripeSizeBytes() {
        return Optional.ofNullable(this.stripeSizeBytes);
    }

    private FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs() {}

    private FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs(FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs $) {
        this.blockSizeBytes = $.blockSizeBytes;
        this.bloomFilterColumns = $.bloomFilterColumns;
        this.bloomFilterFalsePositiveProbability = $.bloomFilterFalsePositiveProbability;
        this.compression = $.compression;
        this.dictionaryKeyThreshold = $.dictionaryKeyThreshold;
        this.enablePadding = $.enablePadding;
        this.formatVersion = $.formatVersion;
        this.paddingTolerance = $.paddingTolerance;
        this.rowIndexStride = $.rowIndexStride;
        this.stripeSizeBytes = $.stripeSizeBytes;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs $;

        public Builder() {
            $ = new FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs();
        }

        public Builder(FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs defaults) {
            $ = new FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param blockSizeBytes The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.
         * 
         * @return builder
         * 
         */
        public Builder blockSizeBytes(@Nullable Output<Integer> blockSizeBytes) {
            $.blockSizeBytes = blockSizeBytes;
            return this;
        }

        /**
         * @param blockSizeBytes The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.
         * 
         * @return builder
         * 
         */
        public Builder blockSizeBytes(Integer blockSizeBytes) {
            return blockSizeBytes(Output.of(blockSizeBytes));
        }

        /**
         * @param bloomFilterColumns A list of column names for which you want Kinesis Data Firehose to create bloom filters.
         * 
         * @return builder
         * 
         */
        public Builder bloomFilterColumns(@Nullable Output<List<String>> bloomFilterColumns) {
            $.bloomFilterColumns = bloomFilterColumns;
            return this;
        }

        /**
         * @param bloomFilterColumns A list of column names for which you want Kinesis Data Firehose to create bloom filters.
         * 
         * @return builder
         * 
         */
        public Builder bloomFilterColumns(List<String> bloomFilterColumns) {
            return bloomFilterColumns(Output.of(bloomFilterColumns));
        }

        /**
         * @param bloomFilterColumns A list of column names for which you want Kinesis Data Firehose to create bloom filters.
         * 
         * @return builder
         * 
         */
        public Builder bloomFilterColumns(String... bloomFilterColumns) {
            return bloomFilterColumns(List.of(bloomFilterColumns));
        }

        /**
         * @param bloomFilterFalsePositiveProbability The Bloom filter false positive probability (FPP). The lower the FPP, the bigger the Bloom filter. The default value is `0.05`, the minimum is `0`, and the maximum is `1`.
         * 
         * @return builder
         * 
         */
        public Builder bloomFilterFalsePositiveProbability(@Nullable Output<Double> bloomFilterFalsePositiveProbability) {
            $.bloomFilterFalsePositiveProbability = bloomFilterFalsePositiveProbability;
            return this;
        }

        /**
         * @param bloomFilterFalsePositiveProbability The Bloom filter false positive probability (FPP). The lower the FPP, the bigger the Bloom filter. The default value is `0.05`, the minimum is `0`, and the maximum is `1`.
         * 
         * @return builder
         * 
         */
        public Builder bloomFilterFalsePositiveProbability(Double bloomFilterFalsePositiveProbability) {
            return bloomFilterFalsePositiveProbability(Output.of(bloomFilterFalsePositiveProbability));
        }

        /**
         * @param compression The compression code to use over data blocks. The default is `SNAPPY`.
         * 
         * @return builder
         * 
         */
        public Builder compression(@Nullable Output<String> compression) {
            $.compression = compression;
            return this;
        }

        /**
         * @param compression The compression code to use over data blocks. The default is `SNAPPY`.
         * 
         * @return builder
         * 
         */
        public Builder compression(String compression) {
            return compression(Output.of(compression));
        }

        /**
         * @param dictionaryKeyThreshold A float that represents the fraction of the total number of non-null rows. To turn off dictionary encoding, set this fraction to a number that is less than the number of distinct keys in a dictionary. To always use dictionary encoding, set this threshold to `1`.
         * 
         * @return builder
         * 
         */
        public Builder dictionaryKeyThreshold(@Nullable Output<Double> dictionaryKeyThreshold) {
            $.dictionaryKeyThreshold = dictionaryKeyThreshold;
            return this;
        }

        /**
         * @param dictionaryKeyThreshold A float that represents the fraction of the total number of non-null rows. To turn off dictionary encoding, set this fraction to a number that is less than the number of distinct keys in a dictionary. To always use dictionary encoding, set this threshold to `1`.
         * 
         * @return builder
         * 
         */
        public Builder dictionaryKeyThreshold(Double dictionaryKeyThreshold) {
            return dictionaryKeyThreshold(Output.of(dictionaryKeyThreshold));
        }

        /**
         * @param enablePadding Set this to `true` to indicate that you want stripes to be padded to the HDFS block boundaries. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is `false`.
         * 
         * @return builder
         * 
         */
        public Builder enablePadding(@Nullable Output<Boolean> enablePadding) {
            $.enablePadding = enablePadding;
            return this;
        }

        /**
         * @param enablePadding Set this to `true` to indicate that you want stripes to be padded to the HDFS block boundaries. This is useful if you intend to copy the data from Amazon S3 to HDFS before querying. The default is `false`.
         * 
         * @return builder
         * 
         */
        public Builder enablePadding(Boolean enablePadding) {
            return enablePadding(Output.of(enablePadding));
        }

        /**
         * @param formatVersion The version of the file to write. The possible values are `V0_11` and `V0_12`. The default is `V0_12`.
         * 
         * @return builder
         * 
         */
        public Builder formatVersion(@Nullable Output<String> formatVersion) {
            $.formatVersion = formatVersion;
            return this;
        }

        /**
         * @param formatVersion The version of the file to write. The possible values are `V0_11` and `V0_12`. The default is `V0_12`.
         * 
         * @return builder
         * 
         */
        public Builder formatVersion(String formatVersion) {
            return formatVersion(Output.of(formatVersion));
        }

        /**
         * @param paddingTolerance A float between 0 and 1 that defines the tolerance for block padding as a decimal fraction of stripe size. The default value is `0.05`, which means 5 percent of stripe size. For the default values of 64 MiB ORC stripes and 256 MiB HDFS blocks, the default block padding tolerance of 5 percent reserves a maximum of 3.2 MiB for padding within the 256 MiB block. In such a case, if the available size within the block is more than 3.2 MiB, a new, smaller stripe is inserted to fit within that space. This ensures that no stripe crosses block boundaries and causes remote reads within a node-local task. Kinesis Data Firehose ignores this parameter when `enable_padding` is `false`.
         * 
         * @return builder
         * 
         */
        public Builder paddingTolerance(@Nullable Output<Double> paddingTolerance) {
            $.paddingTolerance = paddingTolerance;
            return this;
        }

        /**
         * @param paddingTolerance A float between 0 and 1 that defines the tolerance for block padding as a decimal fraction of stripe size. The default value is `0.05`, which means 5 percent of stripe size. For the default values of 64 MiB ORC stripes and 256 MiB HDFS blocks, the default block padding tolerance of 5 percent reserves a maximum of 3.2 MiB for padding within the 256 MiB block. In such a case, if the available size within the block is more than 3.2 MiB, a new, smaller stripe is inserted to fit within that space. This ensures that no stripe crosses block boundaries and causes remote reads within a node-local task. Kinesis Data Firehose ignores this parameter when `enable_padding` is `false`.
         * 
         * @return builder
         * 
         */
        public Builder paddingTolerance(Double paddingTolerance) {
            return paddingTolerance(Output.of(paddingTolerance));
        }

        /**
         * @param rowIndexStride The number of rows between index entries. The default is `10000` and the minimum is `1000`.
         * 
         * @return builder
         * 
         */
        public Builder rowIndexStride(@Nullable Output<Integer> rowIndexStride) {
            $.rowIndexStride = rowIndexStride;
            return this;
        }

        /**
         * @param rowIndexStride The number of rows between index entries. The default is `10000` and the minimum is `1000`.
         * 
         * @return builder
         * 
         */
        public Builder rowIndexStride(Integer rowIndexStride) {
            return rowIndexStride(Output.of(rowIndexStride));
        }

        /**
         * @param stripeSizeBytes The number of bytes in each stripe. The default is 64 MiB and the minimum is 8 MiB.
         * 
         * @return builder
         * 
         */
        public Builder stripeSizeBytes(@Nullable Output<Integer> stripeSizeBytes) {
            $.stripeSizeBytes = stripeSizeBytes;
            return this;
        }

        /**
         * @param stripeSizeBytes The number of bytes in each stripe. The default is 64 MiB and the minimum is 8 MiB.
         * 
         * @return builder
         * 
         */
        public Builder stripeSizeBytes(Integer stripeSizeBytes) {
            return stripeSizeBytes(Output.of(stripeSizeBytes));
        }

        public FirehoseDeliveryStreamExtendedS3ConfigurationOrcSerDeArgs build() {
            return $;
        }
    }

}
