// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.timestreaminfluxdb;

import com.pulumi.aws.Utilities;
import com.pulumi.aws.timestreaminfluxdb.DbClusterArgs;
import com.pulumi.aws.timestreaminfluxdb.inputs.DbClusterState;
import com.pulumi.aws.timestreaminfluxdb.outputs.DbClusterLogDeliveryConfiguration;
import com.pulumi.aws.timestreaminfluxdb.outputs.DbClusterTimeouts;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * Resource for managing an Amazon Timestream for InfluxDB read-replica cluster.
 * 
 * &gt; **NOTE:** This resource requires a subscription to [Timestream for InfluxDB Read Replicas (Add-On) on the AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-lftzfxtb5xlv4?applicationId=AWS-Marketplace-Console&amp;ref_=beagle&amp;sr=0-2).
 * 
 * ## Example Usage
 * 
 * ### Basic Usage
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.timestreaminfluxdb.DbCluster;
 * import com.pulumi.aws.timestreaminfluxdb.DbClusterArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new DbCluster("example", DbClusterArgs.builder()
 *             .allocatedStorage(20)
 *             .bucket("example-bucket-name")
 *             .dbInstanceType("db.influx.medium")
 *             .failoverMode("AUTOMATIC")
 *             .username("admin")
 *             .password("example-password")
 *             .port(8086)
 *             .organization("organization")
 *             .vpcSubnetIds(            
 *                 example1.id(),
 *                 example2.id())
 *             .vpcSecurityGroupIds(exampleAwsSecurityGroup.id())
 *             .name("example-db-cluster")
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Usage with Prerequisite Resources
 * 
 * All Timestream for InfluxDB clusters require a VPC, at least two subnets, and a security group. The following example shows how these prerequisite resources can be created and used with `aws.timestreaminfluxdb.DbCluster`.
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.ec2.Vpc;
 * import com.pulumi.aws.ec2.VpcArgs;
 * import com.pulumi.aws.ec2.Subnet;
 * import com.pulumi.aws.ec2.SubnetArgs;
 * import com.pulumi.aws.ec2.SecurityGroup;
 * import com.pulumi.aws.ec2.SecurityGroupArgs;
 * import com.pulumi.aws.timestreaminfluxdb.DbCluster;
 * import com.pulumi.aws.timestreaminfluxdb.DbClusterArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new Vpc("example", VpcArgs.builder()
 *             .cidrBlock("10.0.0.0/16")
 *             .build());
 * 
 *         var example1 = new Subnet("example1", SubnetArgs.builder()
 *             .vpcId(example.id())
 *             .cidrBlock("10.0.1.0/24")
 *             .build());
 * 
 *         var example2 = new Subnet("example2", SubnetArgs.builder()
 *             .vpcId(example.id())
 *             .cidrBlock("10.0.2.0/24")
 *             .build());
 * 
 *         var exampleSecurityGroup = new SecurityGroup("exampleSecurityGroup", SecurityGroupArgs.builder()
 *             .name("example")
 *             .vpcId(example.id())
 *             .build());
 * 
 *         var exampleDbCluster = new DbCluster("exampleDbCluster", DbClusterArgs.builder()
 *             .allocatedStorage(20)
 *             .bucket("example-bucket-name")
 *             .dbInstanceType("db.influx.medium")
 *             .username("admin")
 *             .password("example-password")
 *             .organization("organization")
 *             .vpcSubnetIds(            
 *                 example1.id(),
 *                 example2.id())
 *             .vpcSecurityGroupIds(exampleSecurityGroup.id())
 *             .name("example-db-cluster")
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Usage with S3 Log Delivery Enabled
 * 
 * You can use an S3 bucket to store logs generated by your Timestream for InfluxDB cluster. The following example shows what resources and arguments are required to configure an S3 bucket for logging, including the IAM policy that needs to be set in order to allow Timestream for InfluxDB to place logs in your S3 bucket. The configuration of the required VPC, security group, and subnets have been left out of the example for brevity.
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.s3.Bucket;
 * import com.pulumi.aws.s3.BucketArgs;
 * import com.pulumi.aws.iam.IamFunctions;
 * import com.pulumi.aws.iam.inputs.GetPolicyDocumentArgs;
 * import com.pulumi.aws.s3.BucketPolicy;
 * import com.pulumi.aws.s3.BucketPolicyArgs;
 * import com.pulumi.aws.timestreaminfluxdb.DbCluster;
 * import com.pulumi.aws.timestreaminfluxdb.DbClusterArgs;
 * import com.pulumi.aws.timestreaminfluxdb.inputs.DbClusterLogDeliveryConfigurationArgs;
 * import com.pulumi.aws.timestreaminfluxdb.inputs.DbClusterLogDeliveryConfigurationS3ConfigurationArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var exampleBucket = new Bucket("exampleBucket", BucketArgs.builder()
 *             .bucket("example-s3-bucket")
 *             .forceDestroy(true)
 *             .build());
 * 
 *         final var example = IamFunctions.getPolicyDocument(GetPolicyDocumentArgs.builder()
 *             .statements(GetPolicyDocumentStatementArgs.builder()
 *                 .actions("s3:PutObject")
 *                 .principals(GetPolicyDocumentStatementPrincipalArgs.builder()
 *                     .type("Service")
 *                     .identifiers("timestream-influxdb.amazonaws.com")
 *                     .build())
 *                 .resources(exampleBucket.arn().applyValue(_arn -> String.format("%s/*", _arn)))
 *                 .build())
 *             .build());
 * 
 *         var exampleBucketPolicy = new BucketPolicy("exampleBucketPolicy", BucketPolicyArgs.builder()
 *             .bucket(exampleBucket.id())
 *             .policy(example.applyValue(_example -> _example.json()))
 *             .build());
 * 
 *         var exampleDbCluster = new DbCluster("exampleDbCluster", DbClusterArgs.builder()
 *             .allocatedStorage(20)
 *             .bucket("example-bucket-name")
 *             .dbInstanceType("db.influx.medium")
 *             .username("admin")
 *             .password("example-password")
 *             .organization("organization")
 *             .vpcSubnetIds(            
 *                 example1.id(),
 *                 example2.id())
 *             .vpcSecurityGroupIds(exampleAwsSecurityGroup.id())
 *             .name("example-db-cluster")
 *             .logDeliveryConfiguration(DbClusterLogDeliveryConfigurationArgs.builder()
 *                 .s3Configuration(DbClusterLogDeliveryConfigurationS3ConfigurationArgs.builder()
 *                     .bucketName(exampleBucket.bucket())
 *                     .enabled(true)
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Usage with InfluxDB V3
 * 
 * For InfluxDB V3 clusters, you can create a cluster without providing `allocatedStorage`, `bucket`, `organization`, `username`, `password`, or `deploymentType` by specifying a `dbParameterGroupIdentifier` such as `&#34;InfluxDBV3Core&#34;`. The following example shows how to create an InfluxDB V3 cluster:
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.timestreaminfluxdb.DbCluster;
 * import com.pulumi.aws.timestreaminfluxdb.DbClusterArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new DbCluster("example", DbClusterArgs.builder()
 *             .name("example-v3-cluster")
 *             .dbInstanceType("db.influx.large")
 *             .dbParameterGroupIdentifier("InfluxDBV3Core")
 *             .vpcSubnetIds(            
 *                 example1.id(),
 *                 example2.id())
 *             .vpcSecurityGroupIds(exampleAwsSecurityGroup.id())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Cluster Type Requirements
 * 
 * ### InfluxDB V2 Clusters (default)
 * 
 * The following arguments are **required** for InfluxDB V2 clusters:
 * 
 * * `allocatedStorage`
 * * `bucket`
 * * `deploymentType`
 * * `organization`
 * * `password`
 * * `username`
 * 
 * The `deploymentType` argument defaults to `&#34;MULTI_NODE_READ_REPLICAS&#34;` for InfluxDB V2 clusters when not specified.
 * 
 * ### InfluxDB V3 Clusters (when using V3 parameter groups)
 * 
 * The following arguments are **forbidden** for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group):
 * 
 * * `allocatedStorage`
 * * `bucket`
 * * `deploymentType`
 * * `organization`
 * * `password`
 * * `username`
 * 
 * ## Import
 * 
 * Using `pulumi import`, import Timestream for InfluxDB cluster using its identifier. For example:
 * 
 * ```sh
 * $ pulumi import aws:timestreaminfluxdb/dbCluster:DbCluster example 12345abcde
 * ```
 * 
 */
@ResourceType(type="aws:timestreaminfluxdb/dbCluster:DbCluster")
public class DbCluster extends com.pulumi.resources.CustomResource {
    /**
     * Amount of storage in GiB (gibibytes). The minimum value is `20`, the maximum value is `16384`. The argument `dbStorageType` places restrictions on this argument&#39;s minimum value. The following is a list of `dbStorageType` values and the corresponding minimum value for `allocatedStorage`: ` &#34;InfluxIOIncludedT1&#34;:  `20` ,  `&#34;InfluxIOIncludedT2&#34; and ` &#34;InfluxIOIncludedT3&#34;:  `400`. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group).
     * 
     */
    @Export(name="allocatedStorage", refs={Integer.class}, tree="[0]")
    private Output</* @Nullable */ Integer> allocatedStorage;

    /**
     * @return Amount of storage in GiB (gibibytes). The minimum value is `20`, the maximum value is `16384`. The argument `dbStorageType` places restrictions on this argument&#39;s minimum value. The following is a list of `dbStorageType` values and the corresponding minimum value for `allocatedStorage`: ` &#34;InfluxIOIncludedT1&#34;:  `20` ,  `&#34;InfluxIOIncludedT2&#34; and ` &#34;InfluxIOIncludedT3&#34;:  `400`. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group).
     * 
     */
    public Output<Optional<Integer>> allocatedStorage() {
        return Codegen.optional(this.allocatedStorage);
    }
    /**
     * ARN of the Timestream for InfluxDB cluster.
     * 
     */
    @Export(name="arn", refs={String.class}, tree="[0]")
    private Output<String> arn;

    /**
     * @return ARN of the Timestream for InfluxDB cluster.
     * 
     */
    public Output<String> arn() {
        return this.arn;
    }
    /**
     * Name of the initial InfluxDB bucket. All InfluxDB data is stored in a bucket. A bucket combines the concept of a database and a retention period (the duration of time that each data point persists). A bucket belongs to an organization. Along with `organization`, `username`, and `password`, this argument will be stored in the secret referred to by the `influxAuthParametersSecretArn` attribute. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group).
     * 
     */
    @Export(name="bucket", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> bucket;

    /**
     * @return Name of the initial InfluxDB bucket. All InfluxDB data is stored in a bucket. A bucket combines the concept of a database and a retention period (the duration of time that each data point persists). A bucket belongs to an organization. Along with `organization`, `username`, and `password`, this argument will be stored in the secret referred to by the `influxAuthParametersSecretArn` attribute. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group).
     * 
     */
    public Output<Optional<String>> bucket() {
        return Codegen.optional(this.bucket);
    }
    /**
     * Timestream for InfluxDB DB instance type to run InfluxDB on. Valid options are: `&#34;db.influx.medium&#34;`, `&#34;db.influx.large&#34;`, `&#34;db.influx.xlarge&#34;`, `&#34;db.influx.2xlarge&#34;`, `&#34;db.influx.4xlarge&#34;`, `&#34;db.influx.8xlarge&#34;`, `&#34;db.influx.12xlarge&#34;`, and `&#34;db.influx.16xlarge&#34;`. This argument is updatable.
     * 
     */
    @Export(name="dbInstanceType", refs={String.class}, tree="[0]")
    private Output<String> dbInstanceType;

    /**
     * @return Timestream for InfluxDB DB instance type to run InfluxDB on. Valid options are: `&#34;db.influx.medium&#34;`, `&#34;db.influx.large&#34;`, `&#34;db.influx.xlarge&#34;`, `&#34;db.influx.2xlarge&#34;`, `&#34;db.influx.4xlarge&#34;`, `&#34;db.influx.8xlarge&#34;`, `&#34;db.influx.12xlarge&#34;`, and `&#34;db.influx.16xlarge&#34;`. This argument is updatable.
     * 
     */
    public Output<String> dbInstanceType() {
        return this.dbInstanceType;
    }
    /**
     * ID of the DB parameter group assigned to your cluster. This argument is updatable. If added to an existing Timestream for InfluxDB cluster or given a new value, will cause an in-place update to the cluster. However, if a cluster already has a value for `dbParameterGroupIdentifier`, removing `dbParameterGroupIdentifier` will cause the cluster to be destroyed and recreated.
     * 
     */
    @Export(name="dbParameterGroupIdentifier", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> dbParameterGroupIdentifier;

    /**
     * @return ID of the DB parameter group assigned to your cluster. This argument is updatable. If added to an existing Timestream for InfluxDB cluster or given a new value, will cause an in-place update to the cluster. However, if a cluster already has a value for `dbParameterGroupIdentifier`, removing `dbParameterGroupIdentifier` will cause the cluster to be destroyed and recreated.
     * 
     */
    public Output<Optional<String>> dbParameterGroupIdentifier() {
        return Codegen.optional(this.dbParameterGroupIdentifier);
    }
    /**
     * Timestream for InfluxDB DB storage type to read and write InfluxDB data. You can choose between 3 different types of provisioned Influx IOPS included storage according to your workloads requirements: Influx IO Included 3000 IOPS, Influx IO Included 12000 IOPS, Influx IO Included 16000 IOPS. Valid options are: `&#34;InfluxIOIncludedT1&#34;`, `&#34;InfluxIOIncludedT2&#34;`, and `&#34;InfluxIOIncludedT3&#34;`. If you use ` &#34;InfluxIOIncludedT2&#34; or &#34;InfluxIOIncludedT3&#34;, the minimum value for  `allocatedStorage` is 400.
     * 
     */
    @Export(name="dbStorageType", refs={String.class}, tree="[0]")
    private Output<String> dbStorageType;

    /**
     * @return Timestream for InfluxDB DB storage type to read and write InfluxDB data. You can choose between 3 different types of provisioned Influx IOPS included storage according to your workloads requirements: Influx IO Included 3000 IOPS, Influx IO Included 12000 IOPS, Influx IO Included 16000 IOPS. Valid options are: `&#34;InfluxIOIncludedT1&#34;`, `&#34;InfluxIOIncludedT2&#34;`, and `&#34;InfluxIOIncludedT3&#34;`. If you use ` &#34;InfluxIOIncludedT2&#34; or &#34;InfluxIOIncludedT3&#34;, the minimum value for  `allocatedStorage` is 400.
     * 
     */
    public Output<String> dbStorageType() {
        return this.dbStorageType;
    }
    /**
     * Specifies the type of cluster to create. Valid options are: `&#34;MULTI_NODE_READ_REPLICAS&#34;`. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group).
     * 
     */
    @Export(name="deploymentType", refs={String.class}, tree="[0]")
    private Output<String> deploymentType;

    /**
     * @return Specifies the type of cluster to create. Valid options are: `&#34;MULTI_NODE_READ_REPLICAS&#34;`. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group).
     * 
     */
    public Output<String> deploymentType() {
        return this.deploymentType;
    }
    /**
     * Endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
     * 
     */
    @Export(name="endpoint", refs={String.class}, tree="[0]")
    private Output<String> endpoint;

    /**
     * @return Endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
     * 
     */
    public Output<String> endpoint() {
        return this.endpoint;
    }
    /**
     * Database engine type of the DB cluster.
     * 
     */
    @Export(name="engineType", refs={String.class}, tree="[0]")
    private Output<String> engineType;

    /**
     * @return Database engine type of the DB cluster.
     * 
     */
    public Output<String> engineType() {
        return this.engineType;
    }
    /**
     * Specifies the behavior of failure recovery when the primary node of the cluster fails. Valid options are: `&#34;AUTOMATIC&#34;` and `&#34;NO_FAILOVER&#34;`.
     * 
     */
    @Export(name="failoverMode", refs={String.class}, tree="[0]")
    private Output<String> failoverMode;

    /**
     * @return Specifies the behavior of failure recovery when the primary node of the cluster fails. Valid options are: `&#34;AUTOMATIC&#34;` and `&#34;NO_FAILOVER&#34;`.
     * 
     */
    public Output<String> failoverMode() {
        return this.failoverMode;
    }
    /**
     * ARN of the AWS Secrets Manager secret containing the initial InfluxDB authorization parameters. For InfluxDB V2 clusters, the secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password. For InfluxDB V3 clusters, the secret contains the InfluxDB admin token.
     * 
     */
    @Export(name="influxAuthParametersSecretArn", refs={String.class}, tree="[0]")
    private Output<String> influxAuthParametersSecretArn;

    /**
     * @return ARN of the AWS Secrets Manager secret containing the initial InfluxDB authorization parameters. For InfluxDB V2 clusters, the secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password. For InfluxDB V3 clusters, the secret contains the InfluxDB admin token.
     * 
     */
    public Output<String> influxAuthParametersSecretArn() {
        return this.influxAuthParametersSecretArn;
    }
    /**
     * Configuration for sending InfluxDB engine logs to a specified S3 bucket. This argument is updatable.
     * 
     */
    @Export(name="logDeliveryConfiguration", refs={DbClusterLogDeliveryConfiguration.class}, tree="[0]")
    private Output</* @Nullable */ DbClusterLogDeliveryConfiguration> logDeliveryConfiguration;

    /**
     * @return Configuration for sending InfluxDB engine logs to a specified S3 bucket. This argument is updatable.
     * 
     */
    public Output<Optional<DbClusterLogDeliveryConfiguration>> logDeliveryConfiguration() {
        return Codegen.optional(this.logDeliveryConfiguration);
    }
    /**
     * Name that uniquely identifies the DB cluster when interacting with the Amazon Timestream for InfluxDB API and CLI commands. This name will also be a prefix included in the endpoint. Cluster names must be unique per customer and per region. The argument must start with a letter, cannot contain consecutive hyphens (`-`) and cannot end with a hyphen.
     * 
     */
    @Export(name="name", refs={String.class}, tree="[0]")
    private Output<String> name;

    /**
     * @return Name that uniquely identifies the DB cluster when interacting with the Amazon Timestream for InfluxDB API and CLI commands. This name will also be a prefix included in the endpoint. Cluster names must be unique per customer and per region. The argument must start with a letter, cannot contain consecutive hyphens (`-`) and cannot end with a hyphen.
     * 
     */
    public Output<String> name() {
        return this.name;
    }
    /**
     * Specifies whether the network type of the Timestream for InfluxDB cluster is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
     * 
     */
    @Export(name="networkType", refs={String.class}, tree="[0]")
    private Output<String> networkType;

    /**
     * @return Specifies whether the network type of the Timestream for InfluxDB cluster is IPV4, which can communicate over IPv4 protocol only, or DUAL, which can communicate over both IPv4 and IPv6 protocols.
     * 
     */
    public Output<String> networkType() {
        return this.networkType;
    }
    /**
     * Name of the initial organization for the initial admin user in InfluxDB. An InfluxDB organization is a workspace for a group of users. Along with `bucket`, `username`, and `password`, this argument will be stored in the secret referred to by the `influxAuthParametersSecretArn` attribute. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group).
     * 
     */
    @Export(name="organization", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> organization;

    /**
     * @return Name of the initial organization for the initial admin user in InfluxDB. An InfluxDB organization is a workspace for a group of users. Along with `bucket`, `username`, and `password`, this argument will be stored in the secret referred to by the `influxAuthParametersSecretArn` attribute. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group).
     * 
     */
    public Output<Optional<String>> organization() {
        return Codegen.optional(this.organization);
    }
    /**
     * Password of the initial admin user created in InfluxDB. This password will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. Along with `bucket`, `username`, and `organization`, this argument will be stored in the secret referred to by the `influxAuthParametersSecretArn` attribute. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group) as the AWS API rejects it.
     * 
     */
    @Export(name="password", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> password;

    /**
     * @return Password of the initial admin user created in InfluxDB. This password will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. Along with `bucket`, `username`, and `organization`, this argument will be stored in the secret referred to by the `influxAuthParametersSecretArn` attribute. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group) as the AWS API rejects it.
     * 
     */
    public Output<Optional<String>> password() {
        return Codegen.optional(this.password);
    }
    /**
     * The port on which the cluster accepts connections. Valid values: `1024`-`65535`. Cannot be `2375`-`2376`, `7788`-`7799`, `8090`, or `51678`-`51680`. This argument is updatable.
     * 
     */
    @Export(name="port", refs={Integer.class}, tree="[0]")
    private Output<Integer> port;

    /**
     * @return The port on which the cluster accepts connections. Valid values: `1024`-`65535`. Cannot be `2375`-`2376`, `7788`-`7799`, `8090`, or `51678`-`51680`. This argument is updatable.
     * 
     */
    public Output<Integer> port() {
        return this.port;
    }
    /**
     * Configures the DB cluster with a public IP to facilitate access. Other resources, such as a VPC, a subnet, an internet gateway, and a route table with routes, are also required to enabled public access, in addition to this argument. See &#34;Usage with Public Internet Access Enabled&#34; for an example configuration with all required resources for public internet access.
     * 
     */
    @Export(name="publiclyAccessible", refs={Boolean.class}, tree="[0]")
    private Output<Boolean> publiclyAccessible;

    /**
     * @return Configures the DB cluster with a public IP to facilitate access. Other resources, such as a VPC, a subnet, an internet gateway, and a route table with routes, are also required to enabled public access, in addition to this argument. See &#34;Usage with Public Internet Access Enabled&#34; for an example configuration with all required resources for public internet access.
     * 
     */
    public Output<Boolean> publiclyAccessible() {
        return this.publiclyAccessible;
    }
    /**
     * The endpoint used to connect to the Timestream for InfluxDB cluster for read-only operations.
     * 
     */
    @Export(name="readerEndpoint", refs={String.class}, tree="[0]")
    private Output<String> readerEndpoint;

    /**
     * @return The endpoint used to connect to the Timestream for InfluxDB cluster for read-only operations.
     * 
     */
    public Output<String> readerEndpoint() {
        return this.readerEndpoint;
    }
    /**
     * Region where this resource will be [managed](https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints). Defaults to the Region set in the provider configuration.
     * 
     */
    @Export(name="region", refs={String.class}, tree="[0]")
    private Output<String> region;

    /**
     * @return Region where this resource will be [managed](https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints). Defaults to the Region set in the provider configuration.
     * 
     */
    public Output<String> region() {
        return this.region;
    }
    /**
     * Map of tags assigned to the resource. If configured with a provider `defaultTags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
     * 
     */
    @Export(name="tags", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> tags;

    /**
     * @return Map of tags assigned to the resource. If configured with a provider `defaultTags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
     * 
     */
    public Output<Optional<Map<String,String>>> tags() {
        return Codegen.optional(this.tags);
    }
    /**
     * Map of tags assigned to the resource, including those inherited from the provider `defaultTags` configuration block.
     * 
     */
    @Export(name="tagsAll", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> tagsAll;

    /**
     * @return Map of tags assigned to the resource, including those inherited from the provider `defaultTags` configuration block.
     * 
     */
    public Output<Map<String,String>> tagsAll() {
        return this.tagsAll;
    }
    @Export(name="timeouts", refs={DbClusterTimeouts.class}, tree="[0]")
    private Output</* @Nullable */ DbClusterTimeouts> timeouts;

    public Output<Optional<DbClusterTimeouts>> timeouts() {
        return Codegen.optional(this.timeouts);
    }
    /**
     * Username of the initial admin user created in InfluxDB. Must start with a letter and can&#39;t end with a hyphen or contain two consecutive hyphens. This username will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. Along with `bucket`, `organization`, and `password`, this argument will be stored in the secret referred to by the `influxAuthParametersSecretArn` attribute. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group).
     * 
     */
    @Export(name="username", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> username;

    /**
     * @return Username of the initial admin user created in InfluxDB. Must start with a letter and can&#39;t end with a hyphen or contain two consecutive hyphens. This username will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. Along with `bucket`, `organization`, and `password`, this argument will be stored in the secret referred to by the `influxAuthParametersSecretArn` attribute. This field is forbidden for InfluxDB V3 clusters (when using an InfluxDB V3 db parameter group).
     * 
     */
    public Output<Optional<String>> username() {
        return Codegen.optional(this.username);
    }
    /**
     * List of VPC security group IDs to associate with the cluster.
     * 
     */
    @Export(name="vpcSecurityGroupIds", refs={List.class,String.class}, tree="[0,1]")
    private Output<List<String>> vpcSecurityGroupIds;

    /**
     * @return List of VPC security group IDs to associate with the cluster.
     * 
     */
    public Output<List<String>> vpcSecurityGroupIds() {
        return this.vpcSecurityGroupIds;
    }
    /**
     * List of VPC subnet IDs to associate with the cluster. Provide at least two VPC subnet IDs in different availability zones when deploying with a Multi-AZ standby.
     * 
     * The following arguments are optional:
     * 
     */
    @Export(name="vpcSubnetIds", refs={List.class,String.class}, tree="[0,1]")
    private Output<List<String>> vpcSubnetIds;

    /**
     * @return List of VPC subnet IDs to associate with the cluster. Provide at least two VPC subnet IDs in different availability zones when deploying with a Multi-AZ standby.
     * 
     * The following arguments are optional:
     * 
     */
    public Output<List<String>> vpcSubnetIds() {
        return this.vpcSubnetIds;
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public DbCluster(java.lang.String name) {
        this(name, DbClusterArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public DbCluster(java.lang.String name, DbClusterArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public DbCluster(java.lang.String name, DbClusterArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("aws:timestreaminfluxdb/dbCluster:DbCluster", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private DbCluster(java.lang.String name, Output<java.lang.String> id, @Nullable DbClusterState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("aws:timestreaminfluxdb/dbCluster:DbCluster", name, state, makeResourceOptions(options, id), false);
    }

    private static DbClusterArgs makeArgs(DbClusterArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? DbClusterArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .additionalSecretOutputs(List.of(
                "password"
            ))
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static DbCluster get(java.lang.String name, Output<java.lang.String> id, @Nullable DbClusterState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new DbCluster(name, id, state, options);
    }
}
