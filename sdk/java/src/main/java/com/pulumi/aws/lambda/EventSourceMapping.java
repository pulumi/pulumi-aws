// *** WARNING: this file was generated by pulumi-language-java. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.lambda;

import com.pulumi.aws.Utilities;
import com.pulumi.aws.lambda.EventSourceMappingArgs;
import com.pulumi.aws.lambda.inputs.EventSourceMappingState;
import com.pulumi.aws.lambda.outputs.EventSourceMappingAmazonManagedKafkaEventSourceConfig;
import com.pulumi.aws.lambda.outputs.EventSourceMappingDestinationConfig;
import com.pulumi.aws.lambda.outputs.EventSourceMappingDocumentDbEventSourceConfig;
import com.pulumi.aws.lambda.outputs.EventSourceMappingFilterCriteria;
import com.pulumi.aws.lambda.outputs.EventSourceMappingMetricsConfig;
import com.pulumi.aws.lambda.outputs.EventSourceMappingProvisionedPollerConfig;
import com.pulumi.aws.lambda.outputs.EventSourceMappingScalingConfig;
import com.pulumi.aws.lambda.outputs.EventSourceMappingSelfManagedEventSource;
import com.pulumi.aws.lambda.outputs.EventSourceMappingSelfManagedKafkaEventSourceConfig;
import com.pulumi.aws.lambda.outputs.EventSourceMappingSourceAccessConfiguration;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Export;
import com.pulumi.core.annotations.ResourceType;
import com.pulumi.core.internal.Codegen;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import javax.annotation.Nullable;

/**
 * Manages an AWS Lambda Event Source Mapping. Use this resource to connect Lambda functions to event sources like Kinesis, DynamoDB, SQS, Amazon MQ, and Managed Streaming for Apache Kafka (MSK).
 * 
 * For information about Lambda and how to use it, see [What is AWS Lambda?](http://docs.aws.amazon.com/lambda/latest/dg/welcome.html). For information about event source mappings, see [CreateEventSourceMapping](http://docs.aws.amazon.com/lambda/latest/dg/API_CreateEventSourceMapping.html) in the API docs.
 * 
 * ## Example Usage
 * 
 * ### DynamoDB Stream
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.lambda.EventSourceMapping;
 * import com.pulumi.aws.lambda.EventSourceMappingArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new EventSourceMapping("example", EventSourceMappingArgs.builder()
 *             .eventSourceArn(exampleAwsDynamodbTable.streamArn())
 *             .functionName(exampleAwsLambdaFunction.arn())
 *             .startingPosition("LATEST")
 *             .tags(Map.of("Name", "dynamodb-stream-mapping"))
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Kinesis Stream
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.lambda.EventSourceMapping;
 * import com.pulumi.aws.lambda.EventSourceMappingArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingDestinationConfigArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingDestinationConfigOnFailureArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new EventSourceMapping("example", EventSourceMappingArgs.builder()
 *             .eventSourceArn(exampleAwsKinesisStream.arn())
 *             .functionName(exampleAwsLambdaFunction.arn())
 *             .startingPosition("LATEST")
 *             .batchSize(100)
 *             .maximumBatchingWindowInSeconds(5)
 *             .parallelizationFactor(2)
 *             .destinationConfig(EventSourceMappingDestinationConfigArgs.builder()
 *                 .onFailure(EventSourceMappingDestinationConfigOnFailureArgs.builder()
 *                     .destinationArn(dlq.arn())
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### SQS Queue
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.lambda.EventSourceMapping;
 * import com.pulumi.aws.lambda.EventSourceMappingArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingScalingConfigArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new EventSourceMapping("example", EventSourceMappingArgs.builder()
 *             .eventSourceArn(exampleAwsSqsQueue.arn())
 *             .functionName(exampleAwsLambdaFunction.arn())
 *             .batchSize(10)
 *             .scalingConfig(EventSourceMappingScalingConfigArgs.builder()
 *                 .maximumConcurrency(100)
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### SQS with Event Filtering
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.lambda.EventSourceMapping;
 * import com.pulumi.aws.lambda.EventSourceMappingArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingFilterCriteriaArgs;
 * import static com.pulumi.codegen.internal.Serialization.*;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new EventSourceMapping("example", EventSourceMappingArgs.builder()
 *             .eventSourceArn(exampleAwsSqsQueue.arn())
 *             .functionName(exampleAwsLambdaFunction.arn())
 *             .filterCriteria(EventSourceMappingFilterCriteriaArgs.builder()
 *                 .filters(EventSourceMappingFilterCriteriaFilterArgs.builder()
 *                     .pattern(serializeJson(
 *                         jsonObject(
 *                             jsonProperty("body", jsonObject(
 *                                 jsonProperty("Temperature", jsonArray(jsonObject(
 *                                     jsonProperty("numeric", jsonArray(
 *                                         ">", 
 *                                         0, 
 *                                         "<=", 
 *                                         100
 *                                     ))
 *                                 ))),
 *                                 jsonProperty("Location", jsonArray("New York"))
 *                             ))
 *                         )))
 *                     .build())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Amazon MSK
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.lambda.EventSourceMapping;
 * import com.pulumi.aws.lambda.EventSourceMappingArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingAmazonManagedKafkaEventSourceConfigArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new EventSourceMapping("example", EventSourceMappingArgs.builder()
 *             .eventSourceArn(exampleAwsMskCluster.arn())
 *             .functionName(exampleAwsLambdaFunction.arn())
 *             .topics(            
 *                 "orders",
 *                 "inventory")
 *             .startingPosition("TRIM_HORIZON")
 *             .batchSize(100)
 *             .amazonManagedKafkaEventSourceConfig(EventSourceMappingAmazonManagedKafkaEventSourceConfigArgs.builder()
 *                 .consumerGroupId("lambda-consumer-group")
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Self-Managed Apache Kafka
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.lambda.EventSourceMapping;
 * import com.pulumi.aws.lambda.EventSourceMappingArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingSelfManagedEventSourceArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingSelfManagedKafkaEventSourceConfigArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingSourceAccessConfigurationArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingProvisionedPollerConfigArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new EventSourceMapping("example", EventSourceMappingArgs.builder()
 *             .functionName(exampleAwsLambdaFunction.arn())
 *             .topics("orders")
 *             .startingPosition("TRIM_HORIZON")
 *             .selfManagedEventSource(EventSourceMappingSelfManagedEventSourceArgs.builder()
 *                 .endpoints(Map.of("KAFKA_BOOTSTRAP_SERVERS", "kafka1.example.com:9092,kafka2.example.com:9092"))
 *                 .build())
 *             .selfManagedKafkaEventSourceConfig(EventSourceMappingSelfManagedKafkaEventSourceConfigArgs.builder()
 *                 .consumerGroupId("lambda-consumer-group")
 *                 .build())
 *             .sourceAccessConfigurations(            
 *                 EventSourceMappingSourceAccessConfigurationArgs.builder()
 *                     .type("VPC_SUBNET")
 *                     .uri(String.format("subnet:%s", example1.id()))
 *                     .build(),
 *                 EventSourceMappingSourceAccessConfigurationArgs.builder()
 *                     .type("VPC_SUBNET")
 *                     .uri(String.format("subnet:%s", example2.id()))
 *                     .build(),
 *                 EventSourceMappingSourceAccessConfigurationArgs.builder()
 *                     .type("VPC_SECURITY_GROUP")
 *                     .uri(String.format("security_group:%s", exampleAwsSecurityGroup.id()))
 *                     .build())
 *             .provisionedPollerConfig(EventSourceMappingProvisionedPollerConfigArgs.builder()
 *                 .maximumPollers(100)
 *                 .minimumPollers(10)
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Amazon MQ (ActiveMQ)
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.lambda.EventSourceMapping;
 * import com.pulumi.aws.lambda.EventSourceMappingArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingSourceAccessConfigurationArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new EventSourceMapping("example", EventSourceMappingArgs.builder()
 *             .eventSourceArn(exampleAwsMqBroker.arn())
 *             .functionName(exampleAwsLambdaFunction.arn())
 *             .queues("orders")
 *             .batchSize(10)
 *             .sourceAccessConfigurations(EventSourceMappingSourceAccessConfigurationArgs.builder()
 *                 .type("BASIC_AUTH")
 *                 .uri(exampleAwsSecretsmanagerSecretVersion.arn())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### Amazon MQ (RabbitMQ)
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.lambda.EventSourceMapping;
 * import com.pulumi.aws.lambda.EventSourceMappingArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingSourceAccessConfigurationArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new EventSourceMapping("example", EventSourceMappingArgs.builder()
 *             .eventSourceArn(exampleAwsMqBroker.arn())
 *             .functionName(exampleAwsLambdaFunction.arn())
 *             .queues("orders")
 *             .batchSize(1)
 *             .sourceAccessConfigurations(            
 *                 EventSourceMappingSourceAccessConfigurationArgs.builder()
 *                     .type("VIRTUAL_HOST")
 *                     .uri("/production")
 *                     .build(),
 *                 EventSourceMappingSourceAccessConfigurationArgs.builder()
 *                     .type("BASIC_AUTH")
 *                     .uri(exampleAwsSecretsmanagerSecretVersion.arn())
 *                     .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ### DocumentDB Change Stream
 * 
 * <pre>
 * {@code
 * package generated_program;
 * 
 * import com.pulumi.Context;
 * import com.pulumi.Pulumi;
 * import com.pulumi.core.Output;
 * import com.pulumi.aws.lambda.EventSourceMapping;
 * import com.pulumi.aws.lambda.EventSourceMappingArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingDocumentDbEventSourceConfigArgs;
 * import com.pulumi.aws.lambda.inputs.EventSourceMappingSourceAccessConfigurationArgs;
 * import java.util.List;
 * import java.util.ArrayList;
 * import java.util.Map;
 * import java.io.File;
 * import java.nio.file.Files;
 * import java.nio.file.Paths;
 * 
 * public class App {
 *     public static void main(String[] args) {
 *         Pulumi.run(App::stack);
 *     }
 * 
 *     public static void stack(Context ctx) {
 *         var example = new EventSourceMapping("example", EventSourceMappingArgs.builder()
 *             .eventSourceArn(exampleAwsDocdbCluster.arn())
 *             .functionName(exampleAwsLambdaFunction.arn())
 *             .startingPosition("LATEST")
 *             .documentDbEventSourceConfig(EventSourceMappingDocumentDbEventSourceConfigArgs.builder()
 *                 .databaseName("orders")
 *                 .collectionName("transactions")
 *                 .fullDocument("UpdateLookup")
 *                 .build())
 *             .sourceAccessConfigurations(EventSourceMappingSourceAccessConfigurationArgs.builder()
 *                 .type("BASIC_AUTH")
 *                 .uri(exampleAwsSecretsmanagerSecretVersion.arn())
 *                 .build())
 *             .build());
 * 
 *     }
 * }
 * }
 * </pre>
 * 
 * ## Import
 * 
 * Using `pulumi import`, import Lambda event source mappings using the `UUID` (event source mapping identifier). For example:
 * 
 * ```sh
 * $ pulumi import aws:lambda/eventSourceMapping:EventSourceMapping example 12345kxodurf3443
 * ```
 * 
 */
@ResourceType(type="aws:lambda/eventSourceMapping:EventSourceMapping")
public class EventSourceMapping extends com.pulumi.resources.CustomResource {
    /**
     * Additional configuration block for Amazon Managed Kafka sources. Incompatible with `selfManagedEventSource` and `selfManagedKafkaEventSourceConfig`. See below.
     * 
     */
    @Export(name="amazonManagedKafkaEventSourceConfig", refs={EventSourceMappingAmazonManagedKafkaEventSourceConfig.class}, tree="[0]")
    private Output<EventSourceMappingAmazonManagedKafkaEventSourceConfig> amazonManagedKafkaEventSourceConfig;

    /**
     * @return Additional configuration block for Amazon Managed Kafka sources. Incompatible with `selfManagedEventSource` and `selfManagedKafkaEventSourceConfig`. See below.
     * 
     */
    public Output<EventSourceMappingAmazonManagedKafkaEventSourceConfig> amazonManagedKafkaEventSourceConfig() {
        return this.amazonManagedKafkaEventSourceConfig;
    }
    /**
     * Event source mapping ARN.
     * 
     */
    @Export(name="arn", refs={String.class}, tree="[0]")
    private Output<String> arn;

    /**
     * @return Event source mapping ARN.
     * 
     */
    public Output<String> arn() {
        return this.arn;
    }
    /**
     * Largest number of records that Lambda will retrieve from your event source at the time of invocation. Defaults to `100` for DynamoDB, Kinesis, MQ and MSK, `10` for SQS.
     * 
     */
    @Export(name="batchSize", refs={Integer.class}, tree="[0]")
    private Output</* @Nullable */ Integer> batchSize;

    /**
     * @return Largest number of records that Lambda will retrieve from your event source at the time of invocation. Defaults to `100` for DynamoDB, Kinesis, MQ and MSK, `10` for SQS.
     * 
     */
    public Output<Optional<Integer>> batchSize() {
        return Codegen.optional(this.batchSize);
    }
    /**
     * Whether to split the batch in two and retry if the function returns an error. Only available for stream sources (DynamoDB and Kinesis). Defaults to `false`.
     * 
     */
    @Export(name="bisectBatchOnFunctionError", refs={Boolean.class}, tree="[0]")
    private Output</* @Nullable */ Boolean> bisectBatchOnFunctionError;

    /**
     * @return Whether to split the batch in two and retry if the function returns an error. Only available for stream sources (DynamoDB and Kinesis). Defaults to `false`.
     * 
     */
    public Output<Optional<Boolean>> bisectBatchOnFunctionError() {
        return Codegen.optional(this.bisectBatchOnFunctionError);
    }
    /**
     * Amazon SQS queue, Amazon SNS topic or Amazon S3 bucket (only available for Kafka sources) destination for failed records. Only available for stream sources (DynamoDB and Kinesis) and Kafka sources (Amazon MSK and Self-managed Apache Kafka). See below.
     * 
     */
    @Export(name="destinationConfig", refs={EventSourceMappingDestinationConfig.class}, tree="[0]")
    private Output</* @Nullable */ EventSourceMappingDestinationConfig> destinationConfig;

    /**
     * @return Amazon SQS queue, Amazon SNS topic or Amazon S3 bucket (only available for Kafka sources) destination for failed records. Only available for stream sources (DynamoDB and Kinesis) and Kafka sources (Amazon MSK and Self-managed Apache Kafka). See below.
     * 
     */
    public Output<Optional<EventSourceMappingDestinationConfig>> destinationConfig() {
        return Codegen.optional(this.destinationConfig);
    }
    /**
     * Configuration settings for a DocumentDB event source. See below.
     * 
     */
    @Export(name="documentDbEventSourceConfig", refs={EventSourceMappingDocumentDbEventSourceConfig.class}, tree="[0]")
    private Output</* @Nullable */ EventSourceMappingDocumentDbEventSourceConfig> documentDbEventSourceConfig;

    /**
     * @return Configuration settings for a DocumentDB event source. See below.
     * 
     */
    public Output<Optional<EventSourceMappingDocumentDbEventSourceConfig>> documentDbEventSourceConfig() {
        return Codegen.optional(this.documentDbEventSourceConfig);
    }
    /**
     * Whether the mapping is enabled. Defaults to `true`.
     * 
     */
    @Export(name="enabled", refs={Boolean.class}, tree="[0]")
    private Output</* @Nullable */ Boolean> enabled;

    /**
     * @return Whether the mapping is enabled. Defaults to `true`.
     * 
     */
    public Output<Optional<Boolean>> enabled() {
        return Codegen.optional(this.enabled);
    }
    /**
     * Event source ARN - required for Kinesis stream, DynamoDB stream, SQS queue, MQ broker, MSK cluster or DocumentDB change stream. Incompatible with Self Managed Kafka source.
     * 
     */
    @Export(name="eventSourceArn", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> eventSourceArn;

    /**
     * @return Event source ARN - required for Kinesis stream, DynamoDB stream, SQS queue, MQ broker, MSK cluster or DocumentDB change stream. Incompatible with Self Managed Kafka source.
     * 
     */
    public Output<Optional<String>> eventSourceArn() {
        return Codegen.optional(this.eventSourceArn);
    }
    /**
     * Criteria to use for [event filtering](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html) Kinesis stream, DynamoDB stream, SQS queue event sources. See below.
     * 
     */
    @Export(name="filterCriteria", refs={EventSourceMappingFilterCriteria.class}, tree="[0]")
    private Output</* @Nullable */ EventSourceMappingFilterCriteria> filterCriteria;

    /**
     * @return Criteria to use for [event filtering](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html) Kinesis stream, DynamoDB stream, SQS queue event sources. See below.
     * 
     */
    public Output<Optional<EventSourceMappingFilterCriteria>> filterCriteria() {
        return Codegen.optional(this.filterCriteria);
    }
    /**
     * ARN of the Lambda function the event source mapping is sending events to. (Note: this is a computed value that differs from `functionName` above.)
     * 
     */
    @Export(name="functionArn", refs={String.class}, tree="[0]")
    private Output<String> functionArn;

    /**
     * @return ARN of the Lambda function the event source mapping is sending events to. (Note: this is a computed value that differs from `functionName` above.)
     * 
     */
    public Output<String> functionArn() {
        return this.functionArn;
    }
    /**
     * Name or ARN of the Lambda function that will be subscribing to events.
     * 
     * The following arguments are optional:
     * 
     */
    @Export(name="functionName", refs={String.class}, tree="[0]")
    private Output<String> functionName;

    /**
     * @return Name or ARN of the Lambda function that will be subscribing to events.
     * 
     * The following arguments are optional:
     * 
     */
    public Output<String> functionName() {
        return this.functionName;
    }
    /**
     * List of current response type enums applied to the event source mapping for [AWS Lambda checkpointing](https://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html#services-ddb-batchfailurereporting). Only available for SQS and stream sources (DynamoDB and Kinesis). Valid values: `ReportBatchItemFailures`.
     * 
     */
    @Export(name="functionResponseTypes", refs={List.class,String.class}, tree="[0,1]")
    private Output</* @Nullable */ List<String>> functionResponseTypes;

    /**
     * @return List of current response type enums applied to the event source mapping for [AWS Lambda checkpointing](https://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html#services-ddb-batchfailurereporting). Only available for SQS and stream sources (DynamoDB and Kinesis). Valid values: `ReportBatchItemFailures`.
     * 
     */
    public Output<Optional<List<String>>> functionResponseTypes() {
        return Codegen.optional(this.functionResponseTypes);
    }
    /**
     * ARN of the Key Management Service (KMS) customer managed key that Lambda uses to encrypt your function&#39;s filter criteria.
     * 
     */
    @Export(name="kmsKeyArn", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> kmsKeyArn;

    /**
     * @return ARN of the Key Management Service (KMS) customer managed key that Lambda uses to encrypt your function&#39;s filter criteria.
     * 
     */
    public Output<Optional<String>> kmsKeyArn() {
        return Codegen.optional(this.kmsKeyArn);
    }
    /**
     * Date this resource was last modified.
     * 
     */
    @Export(name="lastModified", refs={String.class}, tree="[0]")
    private Output<String> lastModified;

    /**
     * @return Date this resource was last modified.
     * 
     */
    public Output<String> lastModified() {
        return this.lastModified;
    }
    /**
     * Result of the last AWS Lambda invocation of your Lambda function.
     * 
     */
    @Export(name="lastProcessingResult", refs={String.class}, tree="[0]")
    private Output<String> lastProcessingResult;

    /**
     * @return Result of the last AWS Lambda invocation of your Lambda function.
     * 
     */
    public Output<String> lastProcessingResult() {
        return this.lastProcessingResult;
    }
    /**
     * Maximum amount of time to gather records before invoking the function, in seconds (between 0 and 300). Records will continue to buffer until either `maximumBatchingWindowInSeconds` expires or `batchSize` has been met. For streaming event sources, defaults to as soon as records are available in the stream. Only available for stream sources (DynamoDB and Kinesis) and SQS standard queues.
     * 
     */
    @Export(name="maximumBatchingWindowInSeconds", refs={Integer.class}, tree="[0]")
    private Output</* @Nullable */ Integer> maximumBatchingWindowInSeconds;

    /**
     * @return Maximum amount of time to gather records before invoking the function, in seconds (between 0 and 300). Records will continue to buffer until either `maximumBatchingWindowInSeconds` expires or `batchSize` has been met. For streaming event sources, defaults to as soon as records are available in the stream. Only available for stream sources (DynamoDB and Kinesis) and SQS standard queues.
     * 
     */
    public Output<Optional<Integer>> maximumBatchingWindowInSeconds() {
        return Codegen.optional(this.maximumBatchingWindowInSeconds);
    }
    /**
     * Maximum age of a record that Lambda sends to a function for processing. Only available for stream sources (DynamoDB and Kinesis). Must be either -1 (forever, and the default value) or between 60 and 604800 (inclusive).
     * 
     */
    @Export(name="maximumRecordAgeInSeconds", refs={Integer.class}, tree="[0]")
    private Output<Integer> maximumRecordAgeInSeconds;

    /**
     * @return Maximum age of a record that Lambda sends to a function for processing. Only available for stream sources (DynamoDB and Kinesis). Must be either -1 (forever, and the default value) or between 60 and 604800 (inclusive).
     * 
     */
    public Output<Integer> maximumRecordAgeInSeconds() {
        return this.maximumRecordAgeInSeconds;
    }
    /**
     * Maximum number of times to retry when the function returns an error. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of -1 (forever), maximum of 10000.
     * 
     */
    @Export(name="maximumRetryAttempts", refs={Integer.class}, tree="[0]")
    private Output<Integer> maximumRetryAttempts;

    /**
     * @return Maximum number of times to retry when the function returns an error. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of -1 (forever), maximum of 10000.
     * 
     */
    public Output<Integer> maximumRetryAttempts() {
        return this.maximumRetryAttempts;
    }
    /**
     * CloudWatch metrics configuration of the event source. Only available for stream sources (DynamoDB and Kinesis) and SQS queues. See below.
     * 
     */
    @Export(name="metricsConfig", refs={EventSourceMappingMetricsConfig.class}, tree="[0]")
    private Output</* @Nullable */ EventSourceMappingMetricsConfig> metricsConfig;

    /**
     * @return CloudWatch metrics configuration of the event source. Only available for stream sources (DynamoDB and Kinesis) and SQS queues. See below.
     * 
     */
    public Output<Optional<EventSourceMappingMetricsConfig>> metricsConfig() {
        return Codegen.optional(this.metricsConfig);
    }
    /**
     * Number of batches to process from each shard concurrently. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of 1, maximum of 10.
     * 
     */
    @Export(name="parallelizationFactor", refs={Integer.class}, tree="[0]")
    private Output<Integer> parallelizationFactor;

    /**
     * @return Number of batches to process from each shard concurrently. Only available for stream sources (DynamoDB and Kinesis). Minimum and default of 1, maximum of 10.
     * 
     */
    public Output<Integer> parallelizationFactor() {
        return this.parallelizationFactor;
    }
    /**
     * Event poller configuration for the event source. Only valid for Amazon MSK or self-managed Apache Kafka sources. See below.
     * 
     */
    @Export(name="provisionedPollerConfig", refs={EventSourceMappingProvisionedPollerConfig.class}, tree="[0]")
    private Output</* @Nullable */ EventSourceMappingProvisionedPollerConfig> provisionedPollerConfig;

    /**
     * @return Event poller configuration for the event source. Only valid for Amazon MSK or self-managed Apache Kafka sources. See below.
     * 
     */
    public Output<Optional<EventSourceMappingProvisionedPollerConfig>> provisionedPollerConfig() {
        return Codegen.optional(this.provisionedPollerConfig);
    }
    /**
     * Name of the Amazon MQ broker destination queue to consume. Only available for MQ sources. The list must contain exactly one queue name.
     * 
     */
    @Export(name="queues", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> queues;

    /**
     * @return Name of the Amazon MQ broker destination queue to consume. Only available for MQ sources. The list must contain exactly one queue name.
     * 
     */
    public Output<Optional<String>> queues() {
        return Codegen.optional(this.queues);
    }
    /**
     * Region where this resource will be [managed](https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints). Defaults to the Region set in the provider configuration.
     * 
     */
    @Export(name="region", refs={String.class}, tree="[0]")
    private Output<String> region;

    /**
     * @return Region where this resource will be [managed](https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints). Defaults to the Region set in the provider configuration.
     * 
     */
    public Output<String> region() {
        return this.region;
    }
    /**
     * Scaling configuration of the event source. Only available for SQS queues. See below.
     * 
     */
    @Export(name="scalingConfig", refs={EventSourceMappingScalingConfig.class}, tree="[0]")
    private Output</* @Nullable */ EventSourceMappingScalingConfig> scalingConfig;

    /**
     * @return Scaling configuration of the event source. Only available for SQS queues. See below.
     * 
     */
    public Output<Optional<EventSourceMappingScalingConfig>> scalingConfig() {
        return Codegen.optional(this.scalingConfig);
    }
    /**
     * For Self Managed Kafka sources, the location of the self managed cluster. If set, configuration must also include `sourceAccessConfiguration`. See below.
     * 
     */
    @Export(name="selfManagedEventSource", refs={EventSourceMappingSelfManagedEventSource.class}, tree="[0]")
    private Output</* @Nullable */ EventSourceMappingSelfManagedEventSource> selfManagedEventSource;

    /**
     * @return For Self Managed Kafka sources, the location of the self managed cluster. If set, configuration must also include `sourceAccessConfiguration`. See below.
     * 
     */
    public Output<Optional<EventSourceMappingSelfManagedEventSource>> selfManagedEventSource() {
        return Codegen.optional(this.selfManagedEventSource);
    }
    /**
     * Additional configuration block for Self Managed Kafka sources. Incompatible with `eventSourceArn` and `amazonManagedKafkaEventSourceConfig`. See below.
     * 
     */
    @Export(name="selfManagedKafkaEventSourceConfig", refs={EventSourceMappingSelfManagedKafkaEventSourceConfig.class}, tree="[0]")
    private Output<EventSourceMappingSelfManagedKafkaEventSourceConfig> selfManagedKafkaEventSourceConfig;

    /**
     * @return Additional configuration block for Self Managed Kafka sources. Incompatible with `eventSourceArn` and `amazonManagedKafkaEventSourceConfig`. See below.
     * 
     */
    public Output<EventSourceMappingSelfManagedKafkaEventSourceConfig> selfManagedKafkaEventSourceConfig() {
        return this.selfManagedKafkaEventSourceConfig;
    }
    /**
     * For Self Managed Kafka sources, the access configuration for the source. If set, configuration must also include `selfManagedEventSource`. See below.
     * 
     */
    @Export(name="sourceAccessConfigurations", refs={List.class,EventSourceMappingSourceAccessConfiguration.class}, tree="[0,1]")
    private Output</* @Nullable */ List<EventSourceMappingSourceAccessConfiguration>> sourceAccessConfigurations;

    /**
     * @return For Self Managed Kafka sources, the access configuration for the source. If set, configuration must also include `selfManagedEventSource`. See below.
     * 
     */
    public Output<Optional<List<EventSourceMappingSourceAccessConfiguration>>> sourceAccessConfigurations() {
        return Codegen.optional(this.sourceAccessConfigurations);
    }
    /**
     * Position in the stream where AWS Lambda should start reading. Must be one of `AT_TIMESTAMP` (Kinesis only), `LATEST` or `TRIM_HORIZON` if getting events from Kinesis, DynamoDB, MSK or Self Managed Apache Kafka. Must not be provided if getting events from SQS. More information about these positions can be found in the [AWS DynamoDB Streams API Reference](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_streams_GetShardIterator.html) and [AWS Kinesis API Reference](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#Kinesis-GetShardIterator-request-ShardIteratorType).
     * 
     */
    @Export(name="startingPosition", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> startingPosition;

    /**
     * @return Position in the stream where AWS Lambda should start reading. Must be one of `AT_TIMESTAMP` (Kinesis only), `LATEST` or `TRIM_HORIZON` if getting events from Kinesis, DynamoDB, MSK or Self Managed Apache Kafka. Must not be provided if getting events from SQS. More information about these positions can be found in the [AWS DynamoDB Streams API Reference](https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_streams_GetShardIterator.html) and [AWS Kinesis API Reference](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#Kinesis-GetShardIterator-request-ShardIteratorType).
     * 
     */
    public Output<Optional<String>> startingPosition() {
        return Codegen.optional(this.startingPosition);
    }
    /**
     * Timestamp in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) of the data record which to start reading when using `startingPosition` set to `AT_TIMESTAMP`. If a record with this exact timestamp does not exist, the next later record is chosen. If the timestamp is older than the current trim horizon, the oldest available record is chosen.
     * 
     */
    @Export(name="startingPositionTimestamp", refs={String.class}, tree="[0]")
    private Output</* @Nullable */ String> startingPositionTimestamp;

    /**
     * @return Timestamp in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8) of the data record which to start reading when using `startingPosition` set to `AT_TIMESTAMP`. If a record with this exact timestamp does not exist, the next later record is chosen. If the timestamp is older than the current trim horizon, the oldest available record is chosen.
     * 
     */
    public Output<Optional<String>> startingPositionTimestamp() {
        return Codegen.optional(this.startingPositionTimestamp);
    }
    /**
     * State of the event source mapping.
     * 
     */
    @Export(name="state", refs={String.class}, tree="[0]")
    private Output<String> state;

    /**
     * @return State of the event source mapping.
     * 
     */
    public Output<String> state() {
        return this.state;
    }
    /**
     * Reason the event source mapping is in its current state.
     * 
     */
    @Export(name="stateTransitionReason", refs={String.class}, tree="[0]")
    private Output<String> stateTransitionReason;

    /**
     * @return Reason the event source mapping is in its current state.
     * 
     */
    public Output<String> stateTransitionReason() {
        return this.stateTransitionReason;
    }
    /**
     * Map of tags to assign to the object. If configured with a provider `defaultTags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
     * 
     */
    @Export(name="tags", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output</* @Nullable */ Map<String,String>> tags;

    /**
     * @return Map of tags to assign to the object. If configured with a provider `defaultTags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
     * 
     */
    public Output<Optional<Map<String,String>>> tags() {
        return Codegen.optional(this.tags);
    }
    /**
     * Map of tags assigned to the resource, including those inherited from the provider `defaultTags` configuration block.
     * 
     */
    @Export(name="tagsAll", refs={Map.class,String.class}, tree="[0,1,1]")
    private Output<Map<String,String>> tagsAll;

    /**
     * @return Map of tags assigned to the resource, including those inherited from the provider `defaultTags` configuration block.
     * 
     */
    public Output<Map<String,String>> tagsAll() {
        return this.tagsAll;
    }
    /**
     * Name of the Kafka topics. Only available for MSK sources. A single topic name must be specified.
     * 
     */
    @Export(name="topics", refs={List.class,String.class}, tree="[0,1]")
    private Output</* @Nullable */ List<String>> topics;

    /**
     * @return Name of the Kafka topics. Only available for MSK sources. A single topic name must be specified.
     * 
     */
    public Output<Optional<List<String>>> topics() {
        return Codegen.optional(this.topics);
    }
    /**
     * Duration in seconds of a processing window for [AWS Lambda streaming analytics](https://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html#services-kinesis-windows). The range is between 1 second up to 900 seconds. Only available for stream sources (DynamoDB and Kinesis).
     * 
     */
    @Export(name="tumblingWindowInSeconds", refs={Integer.class}, tree="[0]")
    private Output</* @Nullable */ Integer> tumblingWindowInSeconds;

    /**
     * @return Duration in seconds of a processing window for [AWS Lambda streaming analytics](https://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html#services-kinesis-windows). The range is between 1 second up to 900 seconds. Only available for stream sources (DynamoDB and Kinesis).
     * 
     */
    public Output<Optional<Integer>> tumblingWindowInSeconds() {
        return Codegen.optional(this.tumblingWindowInSeconds);
    }
    /**
     * UUID of the created event source mapping.
     * 
     */
    @Export(name="uuid", refs={String.class}, tree="[0]")
    private Output<String> uuid;

    /**
     * @return UUID of the created event source mapping.
     * 
     */
    public Output<String> uuid() {
        return this.uuid;
    }

    /**
     *
     * @param name The _unique_ name of the resulting resource.
     */
    public EventSourceMapping(java.lang.String name) {
        this(name, EventSourceMappingArgs.Empty);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     */
    public EventSourceMapping(java.lang.String name, EventSourceMappingArgs args) {
        this(name, args, null);
    }
    /**
     *
     * @param name The _unique_ name of the resulting resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param options A bag of options that control this resource's behavior.
     */
    public EventSourceMapping(java.lang.String name, EventSourceMappingArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("aws:lambda/eventSourceMapping:EventSourceMapping", name, makeArgs(args, options), makeResourceOptions(options, Codegen.empty()), false);
    }

    private EventSourceMapping(java.lang.String name, Output<java.lang.String> id, @Nullable EventSourceMappingState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        super("aws:lambda/eventSourceMapping:EventSourceMapping", name, state, makeResourceOptions(options, id), false);
    }

    private static EventSourceMappingArgs makeArgs(EventSourceMappingArgs args, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        if (options != null && options.getUrn().isPresent()) {
            return null;
        }
        return args == null ? EventSourceMappingArgs.Empty : args;
    }

    private static com.pulumi.resources.CustomResourceOptions makeResourceOptions(@Nullable com.pulumi.resources.CustomResourceOptions options, @Nullable Output<java.lang.String> id) {
        var defaultOptions = com.pulumi.resources.CustomResourceOptions.builder()
            .version(Utilities.getVersion())
            .build();
        return com.pulumi.resources.CustomResourceOptions.merge(defaultOptions, options, id);
    }

    /**
     * Get an existing Host resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state
     * @param options Optional settings to control the behavior of the CustomResource.
     */
    public static EventSourceMapping get(java.lang.String name, Output<java.lang.String> id, @Nullable EventSourceMappingState state, @Nullable com.pulumi.resources.CustomResourceOptions options) {
        return new EventSourceMapping(name, id, state, options);
    }
}
