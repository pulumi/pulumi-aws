// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aws.sagemaker.inputs;

import com.pulumi.aws.sagemaker.inputs.EndpointConfigurationProductionVariantCoreDumpConfigArgs;
import com.pulumi.aws.sagemaker.inputs.EndpointConfigurationProductionVariantManagedInstanceScalingArgs;
import com.pulumi.aws.sagemaker.inputs.EndpointConfigurationProductionVariantRoutingConfigArgs;
import com.pulumi.aws.sagemaker.inputs.EndpointConfigurationProductionVariantServerlessConfigArgs;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Boolean;
import java.lang.Double;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class EndpointConfigurationProductionVariantArgs extends com.pulumi.resources.ResourceArgs {

    public static final EndpointConfigurationProductionVariantArgs Empty = new EndpointConfigurationProductionVariantArgs();

    /**
     * The size of the Elastic Inference (EI) instance to use for the production variant.
     * 
     */
    @Import(name="acceleratorType")
    private @Nullable Output<String> acceleratorType;

    /**
     * @return The size of the Elastic Inference (EI) instance to use for the production variant.
     * 
     */
    public Optional<Output<String>> acceleratorType() {
        return Optional.ofNullable(this.acceleratorType);
    }

    /**
     * The timeout value, in seconds, for your inference container to pass health check by SageMaker AI Hosting. For more information about health check, see [How Your Container Should Respond to Health Check (Ping) Requests](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests). Valid values between `60` and `3600`.
     * 
     */
    @Import(name="containerStartupHealthCheckTimeoutInSeconds")
    private @Nullable Output<Integer> containerStartupHealthCheckTimeoutInSeconds;

    /**
     * @return The timeout value, in seconds, for your inference container to pass health check by SageMaker AI Hosting. For more information about health check, see [How Your Container Should Respond to Health Check (Ping) Requests](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests). Valid values between `60` and `3600`.
     * 
     */
    public Optional<Output<Integer>> containerStartupHealthCheckTimeoutInSeconds() {
        return Optional.ofNullable(this.containerStartupHealthCheckTimeoutInSeconds);
    }

    /**
     * Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
     * 
     */
    @Import(name="coreDumpConfig")
    private @Nullable Output<EndpointConfigurationProductionVariantCoreDumpConfigArgs> coreDumpConfig;

    /**
     * @return Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
     * 
     */
    public Optional<Output<EndpointConfigurationProductionVariantCoreDumpConfigArgs>> coreDumpConfig() {
        return Optional.ofNullable(this.coreDumpConfig);
    }

    /**
     * You can use this parameter to turn on native Amazon Web Services Systems Manager (SSM) access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind an endpoints.
     * 
     */
    @Import(name="enableSsmAccess")
    private @Nullable Output<Boolean> enableSsmAccess;

    /**
     * @return You can use this parameter to turn on native Amazon Web Services Systems Manager (SSM) access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind an endpoints.
     * 
     */
    public Optional<Output<Boolean>> enableSsmAccess() {
        return Optional.ofNullable(this.enableSsmAccess);
    }

    /**
     * Specifies an option from a collection of preconfigured Amazon Machine Image (AMI) images. Each image is configured by Amazon Web Services with a set of software and driver versions. Amazon Web Services optimizes these configurations for different machine learning workloads.
     * 
     */
    @Import(name="inferenceAmiVersion")
    private @Nullable Output<String> inferenceAmiVersion;

    /**
     * @return Specifies an option from a collection of preconfigured Amazon Machine Image (AMI) images. Each image is configured by Amazon Web Services with a set of software and driver versions. Amazon Web Services optimizes these configurations for different machine learning workloads.
     * 
     */
    public Optional<Output<String>> inferenceAmiVersion() {
        return Optional.ofNullable(this.inferenceAmiVersion);
    }

    /**
     * Initial number of instances used for auto-scaling.
     * 
     */
    @Import(name="initialInstanceCount")
    private @Nullable Output<Integer> initialInstanceCount;

    /**
     * @return Initial number of instances used for auto-scaling.
     * 
     */
    public Optional<Output<Integer>> initialInstanceCount() {
        return Optional.ofNullable(this.initialInstanceCount);
    }

    /**
     * Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, it defaults to `1.0`.
     * 
     */
    @Import(name="initialVariantWeight")
    private @Nullable Output<Double> initialVariantWeight;

    /**
     * @return Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, it defaults to `1.0`.
     * 
     */
    public Optional<Output<Double>> initialVariantWeight() {
        return Optional.ofNullable(this.initialVariantWeight);
    }

    /**
     * The type of instance to start.
     * 
     */
    @Import(name="instanceType")
    private @Nullable Output<String> instanceType;

    /**
     * @return The type of instance to start.
     * 
     */
    public Optional<Output<String>> instanceType() {
        return Optional.ofNullable(this.instanceType);
    }

    /**
     * Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
     * 
     */
    @Import(name="managedInstanceScaling")
    private @Nullable Output<EndpointConfigurationProductionVariantManagedInstanceScalingArgs> managedInstanceScaling;

    /**
     * @return Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
     * 
     */
    public Optional<Output<EndpointConfigurationProductionVariantManagedInstanceScalingArgs>> managedInstanceScaling() {
        return Optional.ofNullable(this.managedInstanceScaling);
    }

    /**
     * The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant. Valid values between `60` and `3600`.
     * 
     */
    @Import(name="modelDataDownloadTimeoutInSeconds")
    private @Nullable Output<Integer> modelDataDownloadTimeoutInSeconds;

    /**
     * @return The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant. Valid values between `60` and `3600`.
     * 
     */
    public Optional<Output<Integer>> modelDataDownloadTimeoutInSeconds() {
        return Optional.ofNullable(this.modelDataDownloadTimeoutInSeconds);
    }

    /**
     * The name of the model to use.
     * 
     */
    @Import(name="modelName", required=true)
    private Output<String> modelName;

    /**
     * @return The name of the model to use.
     * 
     */
    public Output<String> modelName() {
        return this.modelName;
    }

    /**
     * Sets how the endpoint routes incoming traffic. See routing_config below.
     * 
     */
    @Import(name="routingConfigs")
    private @Nullable Output<List<EndpointConfigurationProductionVariantRoutingConfigArgs>> routingConfigs;

    /**
     * @return Sets how the endpoint routes incoming traffic. See routing_config below.
     * 
     */
    public Optional<Output<List<EndpointConfigurationProductionVariantRoutingConfigArgs>>> routingConfigs() {
        return Optional.ofNullable(this.routingConfigs);
    }

    /**
     * Specifies configuration for how an endpoint performs asynchronous inference.
     * 
     */
    @Import(name="serverlessConfig")
    private @Nullable Output<EndpointConfigurationProductionVariantServerlessConfigArgs> serverlessConfig;

    /**
     * @return Specifies configuration for how an endpoint performs asynchronous inference.
     * 
     */
    public Optional<Output<EndpointConfigurationProductionVariantServerlessConfigArgs>> serverlessConfig() {
        return Optional.ofNullable(this.serverlessConfig);
    }

    /**
     * The name of the variant. If omitted, this provider will assign a random, unique name.
     * 
     */
    @Import(name="variantName")
    private @Nullable Output<String> variantName;

    /**
     * @return The name of the variant. If omitted, this provider will assign a random, unique name.
     * 
     */
    public Optional<Output<String>> variantName() {
        return Optional.ofNullable(this.variantName);
    }

    /**
     * The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between `1` and `512`.
     * 
     */
    @Import(name="volumeSizeInGb")
    private @Nullable Output<Integer> volumeSizeInGb;

    /**
     * @return The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between `1` and `512`.
     * 
     */
    public Optional<Output<Integer>> volumeSizeInGb() {
        return Optional.ofNullable(this.volumeSizeInGb);
    }

    private EndpointConfigurationProductionVariantArgs() {}

    private EndpointConfigurationProductionVariantArgs(EndpointConfigurationProductionVariantArgs $) {
        this.acceleratorType = $.acceleratorType;
        this.containerStartupHealthCheckTimeoutInSeconds = $.containerStartupHealthCheckTimeoutInSeconds;
        this.coreDumpConfig = $.coreDumpConfig;
        this.enableSsmAccess = $.enableSsmAccess;
        this.inferenceAmiVersion = $.inferenceAmiVersion;
        this.initialInstanceCount = $.initialInstanceCount;
        this.initialVariantWeight = $.initialVariantWeight;
        this.instanceType = $.instanceType;
        this.managedInstanceScaling = $.managedInstanceScaling;
        this.modelDataDownloadTimeoutInSeconds = $.modelDataDownloadTimeoutInSeconds;
        this.modelName = $.modelName;
        this.routingConfigs = $.routingConfigs;
        this.serverlessConfig = $.serverlessConfig;
        this.variantName = $.variantName;
        this.volumeSizeInGb = $.volumeSizeInGb;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(EndpointConfigurationProductionVariantArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private EndpointConfigurationProductionVariantArgs $;

        public Builder() {
            $ = new EndpointConfigurationProductionVariantArgs();
        }

        public Builder(EndpointConfigurationProductionVariantArgs defaults) {
            $ = new EndpointConfigurationProductionVariantArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param acceleratorType The size of the Elastic Inference (EI) instance to use for the production variant.
         * 
         * @return builder
         * 
         */
        public Builder acceleratorType(@Nullable Output<String> acceleratorType) {
            $.acceleratorType = acceleratorType;
            return this;
        }

        /**
         * @param acceleratorType The size of the Elastic Inference (EI) instance to use for the production variant.
         * 
         * @return builder
         * 
         */
        public Builder acceleratorType(String acceleratorType) {
            return acceleratorType(Output.of(acceleratorType));
        }

        /**
         * @param containerStartupHealthCheckTimeoutInSeconds The timeout value, in seconds, for your inference container to pass health check by SageMaker AI Hosting. For more information about health check, see [How Your Container Should Respond to Health Check (Ping) Requests](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests). Valid values between `60` and `3600`.
         * 
         * @return builder
         * 
         */
        public Builder containerStartupHealthCheckTimeoutInSeconds(@Nullable Output<Integer> containerStartupHealthCheckTimeoutInSeconds) {
            $.containerStartupHealthCheckTimeoutInSeconds = containerStartupHealthCheckTimeoutInSeconds;
            return this;
        }

        /**
         * @param containerStartupHealthCheckTimeoutInSeconds The timeout value, in seconds, for your inference container to pass health check by SageMaker AI Hosting. For more information about health check, see [How Your Container Should Respond to Health Check (Ping) Requests](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests). Valid values between `60` and `3600`.
         * 
         * @return builder
         * 
         */
        public Builder containerStartupHealthCheckTimeoutInSeconds(Integer containerStartupHealthCheckTimeoutInSeconds) {
            return containerStartupHealthCheckTimeoutInSeconds(Output.of(containerStartupHealthCheckTimeoutInSeconds));
        }

        /**
         * @param coreDumpConfig Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
         * 
         * @return builder
         * 
         */
        public Builder coreDumpConfig(@Nullable Output<EndpointConfigurationProductionVariantCoreDumpConfigArgs> coreDumpConfig) {
            $.coreDumpConfig = coreDumpConfig;
            return this;
        }

        /**
         * @param coreDumpConfig Specifies configuration for a core dump from the model container when the process crashes. Fields are documented below.
         * 
         * @return builder
         * 
         */
        public Builder coreDumpConfig(EndpointConfigurationProductionVariantCoreDumpConfigArgs coreDumpConfig) {
            return coreDumpConfig(Output.of(coreDumpConfig));
        }

        /**
         * @param enableSsmAccess You can use this parameter to turn on native Amazon Web Services Systems Manager (SSM) access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind an endpoints.
         * 
         * @return builder
         * 
         */
        public Builder enableSsmAccess(@Nullable Output<Boolean> enableSsmAccess) {
            $.enableSsmAccess = enableSsmAccess;
            return this;
        }

        /**
         * @param enableSsmAccess You can use this parameter to turn on native Amazon Web Services Systems Manager (SSM) access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind an endpoints.
         * 
         * @return builder
         * 
         */
        public Builder enableSsmAccess(Boolean enableSsmAccess) {
            return enableSsmAccess(Output.of(enableSsmAccess));
        }

        /**
         * @param inferenceAmiVersion Specifies an option from a collection of preconfigured Amazon Machine Image (AMI) images. Each image is configured by Amazon Web Services with a set of software and driver versions. Amazon Web Services optimizes these configurations for different machine learning workloads.
         * 
         * @return builder
         * 
         */
        public Builder inferenceAmiVersion(@Nullable Output<String> inferenceAmiVersion) {
            $.inferenceAmiVersion = inferenceAmiVersion;
            return this;
        }

        /**
         * @param inferenceAmiVersion Specifies an option from a collection of preconfigured Amazon Machine Image (AMI) images. Each image is configured by Amazon Web Services with a set of software and driver versions. Amazon Web Services optimizes these configurations for different machine learning workloads.
         * 
         * @return builder
         * 
         */
        public Builder inferenceAmiVersion(String inferenceAmiVersion) {
            return inferenceAmiVersion(Output.of(inferenceAmiVersion));
        }

        /**
         * @param initialInstanceCount Initial number of instances used for auto-scaling.
         * 
         * @return builder
         * 
         */
        public Builder initialInstanceCount(@Nullable Output<Integer> initialInstanceCount) {
            $.initialInstanceCount = initialInstanceCount;
            return this;
        }

        /**
         * @param initialInstanceCount Initial number of instances used for auto-scaling.
         * 
         * @return builder
         * 
         */
        public Builder initialInstanceCount(Integer initialInstanceCount) {
            return initialInstanceCount(Output.of(initialInstanceCount));
        }

        /**
         * @param initialVariantWeight Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, it defaults to `1.0`.
         * 
         * @return builder
         * 
         */
        public Builder initialVariantWeight(@Nullable Output<Double> initialVariantWeight) {
            $.initialVariantWeight = initialVariantWeight;
            return this;
        }

        /**
         * @param initialVariantWeight Determines initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, it defaults to `1.0`.
         * 
         * @return builder
         * 
         */
        public Builder initialVariantWeight(Double initialVariantWeight) {
            return initialVariantWeight(Output.of(initialVariantWeight));
        }

        /**
         * @param instanceType The type of instance to start.
         * 
         * @return builder
         * 
         */
        public Builder instanceType(@Nullable Output<String> instanceType) {
            $.instanceType = instanceType;
            return this;
        }

        /**
         * @param instanceType The type of instance to start.
         * 
         * @return builder
         * 
         */
        public Builder instanceType(String instanceType) {
            return instanceType(Output.of(instanceType));
        }

        /**
         * @param managedInstanceScaling Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
         * 
         * @return builder
         * 
         */
        public Builder managedInstanceScaling(@Nullable Output<EndpointConfigurationProductionVariantManagedInstanceScalingArgs> managedInstanceScaling) {
            $.managedInstanceScaling = managedInstanceScaling;
            return this;
        }

        /**
         * @param managedInstanceScaling Settings that control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
         * 
         * @return builder
         * 
         */
        public Builder managedInstanceScaling(EndpointConfigurationProductionVariantManagedInstanceScalingArgs managedInstanceScaling) {
            return managedInstanceScaling(Output.of(managedInstanceScaling));
        }

        /**
         * @param modelDataDownloadTimeoutInSeconds The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant. Valid values between `60` and `3600`.
         * 
         * @return builder
         * 
         */
        public Builder modelDataDownloadTimeoutInSeconds(@Nullable Output<Integer> modelDataDownloadTimeoutInSeconds) {
            $.modelDataDownloadTimeoutInSeconds = modelDataDownloadTimeoutInSeconds;
            return this;
        }

        /**
         * @param modelDataDownloadTimeoutInSeconds The timeout value, in seconds, to download and extract the model that you want to host from Amazon S3 to the individual inference instance associated with this production variant. Valid values between `60` and `3600`.
         * 
         * @return builder
         * 
         */
        public Builder modelDataDownloadTimeoutInSeconds(Integer modelDataDownloadTimeoutInSeconds) {
            return modelDataDownloadTimeoutInSeconds(Output.of(modelDataDownloadTimeoutInSeconds));
        }

        /**
         * @param modelName The name of the model to use.
         * 
         * @return builder
         * 
         */
        public Builder modelName(Output<String> modelName) {
            $.modelName = modelName;
            return this;
        }

        /**
         * @param modelName The name of the model to use.
         * 
         * @return builder
         * 
         */
        public Builder modelName(String modelName) {
            return modelName(Output.of(modelName));
        }

        /**
         * @param routingConfigs Sets how the endpoint routes incoming traffic. See routing_config below.
         * 
         * @return builder
         * 
         */
        public Builder routingConfigs(@Nullable Output<List<EndpointConfigurationProductionVariantRoutingConfigArgs>> routingConfigs) {
            $.routingConfigs = routingConfigs;
            return this;
        }

        /**
         * @param routingConfigs Sets how the endpoint routes incoming traffic. See routing_config below.
         * 
         * @return builder
         * 
         */
        public Builder routingConfigs(List<EndpointConfigurationProductionVariantRoutingConfigArgs> routingConfigs) {
            return routingConfigs(Output.of(routingConfigs));
        }

        /**
         * @param routingConfigs Sets how the endpoint routes incoming traffic. See routing_config below.
         * 
         * @return builder
         * 
         */
        public Builder routingConfigs(EndpointConfigurationProductionVariantRoutingConfigArgs... routingConfigs) {
            return routingConfigs(List.of(routingConfigs));
        }

        /**
         * @param serverlessConfig Specifies configuration for how an endpoint performs asynchronous inference.
         * 
         * @return builder
         * 
         */
        public Builder serverlessConfig(@Nullable Output<EndpointConfigurationProductionVariantServerlessConfigArgs> serverlessConfig) {
            $.serverlessConfig = serverlessConfig;
            return this;
        }

        /**
         * @param serverlessConfig Specifies configuration for how an endpoint performs asynchronous inference.
         * 
         * @return builder
         * 
         */
        public Builder serverlessConfig(EndpointConfigurationProductionVariantServerlessConfigArgs serverlessConfig) {
            return serverlessConfig(Output.of(serverlessConfig));
        }

        /**
         * @param variantName The name of the variant. If omitted, this provider will assign a random, unique name.
         * 
         * @return builder
         * 
         */
        public Builder variantName(@Nullable Output<String> variantName) {
            $.variantName = variantName;
            return this;
        }

        /**
         * @param variantName The name of the variant. If omitted, this provider will assign a random, unique name.
         * 
         * @return builder
         * 
         */
        public Builder variantName(String variantName) {
            return variantName(Output.of(variantName));
        }

        /**
         * @param volumeSizeInGb The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between `1` and `512`.
         * 
         * @return builder
         * 
         */
        public Builder volumeSizeInGb(@Nullable Output<Integer> volumeSizeInGb) {
            $.volumeSizeInGb = volumeSizeInGb;
            return this;
        }

        /**
         * @param volumeSizeInGb The size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between `1` and `512`.
         * 
         * @return builder
         * 
         */
        public Builder volumeSizeInGb(Integer volumeSizeInGb) {
            return volumeSizeInGb(Output.of(volumeSizeInGb));
        }

        public EndpointConfigurationProductionVariantArgs build() {
            if ($.modelName == null) {
                throw new MissingRequiredPropertyException("EndpointConfigurationProductionVariantArgs", "modelName");
            }
            return $;
        }
    }

}
