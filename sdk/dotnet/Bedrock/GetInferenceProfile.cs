// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aws.Bedrock
{
    public static class GetInferenceProfile
    {
        /// <summary>
        /// Data source for managing an AWS Bedrock Inference Profile.
        /// 
        /// ## Example Usage
        /// 
        /// ### Basic Usage
        /// 
        /// ```csharp
        /// using System.Collections.Generic;
        /// using System.Linq;
        /// using Pulumi;
        /// using Aws = Pulumi.Aws;
        /// 
        /// return await Deployment.RunAsync(() =&gt; 
        /// {
        ///     var test = Aws.Bedrock.GetInferenceProfiles.Invoke();
        /// 
        ///     var testGetInferenceProfile = Aws.Bedrock.GetInferenceProfile.Invoke(new()
        ///     {
        ///         InferenceProfileId = test.Apply(getInferenceProfilesResult =&gt; getInferenceProfilesResult.InferenceProfileSummaries[0]?.InferenceProfileId),
        ///     });
        /// 
        /// });
        /// ```
        /// </summary>
        public static Task<GetInferenceProfileResult> InvokeAsync(GetInferenceProfileArgs args, InvokeOptions? options = null)
            => global::Pulumi.Deployment.Instance.InvokeAsync<GetInferenceProfileResult>("aws:bedrock/getInferenceProfile:getInferenceProfile", args ?? new GetInferenceProfileArgs(), options.WithDefaults());

        /// <summary>
        /// Data source for managing an AWS Bedrock Inference Profile.
        /// 
        /// ## Example Usage
        /// 
        /// ### Basic Usage
        /// 
        /// ```csharp
        /// using System.Collections.Generic;
        /// using System.Linq;
        /// using Pulumi;
        /// using Aws = Pulumi.Aws;
        /// 
        /// return await Deployment.RunAsync(() =&gt; 
        /// {
        ///     var test = Aws.Bedrock.GetInferenceProfiles.Invoke();
        /// 
        ///     var testGetInferenceProfile = Aws.Bedrock.GetInferenceProfile.Invoke(new()
        ///     {
        ///         InferenceProfileId = test.Apply(getInferenceProfilesResult =&gt; getInferenceProfilesResult.InferenceProfileSummaries[0]?.InferenceProfileId),
        ///     });
        /// 
        /// });
        /// ```
        /// </summary>
        public static Output<GetInferenceProfileResult> Invoke(GetInferenceProfileInvokeArgs args, InvokeOptions? options = null)
            => global::Pulumi.Deployment.Instance.Invoke<GetInferenceProfileResult>("aws:bedrock/getInferenceProfile:getInferenceProfile", args ?? new GetInferenceProfileInvokeArgs(), options.WithDefaults());

        /// <summary>
        /// Data source for managing an AWS Bedrock Inference Profile.
        /// 
        /// ## Example Usage
        /// 
        /// ### Basic Usage
        /// 
        /// ```csharp
        /// using System.Collections.Generic;
        /// using System.Linq;
        /// using Pulumi;
        /// using Aws = Pulumi.Aws;
        /// 
        /// return await Deployment.RunAsync(() =&gt; 
        /// {
        ///     var test = Aws.Bedrock.GetInferenceProfiles.Invoke();
        /// 
        ///     var testGetInferenceProfile = Aws.Bedrock.GetInferenceProfile.Invoke(new()
        ///     {
        ///         InferenceProfileId = test.Apply(getInferenceProfilesResult =&gt; getInferenceProfilesResult.InferenceProfileSummaries[0]?.InferenceProfileId),
        ///     });
        /// 
        /// });
        /// ```
        /// </summary>
        public static Output<GetInferenceProfileResult> Invoke(GetInferenceProfileInvokeArgs args, InvokeOutputOptions options)
            => global::Pulumi.Deployment.Instance.Invoke<GetInferenceProfileResult>("aws:bedrock/getInferenceProfile:getInferenceProfile", args ?? new GetInferenceProfileInvokeArgs(), options.WithDefaults());
    }


    public sealed class GetInferenceProfileArgs : global::Pulumi.InvokeArgs
    {
        /// <summary>
        /// Inference Profile identifier.
        /// </summary>
        [Input("inferenceProfileId", required: true)]
        public string InferenceProfileId { get; set; } = null!;

        public GetInferenceProfileArgs()
        {
        }
        public static new GetInferenceProfileArgs Empty => new GetInferenceProfileArgs();
    }

    public sealed class GetInferenceProfileInvokeArgs : global::Pulumi.InvokeArgs
    {
        /// <summary>
        /// Inference Profile identifier.
        /// </summary>
        [Input("inferenceProfileId", required: true)]
        public Input<string> InferenceProfileId { get; set; } = null!;

        public GetInferenceProfileInvokeArgs()
        {
        }
        public static new GetInferenceProfileInvokeArgs Empty => new GetInferenceProfileInvokeArgs();
    }


    [OutputType]
    public sealed class GetInferenceProfileResult
    {
        /// <summary>
        /// The time at which the inference profile was created.
        /// </summary>
        public readonly string CreatedAt;
        /// <summary>
        /// The description of the inference profile.
        /// </summary>
        public readonly string Description;
        /// <summary>
        /// The provider-assigned unique ID for this managed resource.
        /// </summary>
        public readonly string Id;
        /// <summary>
        /// The Amazon Resource Name (ARN) of the inference profile.
        /// </summary>
        public readonly string InferenceProfileArn;
        public readonly string InferenceProfileId;
        /// <summary>
        /// The unique identifier of the inference profile.
        /// </summary>
        public readonly string InferenceProfileName;
        /// <summary>
        /// A list of information about each model in the inference profile. See `models`.
        /// </summary>
        public readonly ImmutableArray<Outputs.GetInferenceProfileModelResult> Models;
        /// <summary>
        /// The status of the inference profile. `ACTIVE` means that the inference profile is available to use.
        /// </summary>
        public readonly string Status;
        /// <summary>
        /// The type of the inference profile. `SYSTEM_DEFINED` means that the inference profile is defined by Amazon Bedrock. `APPLICATION` means that the inference profile is defined by the user.
        /// </summary>
        public readonly string Type;
        /// <summary>
        /// The time at which the inference profile was last updated.
        /// </summary>
        public readonly string UpdatedAt;

        [OutputConstructor]
        private GetInferenceProfileResult(
            string createdAt,

            string description,

            string id,

            string inferenceProfileArn,

            string inferenceProfileId,

            string inferenceProfileName,

            ImmutableArray<Outputs.GetInferenceProfileModelResult> models,

            string status,

            string type,

            string updatedAt)
        {
            CreatedAt = createdAt;
            Description = description;
            Id = id;
            InferenceProfileArn = inferenceProfileArn;
            InferenceProfileId = inferenceProfileId;
            InferenceProfileName = inferenceProfileName;
            Models = models;
            Status = status;
            Type = type;
            UpdatedAt = updatedAt;
        }
    }
}
