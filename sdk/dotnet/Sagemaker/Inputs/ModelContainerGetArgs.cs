// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aws.Sagemaker.Inputs
{

    public sealed class ModelContainerGetArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The DNS host name for the container.
        /// </summary>
        [Input("containerHostname")]
        public Input<string>? ContainerHostname { get; set; }

        [Input("environment")]
        private InputMap<string>? _environment;

        /// <summary>
        /// Environment variables for the Docker container.
        /// A list of key value pairs.
        /// </summary>
        public InputMap<string> Environment
        {
            get => _environment ?? (_environment = new InputMap<string>());
            set => _environment = value;
        }

        /// <summary>
        /// The registry path where the inference code image is stored in Amazon ECR.
        /// </summary>
        [Input("image")]
        public Input<string>? Image { get; set; }

        /// <summary>
        /// Specifies whether the model container is in Amazon ECR or a private Docker registry accessible from your Amazon Virtual Private Cloud (VPC). For more information see [Using a Private Docker Registry for Real-Time Inference Containers](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-containers-inference-private.html). see Image Config.
        /// </summary>
        [Input("imageConfig")]
        public Input<Inputs.ModelContainerImageConfigGetArgs>? ImageConfig { get; set; }

        /// <summary>
        /// The inference specification name in the model package version.
        /// </summary>
        [Input("inferenceSpecificationName")]
        public Input<string>? InferenceSpecificationName { get; set; }

        /// <summary>
        /// The container hosts value `SingleModel/MultiModel`. The default value is `SingleModel`.
        /// </summary>
        [Input("mode")]
        public Input<string>? Mode { get; set; }

        /// <summary>
        /// The location of model data to deploy. Use this for uncompressed model deployment. For information about how to deploy an uncompressed model, see [Deploying uncompressed models](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-uncompressed.html) in the _AWS SageMaker AI Developer Guide_.
        /// </summary>
        [Input("modelDataSource")]
        public Input<Inputs.ModelContainerModelDataSourceGetArgs>? ModelDataSource { get; set; }

        /// <summary>
        /// The URL for the S3 location where model artifacts are stored.
        /// </summary>
        [Input("modelDataUrl")]
        public Input<string>? ModelDataUrl { get; set; }

        /// <summary>
        /// The Amazon Resource Name (ARN) of the model package to use to create the model.
        /// </summary>
        [Input("modelPackageName")]
        public Input<string>? ModelPackageName { get; set; }

        /// <summary>
        /// Specifies additional configuration for multi-model endpoints. see Multi Model Config.
        /// </summary>
        [Input("multiModelConfig")]
        public Input<Inputs.ModelContainerMultiModelConfigGetArgs>? MultiModelConfig { get; set; }

        public ModelContainerGetArgs()
        {
        }
        public static new ModelContainerGetArgs Empty => new ModelContainerGetArgs();
    }
}
