// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aws.Sagemaker.Outputs
{

    [OutputType]
    public sealed class EndpointConfigurationProductionVariant
    {
        /// <summary>
        /// Size of the Elastic Inference (EI) instance to use for the production variant.
        /// </summary>
        public readonly string? AcceleratorType;
        /// <summary>
        /// Timeout value, in seconds, for your inference container to pass health check by SageMaker AI Hosting. For more information about health check, see [How Your Container Should Respond to Health Check (Ping) Requests](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-algo-ping-requests). Valid values between `60` and `3600`.
        /// </summary>
        public readonly int? ContainerStartupHealthCheckTimeoutInSeconds;
        /// <summary>
        /// Core dump configuration from the model container when the process crashes. Fields are documented below.
        /// </summary>
        public readonly Outputs.EndpointConfigurationProductionVariantCoreDumpConfig? CoreDumpConfig;
        /// <summary>
        /// Whether to turn on native AWS SSM access for a production variant behind an endpoint. By default, SSM access is disabled for all production variants behind endpoints. Ignored if `ModelName` is not set (Inference Components endpoint).
        /// </summary>
        public readonly bool? EnableSsmAccess;
        /// <summary>
        /// Option from a collection of preconfigured AMI images. Each image is configured by AWS with a set of software and driver versions. AWS optimizes these configurations for different machine learning workloads.
        /// </summary>
        public readonly string? InferenceAmiVersion;
        /// <summary>
        /// Initial number of instances used for auto-scaling.
        /// </summary>
        public readonly int? InitialInstanceCount;
        /// <summary>
        /// Initial traffic distribution among all of the models that you specify in the endpoint configuration. If unspecified, defaults to `1.0`. Ignored if `ModelName` is not set (Inference Components endpoint).
        /// </summary>
        public readonly double? InitialVariantWeight;
        /// <summary>
        /// Type of instance to start.
        /// </summary>
        public readonly string? InstanceType;
        /// <summary>
        /// Control the range in the number of instances that the endpoint provisions as it scales up or down to accommodate traffic.
        /// </summary>
        public readonly Outputs.EndpointConfigurationProductionVariantManagedInstanceScaling? ManagedInstanceScaling;
        /// <summary>
        /// Timeout value, in seconds, to download and extract the model that you want to host from S3 to the individual inference instance associated with this production variant. Valid values between `60` and `3600`.
        /// </summary>
        public readonly int? ModelDataDownloadTimeoutInSeconds;
        /// <summary>
        /// Name of the model to use. Required unless using Inference Components (in which case `ExecutionRoleArn` must be specified at the endpoint configuration level).
        /// </summary>
        public readonly string? ModelName;
        /// <summary>
        /// How the endpoint routes incoming traffic. See RoutingConfig below.
        /// </summary>
        public readonly ImmutableArray<Outputs.EndpointConfigurationProductionVariantRoutingConfig> RoutingConfigs;
        /// <summary>
        /// How an endpoint performs asynchronous inference.
        /// </summary>
        public readonly Outputs.EndpointConfigurationProductionVariantServerlessConfig? ServerlessConfig;
        /// <summary>
        /// Name of the variant. If omitted, the provider will assign a random, unique name.
        /// </summary>
        public readonly string? VariantName;
        /// <summary>
        /// Size, in GB, of the ML storage volume attached to individual inference instance associated with the production variant. Valid values between `1` and `512`.
        /// </summary>
        public readonly int? VolumeSizeInGb;

        [OutputConstructor]
        private EndpointConfigurationProductionVariant(
            string? acceleratorType,

            int? containerStartupHealthCheckTimeoutInSeconds,

            Outputs.EndpointConfigurationProductionVariantCoreDumpConfig? coreDumpConfig,

            bool? enableSsmAccess,

            string? inferenceAmiVersion,

            int? initialInstanceCount,

            double? initialVariantWeight,

            string? instanceType,

            Outputs.EndpointConfigurationProductionVariantManagedInstanceScaling? managedInstanceScaling,

            int? modelDataDownloadTimeoutInSeconds,

            string? modelName,

            ImmutableArray<Outputs.EndpointConfigurationProductionVariantRoutingConfig> routingConfigs,

            Outputs.EndpointConfigurationProductionVariantServerlessConfig? serverlessConfig,

            string? variantName,

            int? volumeSizeInGb)
        {
            AcceleratorType = acceleratorType;
            ContainerStartupHealthCheckTimeoutInSeconds = containerStartupHealthCheckTimeoutInSeconds;
            CoreDumpConfig = coreDumpConfig;
            EnableSsmAccess = enableSsmAccess;
            InferenceAmiVersion = inferenceAmiVersion;
            InitialInstanceCount = initialInstanceCount;
            InitialVariantWeight = initialVariantWeight;
            InstanceType = instanceType;
            ManagedInstanceScaling = managedInstanceScaling;
            ModelDataDownloadTimeoutInSeconds = modelDataDownloadTimeoutInSeconds;
            ModelName = modelName;
            RoutingConfigs = routingConfigs;
            ServerlessConfig = serverlessConfig;
            VariantName = variantName;
            VolumeSizeInGb = volumeSizeInGb;
        }
    }
}
