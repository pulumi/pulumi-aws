// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aws.Amp
{
    /// <summary>
    /// &gt; **Note:** If you change a Scraper's source (EKS cluster), Terraform
    /// will delete the current Scraper and create a new one.
    /// 
    /// Provides an Amazon Managed Service for Prometheus fully managed collector
    /// (scraper).
    /// 
    /// Read more in the [Amazon Managed Service for Prometheus user guide](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector.html).
    /// 
    /// ## Example Usage
    /// 
    /// ### Basic Usage
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Aws = Pulumi.Aws;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var example = new Aws.Amp.Scraper("example", new()
    ///     {
    ///         Source = new Aws.Amp.Inputs.ScraperSourceArgs
    ///         {
    ///             Eks = new Aws.Amp.Inputs.ScraperSourceEksArgs
    ///             {
    ///                 ClusterArn = exampleAwsEksCluster.Arn,
    ///                 SubnetIds = exampleAwsEksCluster.VpcConfig[0].SubnetIds,
    ///             },
    ///         },
    ///         Destination = new Aws.Amp.Inputs.ScraperDestinationArgs
    ///         {
    ///             Amp = new Aws.Amp.Inputs.ScraperDestinationAmpArgs
    ///             {
    ///                 WorkspaceArn = exampleAwsPrometheusWorkspace.Arn,
    ///             },
    ///         },
    ///         ScrapeConfiguration = @"global:
    ///   scrape_interval: 30s
    /// scrape_configs:
    ///   # pod metrics
    ///   - job_name: pod_exporter
    ///     kubernetes_sd_configs:
    ///       - role: pod
    ///   # container metrics
    ///   - job_name: cadvisor
    ///     scheme: https
    ///     authorization:
    ///       credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    ///     kubernetes_sd_configs:
    ///       - role: node
    ///     relabel_configs:
    ///       - action: labelmap
    ///         regex: __meta_kubernetes_node_label_(.+)
    ///       - replacement: kubernetes.default.svc:443
    ///         target_label: __address__
    ///       - source_labels: [__meta_kubernetes_node_name]
    ///         regex: (.+)
    ///         target_label: __metrics_path__
    ///         replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
    ///   # apiserver metrics
    ///   - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    ///     job_name: kubernetes-apiservers
    ///     kubernetes_sd_configs:
    ///     - role: endpoints
    ///     relabel_configs:
    ///     - action: keep
    ///       regex: default;kubernetes;https
    ///       source_labels:
    ///       - __meta_kubernetes_namespace
    ///       - __meta_kubernetes_service_name
    ///       - __meta_kubernetes_endpoint_port_name
    ///     scheme: https
    ///   # kube proxy metrics
    ///   - job_name: kube-proxy
    ///     honor_labels: true
    ///     kubernetes_sd_configs:
    ///     - role: pod
    ///     relabel_configs:
    ///     - action: keep
    ///       source_labels:
    ///       - __meta_kubernetes_namespace
    ///       - __meta_kubernetes_pod_name
    ///       separator: '/'
    ///       regex: 'kube-system/kube-proxy.+'
    ///     - source_labels:
    ///       - __address__
    ///       action: replace
    ///       target_label: __address__
    ///       regex: (.+?)(\\\\:\\\\d+)?
    ///       replacement: $1:10249
    /// ",
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ### Use default EKS scraper configuration
    /// 
    /// You can use the data source `AwsPrometheusScraperConfiguration` to use a
    /// service managed scrape configuration.
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Aws = Pulumi.Aws;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var example = Aws.Amp.GetDefaultScraperConfiguration.Invoke();
    /// 
    ///     var exampleScraper = new Aws.Amp.Scraper("example", new()
    ///     {
    ///         Destination = new Aws.Amp.Inputs.ScraperDestinationArgs
    ///         {
    ///             Amp = new Aws.Amp.Inputs.ScraperDestinationAmpArgs
    ///             {
    ///                 WorkspaceArn = exampleAwsPrometheusWorkspace.Arn,
    ///             },
    ///         },
    ///         ScrapeConfiguration = exampleAwsPrometheusScraperConfiguration.Configuration,
    ///         Source = new Aws.Amp.Inputs.ScraperSourceArgs
    ///         {
    ///             Eks = new Aws.Amp.Inputs.ScraperSourceEksArgs
    ///             {
    ///                 ClusterArn = exampleAwsEksCluster.Arn,
    ///                 SubnetIds = exampleAwsEksCluster.VpcConfig[0].SubnetIds,
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ### Ignoring changes to Prometheus Workspace destination
    /// 
    /// A managed scraper will add a `AMPAgentlessScraper` tag to its Prometheus workspace
    /// destination. To avoid Terraform state forcing removing the tag from the workspace,
    /// you can add this tag to the destination workspace (preferred) or ignore tags
    /// changes with `Lifecycle`. See example below.
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Aws = Pulumi.Aws;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var @this = Aws.Eks.GetCluster.Invoke(new()
    ///     {
    ///         Name = "example",
    ///     });
    /// 
    ///     var example = new Aws.Amp.Workspace("example", new()
    ///     {
    ///         Tags = 
    ///         {
    ///             { "AMPAgentlessScraper", "" },
    ///         },
    ///     });
    /// 
    ///     var exampleScraper = new Aws.Amp.Scraper("example", new()
    ///     {
    ///         Source = new Aws.Amp.Inputs.ScraperSourceArgs
    ///         {
    ///             Eks = new Aws.Amp.Inputs.ScraperSourceEksArgs
    ///             {
    ///                 ClusterArn = exampleAwsEksCluster.Arn,
    ///                 SubnetIds = exampleAwsEksCluster.VpcConfig[0].SubnetIds,
    ///             },
    ///         },
    ///         ScrapeConfiguration = "...",
    ///         Destination = new Aws.Amp.Inputs.ScraperDestinationArgs
    ///         {
    ///             Amp = new Aws.Amp.Inputs.ScraperDestinationAmpArgs
    ///             {
    ///                 WorkspaceArn = example.Arn,
    ///             },
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ### Configure aws-auth
    /// 
    /// Your source Amazon EKS cluster must be configured to allow the scraper to access
    /// metrics. Follow the [user guide](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector-how-to.html#AMP-collector-eks-setup)
    /// to setup the appropriate Kubernetes permissions.
    /// 
    /// ### Cross-Account Configuration
    /// 
    /// This setup allows the scraper, running in a source account, to remote write its collected metrics to a workspace in a target account. Note that:
    /// 
    /// - The target Role and target Workspace must be in the same account
    /// - The source Scraper and target Workspace must be in the same Region
    /// 
    /// Follow [the AWS Best Practices guide](https://aws-observability.github.io/observability-best-practices/patterns/ampxa) to learn about the IAM roles configuration and overall setup.
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Aws = Pulumi.Aws;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var example = new Aws.Amp.Scraper("example", new()
    ///     {
    ///         Source = new Aws.Amp.Inputs.ScraperSourceArgs
    ///         {
    ///             Eks = new Aws.Amp.Inputs.ScraperSourceEksArgs
    ///             {
    ///                 ClusterArn = exampleAwsEksCluster.Arn,
    ///                 SubnetIds = exampleAwsEksCluster.VpcConfig[0].SubnetIds,
    ///             },
    ///         },
    ///         Destination = new Aws.Amp.Inputs.ScraperDestinationArgs
    ///         {
    ///             Amp = new Aws.Amp.Inputs.ScraperDestinationAmpArgs
    ///             {
    ///                 WorkspaceArn = "&lt;target_account_workspace_arn&gt;",
    ///             },
    ///         },
    ///         RoleConfiguration = new Aws.Amp.Inputs.ScraperRoleConfigurationArgs
    ///         {
    ///             SourceRoleArn = source.Arn,
    ///             TargetRoleArn = "arn:aws:iam::ACCOUNT-ID:role/target-role-name",
    ///         },
    ///         ScrapeConfiguration = "...",
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Import
    /// 
    /// Using `pulumi import`, import the Managed Scraper using its identifier.
    /// For example:
    /// 
    /// ```sh
    /// $ pulumi import aws:amp/scraper:Scraper example s-0123abc-0000-0123-a000-000000000000
    /// ```
    /// </summary>
    [AwsResourceType("aws:amp/scraper:Scraper")]
    public partial class Scraper : global::Pulumi.CustomResource
    {
        /// <summary>
        /// a name to associate with the managed scraper. This is for your use, and does not need to be unique.
        /// </summary>
        [Output("alias")]
        public Output<string?> Alias { get; private set; } = null!;

        /// <summary>
        /// The Amazon Resource Name (ARN) of the new scraper.
        /// </summary>
        [Output("arn")]
        public Output<string> Arn { get; private set; } = null!;

        /// <summary>
        /// Configuration block for the managed scraper to send metrics to. See `Destination`.
        /// </summary>
        [Output("destination")]
        public Output<Outputs.ScraperDestination> Destination { get; private set; } = null!;

        /// <summary>
        /// Region where this resource will be [managed](https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints). Defaults to the Region set in the provider configuration.
        /// </summary>
        [Output("region")]
        public Output<string> Region { get; private set; } = null!;

        /// <summary>
        /// The Amazon Resource Name (ARN) of the IAM role that provides permissions for the scraper to discover, collect, and produce metrics
        /// </summary>
        [Output("roleArn")]
        public Output<string> RoleArn { get; private set; } = null!;

        /// <summary>
        /// Configuration block to enable writing to an Amazon Managed Service for Prometheus workspace in a different account. See `RoleConfiguration` below.
        /// </summary>
        [Output("roleConfiguration")]
        public Output<Outputs.ScraperRoleConfiguration?> RoleConfiguration { get; private set; } = null!;

        /// <summary>
        /// The configuration file to use in the new scraper. For more information, see [Scraper configuration](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector-how-to.html#AMP-collector-configuration).
        /// </summary>
        [Output("scrapeConfiguration")]
        public Output<string> ScrapeConfiguration { get; private set; } = null!;

        /// <summary>
        /// Configuration block to specify where the managed scraper will collect metrics from. See `Source`.
        /// 
        /// The following arguments are optional:
        /// </summary>
        [Output("source")]
        public Output<Outputs.ScraperSource?> Source { get; private set; } = null!;

        [Output("tags")]
        public Output<ImmutableDictionary<string, string>?> Tags { get; private set; } = null!;

        [Output("tagsAll")]
        public Output<ImmutableDictionary<string, string>> TagsAll { get; private set; } = null!;

        [Output("timeouts")]
        public Output<Outputs.ScraperTimeouts?> Timeouts { get; private set; } = null!;


        /// <summary>
        /// Create a Scraper resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public Scraper(string name, ScraperArgs args, CustomResourceOptions? options = null)
            : base("aws:amp/scraper:Scraper", name, args ?? new ScraperArgs(), MakeResourceOptions(options, ""))
        {
        }

        private Scraper(string name, Input<string> id, ScraperState? state = null, CustomResourceOptions? options = null)
            : base("aws:amp/scraper:Scraper", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing Scraper resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static Scraper Get(string name, Input<string> id, ScraperState? state = null, CustomResourceOptions? options = null)
        {
            return new Scraper(name, id, state, options);
        }
    }

    public sealed class ScraperArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// a name to associate with the managed scraper. This is for your use, and does not need to be unique.
        /// </summary>
        [Input("alias")]
        public Input<string>? Alias { get; set; }

        /// <summary>
        /// Configuration block for the managed scraper to send metrics to. See `Destination`.
        /// </summary>
        [Input("destination", required: true)]
        public Input<Inputs.ScraperDestinationArgs> Destination { get; set; } = null!;

        /// <summary>
        /// Region where this resource will be [managed](https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints). Defaults to the Region set in the provider configuration.
        /// </summary>
        [Input("region")]
        public Input<string>? Region { get; set; }

        /// <summary>
        /// Configuration block to enable writing to an Amazon Managed Service for Prometheus workspace in a different account. See `RoleConfiguration` below.
        /// </summary>
        [Input("roleConfiguration")]
        public Input<Inputs.ScraperRoleConfigurationArgs>? RoleConfiguration { get; set; }

        /// <summary>
        /// The configuration file to use in the new scraper. For more information, see [Scraper configuration](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector-how-to.html#AMP-collector-configuration).
        /// </summary>
        [Input("scrapeConfiguration", required: true)]
        public Input<string> ScrapeConfiguration { get; set; } = null!;

        /// <summary>
        /// Configuration block to specify where the managed scraper will collect metrics from. See `Source`.
        /// 
        /// The following arguments are optional:
        /// </summary>
        [Input("source")]
        public Input<Inputs.ScraperSourceArgs>? Source { get; set; }

        [Input("tags")]
        private InputMap<string>? _tags;
        public InputMap<string> Tags
        {
            get => _tags ?? (_tags = new InputMap<string>());
            set => _tags = value;
        }

        [Input("timeouts")]
        public Input<Inputs.ScraperTimeoutsArgs>? Timeouts { get; set; }

        public ScraperArgs()
        {
        }
        public static new ScraperArgs Empty => new ScraperArgs();
    }

    public sealed class ScraperState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// a name to associate with the managed scraper. This is for your use, and does not need to be unique.
        /// </summary>
        [Input("alias")]
        public Input<string>? Alias { get; set; }

        /// <summary>
        /// The Amazon Resource Name (ARN) of the new scraper.
        /// </summary>
        [Input("arn")]
        public Input<string>? Arn { get; set; }

        /// <summary>
        /// Configuration block for the managed scraper to send metrics to. See `Destination`.
        /// </summary>
        [Input("destination")]
        public Input<Inputs.ScraperDestinationGetArgs>? Destination { get; set; }

        /// <summary>
        /// Region where this resource will be [managed](https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints). Defaults to the Region set in the provider configuration.
        /// </summary>
        [Input("region")]
        public Input<string>? Region { get; set; }

        /// <summary>
        /// The Amazon Resource Name (ARN) of the IAM role that provides permissions for the scraper to discover, collect, and produce metrics
        /// </summary>
        [Input("roleArn")]
        public Input<string>? RoleArn { get; set; }

        /// <summary>
        /// Configuration block to enable writing to an Amazon Managed Service for Prometheus workspace in a different account. See `RoleConfiguration` below.
        /// </summary>
        [Input("roleConfiguration")]
        public Input<Inputs.ScraperRoleConfigurationGetArgs>? RoleConfiguration { get; set; }

        /// <summary>
        /// The configuration file to use in the new scraper. For more information, see [Scraper configuration](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector-how-to.html#AMP-collector-configuration).
        /// </summary>
        [Input("scrapeConfiguration")]
        public Input<string>? ScrapeConfiguration { get; set; }

        /// <summary>
        /// Configuration block to specify where the managed scraper will collect metrics from. See `Source`.
        /// 
        /// The following arguments are optional:
        /// </summary>
        [Input("source")]
        public Input<Inputs.ScraperSourceGetArgs>? Source { get; set; }

        [Input("tags")]
        private InputMap<string>? _tags;
        public InputMap<string> Tags
        {
            get => _tags ?? (_tags = new InputMap<string>());
            set => _tags = value;
        }

        [Input("tagsAll")]
        private InputMap<string>? _tagsAll;
        public InputMap<string> TagsAll
        {
            get => _tagsAll ?? (_tagsAll = new InputMap<string>());
            set => _tagsAll = value;
        }

        [Input("timeouts")]
        public Input<Inputs.ScraperTimeoutsGetArgs>? Timeouts { get; set; }

        public ScraperState()
        {
        }
        public static new ScraperState Empty => new ScraperState();
    }
}
