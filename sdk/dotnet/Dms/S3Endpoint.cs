// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aws.Dms
{
    /// <summary>
    /// Provides a DMS (Data Migration Service) S3 endpoint resource. DMS S3 endpoints can be created, updated, deleted, and imported.
    /// 
    /// &gt; **Note:** AWS is deprecating `extra_connection_attributes`, such as used with `aws.dms.Endpoint`. This resource is an alternative to `aws.dms.Endpoint` and does not use `extra_connection_attributes`. (AWS currently includes `extra_connection_attributes` in the raw responses to the AWS Provider requests and so they may be visible in the logs.)
    /// 
    /// &gt; **Note:** Some of this resource's arguments have default values that come from the AWS Provider. Other default values are provided by AWS and subject to change without notice. When relying on AWS defaults, the provider state will often have a zero value. For example, the AWS Provider does not provide a default for `cdc_max_batch_interval` but the AWS default is `60` (seconds). However, the provider state will show `0` since this is the value return by AWS when no value is present. Below, we aim to flag the defaults that come from AWS (_e.g._, "AWS default...").
    /// 
    /// ### Minimal Configuration
    /// 
    /// This is the minimal configuration for an `aws.dms.S3Endpoint`. This endpoint will rely on the AWS Provider and AWS defaults.
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Aws = Pulumi.Aws;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var example = new Aws.Dms.S3Endpoint("example", new()
    ///     {
    ///         EndpointId = "donnedtipi",
    ///         EndpointType = "target",
    ///         BucketName = "beckut_name",
    ///         ServiceAccessRoleArn = exampleAwsIamRole.Arn,
    ///     }, new CustomResourceOptions
    ///     {
    ///         DependsOn =
    ///         {
    ///             exampleAwsIamRolePolicy,
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ### Complete Configuration
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Aws = Pulumi.Aws;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var example = new Aws.Dms.S3Endpoint("example", new()
    ///     {
    ///         EndpointId = "donnedtipi",
    ///         EndpointType = "target",
    ///         SslMode = "none",
    ///         Tags = 
    ///         {
    ///             { "Name", "donnedtipi" },
    ///             { "Update", "to-update" },
    ///             { "Remove", "to-remove" },
    ///         },
    ///         AddColumnName = true,
    ///         AddTrailingPaddingCharacter = false,
    ///         BucketFolder = "folder",
    ///         BucketName = "bucket_name",
    ///         CannedAclForObjects = "private",
    ///         CdcInsertsAndUpdates = true,
    ///         CdcInsertsOnly = false,
    ///         CdcMaxBatchInterval = 100,
    ///         CdcMinFileSize = 16,
    ///         CdcPath = "cdc/path",
    ///         CompressionType = "GZIP",
    ///         CsvDelimiter = ";",
    ///         CsvNoSupValue = "x",
    ///         CsvNullValue = "?",
    ///         CsvRowDelimiter = "\\r\\n",
    ///         DataFormat = "parquet",
    ///         DataPageSize = 1100000,
    ///         DatePartitionDelimiter = "UNDERSCORE",
    ///         DatePartitionEnabled = true,
    ///         DatePartitionSequence = "yyyymmddhh",
    ///         DatePartitionTimezone = "Asia/Seoul",
    ///         DictPageSizeLimit = 1000000,
    ///         EnableStatistics = false,
    ///         EncodingType = "plain",
    ///         EncryptionMode = "SSE_S3",
    ///         ExpectedBucketOwner = current.AccountId,
    ///         ExternalTableDefinition = "etd",
    ///         IgnoreHeaderRows = 1,
    ///         IncludeOpForFullLoad = true,
    ///         MaxFileSize = 1000000,
    ///         ParquetTimestampInMillisecond = true,
    ///         ParquetVersion = "parquet-2-0",
    ///         PreserveTransactions = false,
    ///         Rfc4180 = false,
    ///         RowGroupLength = 11000,
    ///         ServerSideEncryptionKmsKeyId = exampleAwsKmsKey.Arn,
    ///         ServiceAccessRoleArn = exampleAwsIamRole.Arn,
    ///         TimestampColumnName = "tx_commit_time",
    ///         UseCsvNoSupValue = false,
    ///         UseTaskStartTimeForFullLoadTimestamp = true,
    ///         GlueCatalogGeneration = true,
    ///     }, new CustomResourceOptions
    ///     {
    ///         DependsOn =
    ///         {
    ///             exampleAwsIamRolePolicy,
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Import
    /// 
    /// Using `pulumi import`, import endpoints using the `endpoint_id`. For example:
    /// 
    /// ```sh
    /// $ pulumi import aws:dms/s3Endpoint:S3Endpoint example example-dms-endpoint-tf
    /// ```
    /// </summary>
    [AwsResourceType("aws:dms/s3Endpoint:S3Endpoint")]
    public partial class S3Endpoint : global::Pulumi.CustomResource
    {
        /// <summary>
        /// Whether to add column name information to the .csv output file. Default is `false`.
        /// </summary>
        [Output("addColumnName")]
        public Output<bool?> AddColumnName { get; private set; } = null!;

        /// <summary>
        /// Whether to add padding. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Output("addTrailingPaddingCharacter")]
        public Output<bool?> AddTrailingPaddingCharacter { get; private set; } = null!;

        /// <summary>
        /// S3 object prefix.
        /// </summary>
        [Output("bucketFolder")]
        public Output<string?> BucketFolder { get; private set; } = null!;

        /// <summary>
        /// S3 bucket name.
        /// </summary>
        [Output("bucketName")]
        public Output<string> BucketName { get; private set; } = null!;

        /// <summary>
        /// Predefined (canned) access control list for objects created in an S3 bucket. Valid values include `none`, `private`, `public-read`, `public-read-write`, `authenticated-read`, `aws-exec-read`, `bucket-owner-read`, and `bucket-owner-full-control`. Default is `none`.
        /// </summary>
        [Output("cannedAclForObjects")]
        public Output<string?> CannedAclForObjects { get; private set; } = null!;

        /// <summary>
        /// Whether to write insert and update operations to .csv or .parquet output files. Default is `false`.
        /// </summary>
        [Output("cdcInsertsAndUpdates")]
        public Output<bool?> CdcInsertsAndUpdates { get; private set; } = null!;

        /// <summary>
        /// Whether to write insert operations to .csv or .parquet output files. Default is `false`.
        /// </summary>
        [Output("cdcInsertsOnly")]
        public Output<bool?> CdcInsertsOnly { get; private set; } = null!;

        /// <summary>
        /// Maximum length of the interval, defined in seconds, after which to output a file to Amazon S3. (AWS default is `60`.)
        /// </summary>
        [Output("cdcMaxBatchInterval")]
        public Output<int?> CdcMaxBatchInterval { get; private set; } = null!;

        /// <summary>
        /// Minimum file size condition as defined in kilobytes to output a file to Amazon S3. (AWS default is 32000 KB.)
        /// </summary>
        [Output("cdcMinFileSize")]
        public Output<int?> CdcMinFileSize { get; private set; } = null!;

        /// <summary>
        /// Folder path of CDC files. If `cdc_path` is set, AWS DMS reads CDC files from this path and replicates the data changes to the target endpoint. Supported in AWS DMS versions 3.4.2 and later.
        /// </summary>
        [Output("cdcPath")]
        public Output<string?> CdcPath { get; private set; } = null!;

        /// <summary>
        /// ARN for the certificate.
        /// </summary>
        [Output("certificateArn")]
        public Output<string> CertificateArn { get; private set; } = null!;

        /// <summary>
        /// Set to compress target files. Valid values are `GZIP` and `NONE`. Default is `NONE`. (Ignored for source endpoints.)
        /// </summary>
        [Output("compressionType")]
        public Output<string?> CompressionType { get; private set; } = null!;

        /// <summary>
        /// Delimiter used to separate columns in the source files. Default is `,`.
        /// </summary>
        [Output("csvDelimiter")]
        public Output<string?> CsvDelimiter { get; private set; } = null!;

        /// <summary>
        /// Only applies if output files for a CDC load are written in .csv format. If `use_csv_no_sup_value` is set to `true`, string to use for all columns not included in the supplemental log. If you do not specify a string value, DMS uses the null value for these columns regardless of `use_csv_no_sup_value`. (Ignored for source endpoints.)
        /// </summary>
        [Output("csvNoSupValue")]
        public Output<string?> CsvNoSupValue { get; private set; } = null!;

        /// <summary>
        /// String to as null when writing to the target. (AWS default is `NULL`.)
        /// </summary>
        [Output("csvNullValue")]
        public Output<string?> CsvNullValue { get; private set; } = null!;

        /// <summary>
        /// Delimiter used to separate rows in the source files. Default is newline (_i.e._, `\n`).
        /// </summary>
        [Output("csvRowDelimiter")]
        public Output<string?> CsvRowDelimiter { get; private set; } = null!;

        /// <summary>
        /// Output format for the files that AWS DMS uses to create S3 objects. Valid values are `csv` and `parquet`.  (Ignored for source endpoints -- only `csv` is valid.)
        /// </summary>
        [Output("dataFormat")]
        public Output<string?> DataFormat { get; private set; } = null!;

        /// <summary>
        /// Size of one data page in bytes. (AWS default is 1 MiB, _i.e._, `1048576`.)
        /// </summary>
        [Output("dataPageSize")]
        public Output<int?> DataPageSize { get; private set; } = null!;

        /// <summary>
        /// Date separating delimiter to use during folder partitioning. Valid values are `SLASH`, `UNDERSCORE`, `DASH`, and `NONE`. (AWS default is `SLASH`.) (Ignored for source endpoints.)
        /// </summary>
        [Output("datePartitionDelimiter")]
        public Output<string?> DatePartitionDelimiter { get; private set; } = null!;

        /// <summary>
        /// Partition S3 bucket folders based on transaction commit dates. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Output("datePartitionEnabled")]
        public Output<bool?> DatePartitionEnabled { get; private set; } = null!;

        /// <summary>
        /// Date format to use during folder partitioning. Use this parameter when `date_partition_enabled` is set to true. Valid values are `YYYYMMDD`, `YYYYMMDDHH`, `YYYYMM`, `MMYYYYDD`, and `DDMMYYYY`. (AWS default is `YYYYMMDD`.) (Ignored for source endpoints.)
        /// </summary>
        [Output("datePartitionSequence")]
        public Output<string?> DatePartitionSequence { get; private set; } = null!;

        /// <summary>
        /// Convert the current UTC time to a timezone. The conversion occurs when a date partition folder is created and a CDC filename is generated. The timezone format is Area/Location (_e.g._, `Europe/Paris`). Use this when `date_partition_enabled` is `true`. (Ignored for source endpoints.)
        /// </summary>
        [Output("datePartitionTimezone")]
        public Output<string?> DatePartitionTimezone { get; private set; } = null!;

        /// <summary>
        /// Undocumented argument for use as directed by AWS Support.
        /// </summary>
        [Output("detachTargetOnLobLookupFailureParquet")]
        public Output<bool?> DetachTargetOnLobLookupFailureParquet { get; private set; } = null!;

        /// <summary>
        /// Maximum size in bytes of an encoded dictionary page of a column. (AWS default is 1 MiB, _i.e._, `1048576`.)
        /// </summary>
        [Output("dictPageSizeLimit")]
        public Output<int?> DictPageSizeLimit { get; private set; } = null!;

        /// <summary>
        /// Whether to enable statistics for Parquet pages and row groups. Default is `true`.
        /// </summary>
        [Output("enableStatistics")]
        public Output<bool?> EnableStatistics { get; private set; } = null!;

        /// <summary>
        /// Type of encoding to use. Value values are `rle_dictionary`, `plain`, and `plain_dictionary`. (AWS default is `rle_dictionary`.)
        /// </summary>
        [Output("encodingType")]
        public Output<string?> EncodingType { get; private set; } = null!;

        /// <summary>
        /// Server-side encryption mode that you want to encrypt your .csv or .parquet object files copied to S3. Valid values are `SSE_S3` and `SSE_KMS`. (AWS default is `SSE_S3`.) (Ignored for source endpoints -- only `SSE_S3` is valid.)
        /// </summary>
        [Output("encryptionMode")]
        public Output<string?> EncryptionMode { get; private set; } = null!;

        /// <summary>
        /// ARN for the endpoint.
        /// </summary>
        [Output("endpointArn")]
        public Output<string> EndpointArn { get; private set; } = null!;

        /// <summary>
        /// Database endpoint identifier. Identifiers must contain from 1 to 255 alphanumeric characters or hyphens, begin with a letter, contain only ASCII letters, digits, and hyphens, not end with a hyphen, and not contain two consecutive hyphens.
        /// </summary>
        [Output("endpointId")]
        public Output<string> EndpointId { get; private set; } = null!;

        /// <summary>
        /// Type of endpoint. Valid values are `source`, `target`.
        /// </summary>
        [Output("endpointType")]
        public Output<string> EndpointType { get; private set; } = null!;

        /// <summary>
        /// Expanded name for the engine name.
        /// </summary>
        [Output("engineDisplayName")]
        public Output<string> EngineDisplayName { get; private set; } = null!;

        /// <summary>
        /// Bucket owner to prevent sniping. Value is an AWS account ID.
        /// </summary>
        [Output("expectedBucketOwner")]
        public Output<string?> ExpectedBucketOwner { get; private set; } = null!;

        /// <summary>
        /// Can be used for cross-account validation. Use it in another account with `aws.dms.S3Endpoint` to create the endpoint cross-account.
        /// </summary>
        [Output("externalId")]
        public Output<string> ExternalId { get; private set; } = null!;

        /// <summary>
        /// JSON document that describes how AWS DMS should interpret the data.
        /// </summary>
        [Output("externalTableDefinition")]
        public Output<string?> ExternalTableDefinition { get; private set; } = null!;

        /// <summary>
        /// Whether to integrate AWS Glue Data Catalog with an Amazon S3 target. See [Using AWS Glue Data Catalog with an Amazon S3 target for AWS DMS](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html#CHAP_Target.S3.GlueCatalog) for more information. Default is `false`.
        /// </summary>
        [Output("glueCatalogGeneration")]
        public Output<bool?> GlueCatalogGeneration { get; private set; } = null!;

        /// <summary>
        /// When this value is set to `1`, DMS ignores the first row header in a .csv file. (AWS default is `0`.)
        /// </summary>
        [Output("ignoreHeaderRows")]
        public Output<int?> IgnoreHeaderRows { get; private set; } = null!;

        /// <summary>
        /// Whether to enable a full load to write INSERT operations to the .csv output files only to indicate how the rows were added to the source database. Default is `false`.
        /// </summary>
        [Output("includeOpForFullLoad")]
        public Output<bool?> IncludeOpForFullLoad { get; private set; } = null!;

        /// <summary>
        /// ARN for the KMS key that will be used to encrypt the connection parameters. If you do not specify a value for `kms_key_arn`, then AWS DMS will use your default encryption key. AWS KMS creates the default encryption key for your AWS account. Your AWS account has a different default encryption key for each AWS region.
        /// </summary>
        [Output("kmsKeyArn")]
        public Output<string> KmsKeyArn { get; private set; } = null!;

        /// <summary>
        /// Maximum size (in KB) of any .csv file to be created while migrating to an S3 target during full load. Valid values are from `1` to `1048576`. (AWS default is 1 GB, _i.e._, `1048576`.)
        /// </summary>
        [Output("maxFileSize")]
        public Output<int?> MaxFileSize { get; private set; } = null!;

        /// <summary>
        /// Specifies the precision of any TIMESTAMP column values written to an S3 object file in .parquet format. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Output("parquetTimestampInMillisecond")]
        public Output<bool?> ParquetTimestampInMillisecond { get; private set; } = null!;

        /// <summary>
        /// Version of the .parquet file format. Valid values are `parquet-1-0` and `parquet-2-0`. (AWS default is `parquet-1-0`.) (Ignored for source endpoints.)
        /// </summary>
        [Output("parquetVersion")]
        public Output<string?> ParquetVersion { get; private set; } = null!;

        /// <summary>
        /// Whether DMS saves the transaction order for a CDC load on the S3 target specified by `cdc_path`. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Output("preserveTransactions")]
        public Output<bool?> PreserveTransactions { get; private set; } = null!;

        /// <summary>
        /// For an S3 source, whether each leading double quotation mark has to be followed by an ending double quotation mark. Default is `true`.
        /// </summary>
        [Output("rfc4180")]
        public Output<bool?> Rfc4180 { get; private set; } = null!;

        /// <summary>
        /// Number of rows in a row group. (AWS default is `10000`.)
        /// </summary>
        [Output("rowGroupLength")]
        public Output<int?> RowGroupLength { get; private set; } = null!;

        /// <summary>
        /// When `encryption_mode` is `SSE_KMS`, ARN for the AWS KMS key. (Ignored for source endpoints -- only `SSE_S3` `encryption_mode` is valid.)
        /// </summary>
        [Output("serverSideEncryptionKmsKeyId")]
        public Output<string?> ServerSideEncryptionKmsKeyId { get; private set; } = null!;

        /// <summary>
        /// ARN of the IAM role with permissions to the S3 Bucket.
        /// 
        /// The following arguments are optional:
        /// </summary>
        [Output("serviceAccessRoleArn")]
        public Output<string> ServiceAccessRoleArn { get; private set; } = null!;

        /// <summary>
        /// SSL mode to use for the connection. Valid values are `none`, `require`, `verify-ca`, `verify-full`. (AWS default is `none`.)
        /// </summary>
        [Output("sslMode")]
        public Output<string> SslMode { get; private set; } = null!;

        /// <summary>
        /// Status of the endpoint.
        /// </summary>
        [Output("status")]
        public Output<string> Status { get; private set; } = null!;

        /// <summary>
        /// Map of tags to assign to the resource. If configured with a provider `default_tags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
        /// </summary>
        [Output("tags")]
        public Output<ImmutableDictionary<string, string>?> Tags { get; private set; } = null!;

        /// <summary>
        /// Map of tags assigned to the resource, including those inherited from the provider `default_tags` configuration block.
        /// </summary>
        [Output("tagsAll")]
        public Output<ImmutableDictionary<string, string>> TagsAll { get; private set; } = null!;

        /// <summary>
        /// Column to add with timestamp information to the endpoint data for an Amazon S3 target.
        /// </summary>
        [Output("timestampColumnName")]
        public Output<string?> TimestampColumnName { get; private set; } = null!;

        /// <summary>
        /// Whether to use `csv_no_sup_value` for columns not included in the supplemental log. (Ignored for source endpoints.)
        /// </summary>
        [Output("useCsvNoSupValue")]
        public Output<bool?> UseCsvNoSupValue { get; private set; } = null!;

        /// <summary>
        /// When set to `true`, uses the task start time as the timestamp column value instead of the time data is written to target. For full load, when set to `true`, each row of the timestamp column contains the task start time. For CDC loads, each row of the timestamp column contains the transaction commit time.When set to false, the full load timestamp in the timestamp column increments with the time data arrives at the target. Default is `false`.
        /// </summary>
        [Output("useTaskStartTimeForFullLoadTimestamp")]
        public Output<bool?> UseTaskStartTimeForFullLoadTimestamp { get; private set; } = null!;


        /// <summary>
        /// Create a S3Endpoint resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public S3Endpoint(string name, S3EndpointArgs args, CustomResourceOptions? options = null)
            : base("aws:dms/s3Endpoint:S3Endpoint", name, args ?? new S3EndpointArgs(), MakeResourceOptions(options, ""))
        {
        }

        private S3Endpoint(string name, Input<string> id, S3EndpointState? state = null, CustomResourceOptions? options = null)
            : base("aws:dms/s3Endpoint:S3Endpoint", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing S3Endpoint resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static S3Endpoint Get(string name, Input<string> id, S3EndpointState? state = null, CustomResourceOptions? options = null)
        {
            return new S3Endpoint(name, id, state, options);
        }
    }

    public sealed class S3EndpointArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Whether to add column name information to the .csv output file. Default is `false`.
        /// </summary>
        [Input("addColumnName")]
        public Input<bool>? AddColumnName { get; set; }

        /// <summary>
        /// Whether to add padding. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("addTrailingPaddingCharacter")]
        public Input<bool>? AddTrailingPaddingCharacter { get; set; }

        /// <summary>
        /// S3 object prefix.
        /// </summary>
        [Input("bucketFolder")]
        public Input<string>? BucketFolder { get; set; }

        /// <summary>
        /// S3 bucket name.
        /// </summary>
        [Input("bucketName", required: true)]
        public Input<string> BucketName { get; set; } = null!;

        /// <summary>
        /// Predefined (canned) access control list for objects created in an S3 bucket. Valid values include `none`, `private`, `public-read`, `public-read-write`, `authenticated-read`, `aws-exec-read`, `bucket-owner-read`, and `bucket-owner-full-control`. Default is `none`.
        /// </summary>
        [Input("cannedAclForObjects")]
        public Input<string>? CannedAclForObjects { get; set; }

        /// <summary>
        /// Whether to write insert and update operations to .csv or .parquet output files. Default is `false`.
        /// </summary>
        [Input("cdcInsertsAndUpdates")]
        public Input<bool>? CdcInsertsAndUpdates { get; set; }

        /// <summary>
        /// Whether to write insert operations to .csv or .parquet output files. Default is `false`.
        /// </summary>
        [Input("cdcInsertsOnly")]
        public Input<bool>? CdcInsertsOnly { get; set; }

        /// <summary>
        /// Maximum length of the interval, defined in seconds, after which to output a file to Amazon S3. (AWS default is `60`.)
        /// </summary>
        [Input("cdcMaxBatchInterval")]
        public Input<int>? CdcMaxBatchInterval { get; set; }

        /// <summary>
        /// Minimum file size condition as defined in kilobytes to output a file to Amazon S3. (AWS default is 32000 KB.)
        /// </summary>
        [Input("cdcMinFileSize")]
        public Input<int>? CdcMinFileSize { get; set; }

        /// <summary>
        /// Folder path of CDC files. If `cdc_path` is set, AWS DMS reads CDC files from this path and replicates the data changes to the target endpoint. Supported in AWS DMS versions 3.4.2 and later.
        /// </summary>
        [Input("cdcPath")]
        public Input<string>? CdcPath { get; set; }

        /// <summary>
        /// ARN for the certificate.
        /// </summary>
        [Input("certificateArn")]
        public Input<string>? CertificateArn { get; set; }

        /// <summary>
        /// Set to compress target files. Valid values are `GZIP` and `NONE`. Default is `NONE`. (Ignored for source endpoints.)
        /// </summary>
        [Input("compressionType")]
        public Input<string>? CompressionType { get; set; }

        /// <summary>
        /// Delimiter used to separate columns in the source files. Default is `,`.
        /// </summary>
        [Input("csvDelimiter")]
        public Input<string>? CsvDelimiter { get; set; }

        /// <summary>
        /// Only applies if output files for a CDC load are written in .csv format. If `use_csv_no_sup_value` is set to `true`, string to use for all columns not included in the supplemental log. If you do not specify a string value, DMS uses the null value for these columns regardless of `use_csv_no_sup_value`. (Ignored for source endpoints.)
        /// </summary>
        [Input("csvNoSupValue")]
        public Input<string>? CsvNoSupValue { get; set; }

        /// <summary>
        /// String to as null when writing to the target. (AWS default is `NULL`.)
        /// </summary>
        [Input("csvNullValue")]
        public Input<string>? CsvNullValue { get; set; }

        /// <summary>
        /// Delimiter used to separate rows in the source files. Default is newline (_i.e._, `\n`).
        /// </summary>
        [Input("csvRowDelimiter")]
        public Input<string>? CsvRowDelimiter { get; set; }

        /// <summary>
        /// Output format for the files that AWS DMS uses to create S3 objects. Valid values are `csv` and `parquet`.  (Ignored for source endpoints -- only `csv` is valid.)
        /// </summary>
        [Input("dataFormat")]
        public Input<string>? DataFormat { get; set; }

        /// <summary>
        /// Size of one data page in bytes. (AWS default is 1 MiB, _i.e._, `1048576`.)
        /// </summary>
        [Input("dataPageSize")]
        public Input<int>? DataPageSize { get; set; }

        /// <summary>
        /// Date separating delimiter to use during folder partitioning. Valid values are `SLASH`, `UNDERSCORE`, `DASH`, and `NONE`. (AWS default is `SLASH`.) (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionDelimiter")]
        public Input<string>? DatePartitionDelimiter { get; set; }

        /// <summary>
        /// Partition S3 bucket folders based on transaction commit dates. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionEnabled")]
        public Input<bool>? DatePartitionEnabled { get; set; }

        /// <summary>
        /// Date format to use during folder partitioning. Use this parameter when `date_partition_enabled` is set to true. Valid values are `YYYYMMDD`, `YYYYMMDDHH`, `YYYYMM`, `MMYYYYDD`, and `DDMMYYYY`. (AWS default is `YYYYMMDD`.) (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionSequence")]
        public Input<string>? DatePartitionSequence { get; set; }

        /// <summary>
        /// Convert the current UTC time to a timezone. The conversion occurs when a date partition folder is created and a CDC filename is generated. The timezone format is Area/Location (_e.g._, `Europe/Paris`). Use this when `date_partition_enabled` is `true`. (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionTimezone")]
        public Input<string>? DatePartitionTimezone { get; set; }

        /// <summary>
        /// Undocumented argument for use as directed by AWS Support.
        /// </summary>
        [Input("detachTargetOnLobLookupFailureParquet")]
        public Input<bool>? DetachTargetOnLobLookupFailureParquet { get; set; }

        /// <summary>
        /// Maximum size in bytes of an encoded dictionary page of a column. (AWS default is 1 MiB, _i.e._, `1048576`.)
        /// </summary>
        [Input("dictPageSizeLimit")]
        public Input<int>? DictPageSizeLimit { get; set; }

        /// <summary>
        /// Whether to enable statistics for Parquet pages and row groups. Default is `true`.
        /// </summary>
        [Input("enableStatistics")]
        public Input<bool>? EnableStatistics { get; set; }

        /// <summary>
        /// Type of encoding to use. Value values are `rle_dictionary`, `plain`, and `plain_dictionary`. (AWS default is `rle_dictionary`.)
        /// </summary>
        [Input("encodingType")]
        public Input<string>? EncodingType { get; set; }

        /// <summary>
        /// Server-side encryption mode that you want to encrypt your .csv or .parquet object files copied to S3. Valid values are `SSE_S3` and `SSE_KMS`. (AWS default is `SSE_S3`.) (Ignored for source endpoints -- only `SSE_S3` is valid.)
        /// </summary>
        [Input("encryptionMode")]
        public Input<string>? EncryptionMode { get; set; }

        /// <summary>
        /// Database endpoint identifier. Identifiers must contain from 1 to 255 alphanumeric characters or hyphens, begin with a letter, contain only ASCII letters, digits, and hyphens, not end with a hyphen, and not contain two consecutive hyphens.
        /// </summary>
        [Input("endpointId", required: true)]
        public Input<string> EndpointId { get; set; } = null!;

        /// <summary>
        /// Type of endpoint. Valid values are `source`, `target`.
        /// </summary>
        [Input("endpointType", required: true)]
        public Input<string> EndpointType { get; set; } = null!;

        /// <summary>
        /// Bucket owner to prevent sniping. Value is an AWS account ID.
        /// </summary>
        [Input("expectedBucketOwner")]
        public Input<string>? ExpectedBucketOwner { get; set; }

        /// <summary>
        /// JSON document that describes how AWS DMS should interpret the data.
        /// </summary>
        [Input("externalTableDefinition")]
        public Input<string>? ExternalTableDefinition { get; set; }

        /// <summary>
        /// Whether to integrate AWS Glue Data Catalog with an Amazon S3 target. See [Using AWS Glue Data Catalog with an Amazon S3 target for AWS DMS](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html#CHAP_Target.S3.GlueCatalog) for more information. Default is `false`.
        /// </summary>
        [Input("glueCatalogGeneration")]
        public Input<bool>? GlueCatalogGeneration { get; set; }

        /// <summary>
        /// When this value is set to `1`, DMS ignores the first row header in a .csv file. (AWS default is `0`.)
        /// </summary>
        [Input("ignoreHeaderRows")]
        public Input<int>? IgnoreHeaderRows { get; set; }

        /// <summary>
        /// Whether to enable a full load to write INSERT operations to the .csv output files only to indicate how the rows were added to the source database. Default is `false`.
        /// </summary>
        [Input("includeOpForFullLoad")]
        public Input<bool>? IncludeOpForFullLoad { get; set; }

        /// <summary>
        /// ARN for the KMS key that will be used to encrypt the connection parameters. If you do not specify a value for `kms_key_arn`, then AWS DMS will use your default encryption key. AWS KMS creates the default encryption key for your AWS account. Your AWS account has a different default encryption key for each AWS region.
        /// </summary>
        [Input("kmsKeyArn")]
        public Input<string>? KmsKeyArn { get; set; }

        /// <summary>
        /// Maximum size (in KB) of any .csv file to be created while migrating to an S3 target during full load. Valid values are from `1` to `1048576`. (AWS default is 1 GB, _i.e._, `1048576`.)
        /// </summary>
        [Input("maxFileSize")]
        public Input<int>? MaxFileSize { get; set; }

        /// <summary>
        /// Specifies the precision of any TIMESTAMP column values written to an S3 object file in .parquet format. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("parquetTimestampInMillisecond")]
        public Input<bool>? ParquetTimestampInMillisecond { get; set; }

        /// <summary>
        /// Version of the .parquet file format. Valid values are `parquet-1-0` and `parquet-2-0`. (AWS default is `parquet-1-0`.) (Ignored for source endpoints.)
        /// </summary>
        [Input("parquetVersion")]
        public Input<string>? ParquetVersion { get; set; }

        /// <summary>
        /// Whether DMS saves the transaction order for a CDC load on the S3 target specified by `cdc_path`. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("preserveTransactions")]
        public Input<bool>? PreserveTransactions { get; set; }

        /// <summary>
        /// For an S3 source, whether each leading double quotation mark has to be followed by an ending double quotation mark. Default is `true`.
        /// </summary>
        [Input("rfc4180")]
        public Input<bool>? Rfc4180 { get; set; }

        /// <summary>
        /// Number of rows in a row group. (AWS default is `10000`.)
        /// </summary>
        [Input("rowGroupLength")]
        public Input<int>? RowGroupLength { get; set; }

        /// <summary>
        /// When `encryption_mode` is `SSE_KMS`, ARN for the AWS KMS key. (Ignored for source endpoints -- only `SSE_S3` `encryption_mode` is valid.)
        /// </summary>
        [Input("serverSideEncryptionKmsKeyId")]
        public Input<string>? ServerSideEncryptionKmsKeyId { get; set; }

        /// <summary>
        /// ARN of the IAM role with permissions to the S3 Bucket.
        /// 
        /// The following arguments are optional:
        /// </summary>
        [Input("serviceAccessRoleArn", required: true)]
        public Input<string> ServiceAccessRoleArn { get; set; } = null!;

        /// <summary>
        /// SSL mode to use for the connection. Valid values are `none`, `require`, `verify-ca`, `verify-full`. (AWS default is `none`.)
        /// </summary>
        [Input("sslMode")]
        public Input<string>? SslMode { get; set; }

        [Input("tags")]
        private InputMap<string>? _tags;

        /// <summary>
        /// Map of tags to assign to the resource. If configured with a provider `default_tags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
        /// </summary>
        public InputMap<string> Tags
        {
            get => _tags ?? (_tags = new InputMap<string>());
            set => _tags = value;
        }

        /// <summary>
        /// Column to add with timestamp information to the endpoint data for an Amazon S3 target.
        /// </summary>
        [Input("timestampColumnName")]
        public Input<string>? TimestampColumnName { get; set; }

        /// <summary>
        /// Whether to use `csv_no_sup_value` for columns not included in the supplemental log. (Ignored for source endpoints.)
        /// </summary>
        [Input("useCsvNoSupValue")]
        public Input<bool>? UseCsvNoSupValue { get; set; }

        /// <summary>
        /// When set to `true`, uses the task start time as the timestamp column value instead of the time data is written to target. For full load, when set to `true`, each row of the timestamp column contains the task start time. For CDC loads, each row of the timestamp column contains the transaction commit time.When set to false, the full load timestamp in the timestamp column increments with the time data arrives at the target. Default is `false`.
        /// </summary>
        [Input("useTaskStartTimeForFullLoadTimestamp")]
        public Input<bool>? UseTaskStartTimeForFullLoadTimestamp { get; set; }

        public S3EndpointArgs()
        {
        }
        public static new S3EndpointArgs Empty => new S3EndpointArgs();
    }

    public sealed class S3EndpointState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Whether to add column name information to the .csv output file. Default is `false`.
        /// </summary>
        [Input("addColumnName")]
        public Input<bool>? AddColumnName { get; set; }

        /// <summary>
        /// Whether to add padding. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("addTrailingPaddingCharacter")]
        public Input<bool>? AddTrailingPaddingCharacter { get; set; }

        /// <summary>
        /// S3 object prefix.
        /// </summary>
        [Input("bucketFolder")]
        public Input<string>? BucketFolder { get; set; }

        /// <summary>
        /// S3 bucket name.
        /// </summary>
        [Input("bucketName")]
        public Input<string>? BucketName { get; set; }

        /// <summary>
        /// Predefined (canned) access control list for objects created in an S3 bucket. Valid values include `none`, `private`, `public-read`, `public-read-write`, `authenticated-read`, `aws-exec-read`, `bucket-owner-read`, and `bucket-owner-full-control`. Default is `none`.
        /// </summary>
        [Input("cannedAclForObjects")]
        public Input<string>? CannedAclForObjects { get; set; }

        /// <summary>
        /// Whether to write insert and update operations to .csv or .parquet output files. Default is `false`.
        /// </summary>
        [Input("cdcInsertsAndUpdates")]
        public Input<bool>? CdcInsertsAndUpdates { get; set; }

        /// <summary>
        /// Whether to write insert operations to .csv or .parquet output files. Default is `false`.
        /// </summary>
        [Input("cdcInsertsOnly")]
        public Input<bool>? CdcInsertsOnly { get; set; }

        /// <summary>
        /// Maximum length of the interval, defined in seconds, after which to output a file to Amazon S3. (AWS default is `60`.)
        /// </summary>
        [Input("cdcMaxBatchInterval")]
        public Input<int>? CdcMaxBatchInterval { get; set; }

        /// <summary>
        /// Minimum file size condition as defined in kilobytes to output a file to Amazon S3. (AWS default is 32000 KB.)
        /// </summary>
        [Input("cdcMinFileSize")]
        public Input<int>? CdcMinFileSize { get; set; }

        /// <summary>
        /// Folder path of CDC files. If `cdc_path` is set, AWS DMS reads CDC files from this path and replicates the data changes to the target endpoint. Supported in AWS DMS versions 3.4.2 and later.
        /// </summary>
        [Input("cdcPath")]
        public Input<string>? CdcPath { get; set; }

        /// <summary>
        /// ARN for the certificate.
        /// </summary>
        [Input("certificateArn")]
        public Input<string>? CertificateArn { get; set; }

        /// <summary>
        /// Set to compress target files. Valid values are `GZIP` and `NONE`. Default is `NONE`. (Ignored for source endpoints.)
        /// </summary>
        [Input("compressionType")]
        public Input<string>? CompressionType { get; set; }

        /// <summary>
        /// Delimiter used to separate columns in the source files. Default is `,`.
        /// </summary>
        [Input("csvDelimiter")]
        public Input<string>? CsvDelimiter { get; set; }

        /// <summary>
        /// Only applies if output files for a CDC load are written in .csv format. If `use_csv_no_sup_value` is set to `true`, string to use for all columns not included in the supplemental log. If you do not specify a string value, DMS uses the null value for these columns regardless of `use_csv_no_sup_value`. (Ignored for source endpoints.)
        /// </summary>
        [Input("csvNoSupValue")]
        public Input<string>? CsvNoSupValue { get; set; }

        /// <summary>
        /// String to as null when writing to the target. (AWS default is `NULL`.)
        /// </summary>
        [Input("csvNullValue")]
        public Input<string>? CsvNullValue { get; set; }

        /// <summary>
        /// Delimiter used to separate rows in the source files. Default is newline (_i.e._, `\n`).
        /// </summary>
        [Input("csvRowDelimiter")]
        public Input<string>? CsvRowDelimiter { get; set; }

        /// <summary>
        /// Output format for the files that AWS DMS uses to create S3 objects. Valid values are `csv` and `parquet`.  (Ignored for source endpoints -- only `csv` is valid.)
        /// </summary>
        [Input("dataFormat")]
        public Input<string>? DataFormat { get; set; }

        /// <summary>
        /// Size of one data page in bytes. (AWS default is 1 MiB, _i.e._, `1048576`.)
        /// </summary>
        [Input("dataPageSize")]
        public Input<int>? DataPageSize { get; set; }

        /// <summary>
        /// Date separating delimiter to use during folder partitioning. Valid values are `SLASH`, `UNDERSCORE`, `DASH`, and `NONE`. (AWS default is `SLASH`.) (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionDelimiter")]
        public Input<string>? DatePartitionDelimiter { get; set; }

        /// <summary>
        /// Partition S3 bucket folders based on transaction commit dates. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionEnabled")]
        public Input<bool>? DatePartitionEnabled { get; set; }

        /// <summary>
        /// Date format to use during folder partitioning. Use this parameter when `date_partition_enabled` is set to true. Valid values are `YYYYMMDD`, `YYYYMMDDHH`, `YYYYMM`, `MMYYYYDD`, and `DDMMYYYY`. (AWS default is `YYYYMMDD`.) (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionSequence")]
        public Input<string>? DatePartitionSequence { get; set; }

        /// <summary>
        /// Convert the current UTC time to a timezone. The conversion occurs when a date partition folder is created and a CDC filename is generated. The timezone format is Area/Location (_e.g._, `Europe/Paris`). Use this when `date_partition_enabled` is `true`. (Ignored for source endpoints.)
        /// </summary>
        [Input("datePartitionTimezone")]
        public Input<string>? DatePartitionTimezone { get; set; }

        /// <summary>
        /// Undocumented argument for use as directed by AWS Support.
        /// </summary>
        [Input("detachTargetOnLobLookupFailureParquet")]
        public Input<bool>? DetachTargetOnLobLookupFailureParquet { get; set; }

        /// <summary>
        /// Maximum size in bytes of an encoded dictionary page of a column. (AWS default is 1 MiB, _i.e._, `1048576`.)
        /// </summary>
        [Input("dictPageSizeLimit")]
        public Input<int>? DictPageSizeLimit { get; set; }

        /// <summary>
        /// Whether to enable statistics for Parquet pages and row groups. Default is `true`.
        /// </summary>
        [Input("enableStatistics")]
        public Input<bool>? EnableStatistics { get; set; }

        /// <summary>
        /// Type of encoding to use. Value values are `rle_dictionary`, `plain`, and `plain_dictionary`. (AWS default is `rle_dictionary`.)
        /// </summary>
        [Input("encodingType")]
        public Input<string>? EncodingType { get; set; }

        /// <summary>
        /// Server-side encryption mode that you want to encrypt your .csv or .parquet object files copied to S3. Valid values are `SSE_S3` and `SSE_KMS`. (AWS default is `SSE_S3`.) (Ignored for source endpoints -- only `SSE_S3` is valid.)
        /// </summary>
        [Input("encryptionMode")]
        public Input<string>? EncryptionMode { get; set; }

        /// <summary>
        /// ARN for the endpoint.
        /// </summary>
        [Input("endpointArn")]
        public Input<string>? EndpointArn { get; set; }

        /// <summary>
        /// Database endpoint identifier. Identifiers must contain from 1 to 255 alphanumeric characters or hyphens, begin with a letter, contain only ASCII letters, digits, and hyphens, not end with a hyphen, and not contain two consecutive hyphens.
        /// </summary>
        [Input("endpointId")]
        public Input<string>? EndpointId { get; set; }

        /// <summary>
        /// Type of endpoint. Valid values are `source`, `target`.
        /// </summary>
        [Input("endpointType")]
        public Input<string>? EndpointType { get; set; }

        /// <summary>
        /// Expanded name for the engine name.
        /// </summary>
        [Input("engineDisplayName")]
        public Input<string>? EngineDisplayName { get; set; }

        /// <summary>
        /// Bucket owner to prevent sniping. Value is an AWS account ID.
        /// </summary>
        [Input("expectedBucketOwner")]
        public Input<string>? ExpectedBucketOwner { get; set; }

        /// <summary>
        /// Can be used for cross-account validation. Use it in another account with `aws.dms.S3Endpoint` to create the endpoint cross-account.
        /// </summary>
        [Input("externalId")]
        public Input<string>? ExternalId { get; set; }

        /// <summary>
        /// JSON document that describes how AWS DMS should interpret the data.
        /// </summary>
        [Input("externalTableDefinition")]
        public Input<string>? ExternalTableDefinition { get; set; }

        /// <summary>
        /// Whether to integrate AWS Glue Data Catalog with an Amazon S3 target. See [Using AWS Glue Data Catalog with an Amazon S3 target for AWS DMS](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html#CHAP_Target.S3.GlueCatalog) for more information. Default is `false`.
        /// </summary>
        [Input("glueCatalogGeneration")]
        public Input<bool>? GlueCatalogGeneration { get; set; }

        /// <summary>
        /// When this value is set to `1`, DMS ignores the first row header in a .csv file. (AWS default is `0`.)
        /// </summary>
        [Input("ignoreHeaderRows")]
        public Input<int>? IgnoreHeaderRows { get; set; }

        /// <summary>
        /// Whether to enable a full load to write INSERT operations to the .csv output files only to indicate how the rows were added to the source database. Default is `false`.
        /// </summary>
        [Input("includeOpForFullLoad")]
        public Input<bool>? IncludeOpForFullLoad { get; set; }

        /// <summary>
        /// ARN for the KMS key that will be used to encrypt the connection parameters. If you do not specify a value for `kms_key_arn`, then AWS DMS will use your default encryption key. AWS KMS creates the default encryption key for your AWS account. Your AWS account has a different default encryption key for each AWS region.
        /// </summary>
        [Input("kmsKeyArn")]
        public Input<string>? KmsKeyArn { get; set; }

        /// <summary>
        /// Maximum size (in KB) of any .csv file to be created while migrating to an S3 target during full load. Valid values are from `1` to `1048576`. (AWS default is 1 GB, _i.e._, `1048576`.)
        /// </summary>
        [Input("maxFileSize")]
        public Input<int>? MaxFileSize { get; set; }

        /// <summary>
        /// Specifies the precision of any TIMESTAMP column values written to an S3 object file in .parquet format. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("parquetTimestampInMillisecond")]
        public Input<bool>? ParquetTimestampInMillisecond { get; set; }

        /// <summary>
        /// Version of the .parquet file format. Valid values are `parquet-1-0` and `parquet-2-0`. (AWS default is `parquet-1-0`.) (Ignored for source endpoints.)
        /// </summary>
        [Input("parquetVersion")]
        public Input<string>? ParquetVersion { get; set; }

        /// <summary>
        /// Whether DMS saves the transaction order for a CDC load on the S3 target specified by `cdc_path`. Default is `false`. (Ignored for source endpoints.)
        /// </summary>
        [Input("preserveTransactions")]
        public Input<bool>? PreserveTransactions { get; set; }

        /// <summary>
        /// For an S3 source, whether each leading double quotation mark has to be followed by an ending double quotation mark. Default is `true`.
        /// </summary>
        [Input("rfc4180")]
        public Input<bool>? Rfc4180 { get; set; }

        /// <summary>
        /// Number of rows in a row group. (AWS default is `10000`.)
        /// </summary>
        [Input("rowGroupLength")]
        public Input<int>? RowGroupLength { get; set; }

        /// <summary>
        /// When `encryption_mode` is `SSE_KMS`, ARN for the AWS KMS key. (Ignored for source endpoints -- only `SSE_S3` `encryption_mode` is valid.)
        /// </summary>
        [Input("serverSideEncryptionKmsKeyId")]
        public Input<string>? ServerSideEncryptionKmsKeyId { get; set; }

        /// <summary>
        /// ARN of the IAM role with permissions to the S3 Bucket.
        /// 
        /// The following arguments are optional:
        /// </summary>
        [Input("serviceAccessRoleArn")]
        public Input<string>? ServiceAccessRoleArn { get; set; }

        /// <summary>
        /// SSL mode to use for the connection. Valid values are `none`, `require`, `verify-ca`, `verify-full`. (AWS default is `none`.)
        /// </summary>
        [Input("sslMode")]
        public Input<string>? SslMode { get; set; }

        /// <summary>
        /// Status of the endpoint.
        /// </summary>
        [Input("status")]
        public Input<string>? Status { get; set; }

        [Input("tags")]
        private InputMap<string>? _tags;

        /// <summary>
        /// Map of tags to assign to the resource. If configured with a provider `default_tags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
        /// </summary>
        public InputMap<string> Tags
        {
            get => _tags ?? (_tags = new InputMap<string>());
            set => _tags = value;
        }

        [Input("tagsAll")]
        private InputMap<string>? _tagsAll;

        /// <summary>
        /// Map of tags assigned to the resource, including those inherited from the provider `default_tags` configuration block.
        /// </summary>
        [Obsolete(@"Please use `tags` instead.")]
        public InputMap<string> TagsAll
        {
            get => _tagsAll ?? (_tagsAll = new InputMap<string>());
            set => _tagsAll = value;
        }

        /// <summary>
        /// Column to add with timestamp information to the endpoint data for an Amazon S3 target.
        /// </summary>
        [Input("timestampColumnName")]
        public Input<string>? TimestampColumnName { get; set; }

        /// <summary>
        /// Whether to use `csv_no_sup_value` for columns not included in the supplemental log. (Ignored for source endpoints.)
        /// </summary>
        [Input("useCsvNoSupValue")]
        public Input<bool>? UseCsvNoSupValue { get; set; }

        /// <summary>
        /// When set to `true`, uses the task start time as the timestamp column value instead of the time data is written to target. For full load, when set to `true`, each row of the timestamp column contains the task start time. For CDC loads, each row of the timestamp column contains the transaction commit time.When set to false, the full load timestamp in the timestamp column increments with the time data arrives at the target. Default is `false`.
        /// </summary>
        [Input("useTaskStartTimeForFullLoadTimestamp")]
        public Input<bool>? UseTaskStartTimeForFullLoadTimestamp { get; set; }

        public S3EndpointState()
        {
        }
        public static new S3EndpointState Empty => new S3EndpointState();
    }
}
