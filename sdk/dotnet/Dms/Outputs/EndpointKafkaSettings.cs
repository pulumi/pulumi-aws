// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aws.Dms.Outputs
{

    [OutputType]
    public sealed class EndpointKafkaSettings
    {
        /// <summary>
        /// Kafka broker location. Specify in the form broker-hostname-or-ip:port.
        /// </summary>
        public readonly string Broker;
        /// <summary>
        /// Shows detailed control information for table definition, column definition, and table and column changes in the Kafka message output. Default is `False`.
        /// </summary>
        public readonly bool? IncludeControlDetails;
        /// <summary>
        /// Include NULL and empty columns for records migrated to the endpoint. Default is `False`.
        /// </summary>
        public readonly bool? IncludeNullAndEmpty;
        /// <summary>
        /// Shows the partition value within the Kafka message output unless the partition type is `schema-table-type`. Default is `False`.
        /// </summary>
        public readonly bool? IncludePartitionValue;
        /// <summary>
        /// Includes any data definition language (DDL) operations that change the table in the control data, such as `rename-table`, `drop-table`, `add-column`, `drop-column`, and `rename-column`. Default is `False`.
        /// </summary>
        public readonly bool? IncludeTableAlterOperations;
        /// <summary>
        /// Provides detailed transaction information from the source database. This information includes a commit timestamp, a log position, and values for `TransactionId`, previous `TransactionId`, and `TransactionRecordId` (the record offset within a transaction). Default is `False`.
        /// </summary>
        public readonly bool? IncludeTransactionDetails;
        /// <summary>
        /// Output format for the records created on the endpoint. Message format is `JSON` (default) or `JSON_UNFORMATTED` (a single line with no tab).
        /// </summary>
        public readonly string? MessageFormat;
        /// <summary>
        /// Maximum size in bytes for records created on the endpoint Default is `1,000,000`.
        /// </summary>
        public readonly int? MessageMaxBytes;
        /// <summary>
        /// Set this optional parameter to true to avoid adding a '0x' prefix to raw data in hexadecimal format. For example, by default, AWS DMS adds a '0x' prefix to the LOB column type in hexadecimal format moving from an Oracle source to a Kafka target. Use the `NoHexPrefix` endpoint setting to enable migration of RAW data type columns without adding the `'0x'` prefix.
        /// </summary>
        public readonly bool? NoHexPrefix;
        /// <summary>
        /// Prefixes schema and table names to partition values, when the partition type is `primary-key-type`. Doing this increases data distribution among Kafka partitions. For example, suppose that a SysBench schema has thousands of tables and each table has only limited range for a primary key. In this case, the same primary key is sent from thousands of tables to the same partition, which causes throttling. Default is `False`.
        /// </summary>
        public readonly bool? PartitionIncludeSchemaTable;
        /// <summary>
        /// For SASL/SSL authentication, AWS DMS supports the `scram-sha-512` mechanism by default. AWS DMS versions 3.5.0 and later also support the PLAIN mechanism. To use the PLAIN mechanism, set this parameter to `Plain`.
        /// </summary>
        public readonly string? SaslMechanism;
        /// <summary>
        /// Secure password you created when you first set up your MSK cluster to validate a client identity and make an encrypted connection between server and client using SASL-SSL authentication.
        /// </summary>
        public readonly string? SaslPassword;
        /// <summary>
        /// Secure user name you created when you first set up your MSK cluster to validate a client identity and make an encrypted connection between server and client using SASL-SSL authentication.
        /// </summary>
        public readonly string? SaslUsername;
        /// <summary>
        /// Set secure connection to a Kafka target endpoint using Transport Layer Security (TLS). Options include `ssl-encryption`, `ssl-authentication`, and `sasl-ssl`. `sasl-ssl` requires `SaslUsername` and `SaslPassword`.
        /// </summary>
        public readonly string? SecurityProtocol;
        /// <summary>
        /// ARN for the private certificate authority (CA) cert that AWS DMS uses to securely connect to your Kafka target endpoint.
        /// </summary>
        public readonly string? SslCaCertificateArn;
        /// <summary>
        /// ARN of the client certificate used to securely connect to a Kafka target endpoint.
        /// </summary>
        public readonly string? SslClientCertificateArn;
        /// <summary>
        /// ARN for the client private key used to securely connect to a Kafka target endpoint.
        /// </summary>
        public readonly string? SslClientKeyArn;
        /// <summary>
        /// Password for the client private key used to securely connect to a Kafka target endpoint.
        /// </summary>
        public readonly string? SslClientKeyPassword;
        /// <summary>
        /// Kafka topic for migration. Default is `kafka-default-topic`.
        /// </summary>
        public readonly string? Topic;

        [OutputConstructor]
        private EndpointKafkaSettings(
            string broker,

            bool? includeControlDetails,

            bool? includeNullAndEmpty,

            bool? includePartitionValue,

            bool? includeTableAlterOperations,

            bool? includeTransactionDetails,

            string? messageFormat,

            int? messageMaxBytes,

            bool? noHexPrefix,

            bool? partitionIncludeSchemaTable,

            string? saslMechanism,

            string? saslPassword,

            string? saslUsername,

            string? securityProtocol,

            string? sslCaCertificateArn,

            string? sslClientCertificateArn,

            string? sslClientKeyArn,

            string? sslClientKeyPassword,

            string? topic)
        {
            Broker = broker;
            IncludeControlDetails = includeControlDetails;
            IncludeNullAndEmpty = includeNullAndEmpty;
            IncludePartitionValue = includePartitionValue;
            IncludeTableAlterOperations = includeTableAlterOperations;
            IncludeTransactionDetails = includeTransactionDetails;
            MessageFormat = messageFormat;
            MessageMaxBytes = messageMaxBytes;
            NoHexPrefix = noHexPrefix;
            PartitionIncludeSchemaTable = partitionIncludeSchemaTable;
            SaslMechanism = saslMechanism;
            SaslPassword = saslPassword;
            SaslUsername = saslUsername;
            SecurityProtocol = securityProtocol;
            SslCaCertificateArn = sslCaCertificateArn;
            SslClientCertificateArn = sslClientCertificateArn;
            SslClientKeyArn = sslClientKeyArn;
            SslClientKeyPassword = sslClientKeyPassword;
            Topic = topic;
        }
    }
}
