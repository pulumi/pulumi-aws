// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aws.Glue
{
    /// <summary>
    /// Manages a Glue Crawler. More information can be found in the [AWS Glue Developer Guide](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html)
    /// 
    /// &gt; This content is derived from https://github.com/terraform-providers/terraform-provider-aws/blob/master/website/docs/r/glue_crawler.html.markdown.
    /// </summary>
    public partial class Crawler : Pulumi.CustomResource
    {
        /// <summary>
        /// The ARN of the crawler 
        /// </summary>
        [Output("arn")]
        public Output<string> Arn { get; private set; } = null!;

        [Output("catalogTargets")]
        public Output<ImmutableArray<Outputs.CrawlerCatalogTargets>> CatalogTargets { get; private set; } = null!;

        /// <summary>
        /// List of custom classifiers. By default, all AWS classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.
        /// </summary>
        [Output("classifiers")]
        public Output<ImmutableArray<string>> Classifiers { get; private set; } = null!;

        /// <summary>
        /// JSON string of configuration information.
        /// </summary>
        [Output("configuration")]
        public Output<string?> Configuration { get; private set; } = null!;

        /// <summary>
        /// The name of the Glue database to be synchronized.
        /// </summary>
        [Output("databaseName")]
        public Output<string> DatabaseName { get; private set; } = null!;

        /// <summary>
        /// Description of the crawler.
        /// </summary>
        [Output("description")]
        public Output<string?> Description { get; private set; } = null!;

        /// <summary>
        /// List of nested DynamoDB target arguments. See below.
        /// </summary>
        [Output("dynamodbTargets")]
        public Output<ImmutableArray<Outputs.CrawlerDynamodbTargets>> DynamodbTargets { get; private set; } = null!;

        /// <summary>
        /// List of nested JBDC target arguments. See below.
        /// </summary>
        [Output("jdbcTargets")]
        public Output<ImmutableArray<Outputs.CrawlerJdbcTargets>> JdbcTargets { get; private set; } = null!;

        /// <summary>
        /// Name of the crawler.
        /// </summary>
        [Output("name")]
        public Output<string> Name { get; private set; } = null!;

        /// <summary>
        /// The IAM role friendly name (including path without leading slash), or ARN of an IAM role, used by the crawler to access other resources.
        /// </summary>
        [Output("role")]
        public Output<string> Role { get; private set; } = null!;

        /// <summary>
        /// List nested Amazon S3 target arguments. See below.
        /// </summary>
        [Output("s3Targets")]
        public Output<ImmutableArray<Outputs.CrawlerS3Targets>> S3Targets { get; private set; } = null!;

        /// <summary>
        /// A cron expression used to specify the schedule. For more information, see [Time-Based Schedules for Jobs and Crawlers](https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html). For example, to run something every day at 12:15 UTC, you would specify: `cron(15 12 * * ? *)`.
        /// </summary>
        [Output("schedule")]
        public Output<string?> Schedule { get; private set; } = null!;

        /// <summary>
        /// Policy for the crawler's update and deletion behavior.
        /// </summary>
        [Output("schemaChangePolicy")]
        public Output<Outputs.CrawlerSchemaChangePolicy?> SchemaChangePolicy { get; private set; } = null!;

        /// <summary>
        /// The name of Security Configuration to be used by the crawler
        /// </summary>
        [Output("securityConfiguration")]
        public Output<string?> SecurityConfiguration { get; private set; } = null!;

        /// <summary>
        /// The table prefix used for catalog tables that are created.
        /// </summary>
        [Output("tablePrefix")]
        public Output<string?> TablePrefix { get; private set; } = null!;

        /// <summary>
        /// Key-value mapping of resource tags
        /// </summary>
        [Output("tags")]
        public Output<ImmutableDictionary<string, object>?> Tags { get; private set; } = null!;


        /// <summary>
        /// Create a Crawler resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public Crawler(string name, CrawlerArgs args, CustomResourceOptions? options = null)
            : base("aws:glue/crawler:Crawler", name, args ?? ResourceArgs.Empty, MakeResourceOptions(options, ""))
        {
        }

        private Crawler(string name, Input<string> id, CrawlerState? state = null, CustomResourceOptions? options = null)
            : base("aws:glue/crawler:Crawler", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing Crawler resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static Crawler Get(string name, Input<string> id, CrawlerState? state = null, CustomResourceOptions? options = null)
        {
            return new Crawler(name, id, state, options);
        }
    }

    public sealed class CrawlerArgs : Pulumi.ResourceArgs
    {
        [Input("catalogTargets")]
        private InputList<Inputs.CrawlerCatalogTargetsArgs>? _catalogTargets;
        public InputList<Inputs.CrawlerCatalogTargetsArgs> CatalogTargets
        {
            get => _catalogTargets ?? (_catalogTargets = new InputList<Inputs.CrawlerCatalogTargetsArgs>());
            set => _catalogTargets = value;
        }

        [Input("classifiers")]
        private InputList<string>? _classifiers;

        /// <summary>
        /// List of custom classifiers. By default, all AWS classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.
        /// </summary>
        public InputList<string> Classifiers
        {
            get => _classifiers ?? (_classifiers = new InputList<string>());
            set => _classifiers = value;
        }

        /// <summary>
        /// JSON string of configuration information.
        /// </summary>
        [Input("configuration")]
        public Input<string>? Configuration { get; set; }

        /// <summary>
        /// The name of the Glue database to be synchronized.
        /// </summary>
        [Input("databaseName", required: true)]
        public Input<string> DatabaseName { get; set; } = null!;

        /// <summary>
        /// Description of the crawler.
        /// </summary>
        [Input("description")]
        public Input<string>? Description { get; set; }

        [Input("dynamodbTargets")]
        private InputList<Inputs.CrawlerDynamodbTargetsArgs>? _dynamodbTargets;

        /// <summary>
        /// List of nested DynamoDB target arguments. See below.
        /// </summary>
        public InputList<Inputs.CrawlerDynamodbTargetsArgs> DynamodbTargets
        {
            get => _dynamodbTargets ?? (_dynamodbTargets = new InputList<Inputs.CrawlerDynamodbTargetsArgs>());
            set => _dynamodbTargets = value;
        }

        [Input("jdbcTargets")]
        private InputList<Inputs.CrawlerJdbcTargetsArgs>? _jdbcTargets;

        /// <summary>
        /// List of nested JBDC target arguments. See below.
        /// </summary>
        public InputList<Inputs.CrawlerJdbcTargetsArgs> JdbcTargets
        {
            get => _jdbcTargets ?? (_jdbcTargets = new InputList<Inputs.CrawlerJdbcTargetsArgs>());
            set => _jdbcTargets = value;
        }

        /// <summary>
        /// Name of the crawler.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// The IAM role friendly name (including path without leading slash), or ARN of an IAM role, used by the crawler to access other resources.
        /// </summary>
        [Input("role", required: true)]
        public Input<string> Role { get; set; } = null!;

        [Input("s3Targets")]
        private InputList<Inputs.CrawlerS3TargetsArgs>? _s3Targets;

        /// <summary>
        /// List nested Amazon S3 target arguments. See below.
        /// </summary>
        public InputList<Inputs.CrawlerS3TargetsArgs> S3Targets
        {
            get => _s3Targets ?? (_s3Targets = new InputList<Inputs.CrawlerS3TargetsArgs>());
            set => _s3Targets = value;
        }

        /// <summary>
        /// A cron expression used to specify the schedule. For more information, see [Time-Based Schedules for Jobs and Crawlers](https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html). For example, to run something every day at 12:15 UTC, you would specify: `cron(15 12 * * ? *)`.
        /// </summary>
        [Input("schedule")]
        public Input<string>? Schedule { get; set; }

        /// <summary>
        /// Policy for the crawler's update and deletion behavior.
        /// </summary>
        [Input("schemaChangePolicy")]
        public Input<Inputs.CrawlerSchemaChangePolicyArgs>? SchemaChangePolicy { get; set; }

        /// <summary>
        /// The name of Security Configuration to be used by the crawler
        /// </summary>
        [Input("securityConfiguration")]
        public Input<string>? SecurityConfiguration { get; set; }

        /// <summary>
        /// The table prefix used for catalog tables that are created.
        /// </summary>
        [Input("tablePrefix")]
        public Input<string>? TablePrefix { get; set; }

        [Input("tags")]
        private InputMap<object>? _tags;

        /// <summary>
        /// Key-value mapping of resource tags
        /// </summary>
        public InputMap<object> Tags
        {
            get => _tags ?? (_tags = new InputMap<object>());
            set => _tags = value;
        }

        public CrawlerArgs()
        {
        }
    }

    public sealed class CrawlerState : Pulumi.ResourceArgs
    {
        /// <summary>
        /// The ARN of the crawler 
        /// </summary>
        [Input("arn")]
        public Input<string>? Arn { get; set; }

        [Input("catalogTargets")]
        private InputList<Inputs.CrawlerCatalogTargetsGetArgs>? _catalogTargets;
        public InputList<Inputs.CrawlerCatalogTargetsGetArgs> CatalogTargets
        {
            get => _catalogTargets ?? (_catalogTargets = new InputList<Inputs.CrawlerCatalogTargetsGetArgs>());
            set => _catalogTargets = value;
        }

        [Input("classifiers")]
        private InputList<string>? _classifiers;

        /// <summary>
        /// List of custom classifiers. By default, all AWS classifiers are included in a crawl, but these custom classifiers always override the default classifiers for a given classification.
        /// </summary>
        public InputList<string> Classifiers
        {
            get => _classifiers ?? (_classifiers = new InputList<string>());
            set => _classifiers = value;
        }

        /// <summary>
        /// JSON string of configuration information.
        /// </summary>
        [Input("configuration")]
        public Input<string>? Configuration { get; set; }

        /// <summary>
        /// The name of the Glue database to be synchronized.
        /// </summary>
        [Input("databaseName")]
        public Input<string>? DatabaseName { get; set; }

        /// <summary>
        /// Description of the crawler.
        /// </summary>
        [Input("description")]
        public Input<string>? Description { get; set; }

        [Input("dynamodbTargets")]
        private InputList<Inputs.CrawlerDynamodbTargetsGetArgs>? _dynamodbTargets;

        /// <summary>
        /// List of nested DynamoDB target arguments. See below.
        /// </summary>
        public InputList<Inputs.CrawlerDynamodbTargetsGetArgs> DynamodbTargets
        {
            get => _dynamodbTargets ?? (_dynamodbTargets = new InputList<Inputs.CrawlerDynamodbTargetsGetArgs>());
            set => _dynamodbTargets = value;
        }

        [Input("jdbcTargets")]
        private InputList<Inputs.CrawlerJdbcTargetsGetArgs>? _jdbcTargets;

        /// <summary>
        /// List of nested JBDC target arguments. See below.
        /// </summary>
        public InputList<Inputs.CrawlerJdbcTargetsGetArgs> JdbcTargets
        {
            get => _jdbcTargets ?? (_jdbcTargets = new InputList<Inputs.CrawlerJdbcTargetsGetArgs>());
            set => _jdbcTargets = value;
        }

        /// <summary>
        /// Name of the crawler.
        /// </summary>
        [Input("name")]
        public Input<string>? Name { get; set; }

        /// <summary>
        /// The IAM role friendly name (including path without leading slash), or ARN of an IAM role, used by the crawler to access other resources.
        /// </summary>
        [Input("role")]
        public Input<string>? Role { get; set; }

        [Input("s3Targets")]
        private InputList<Inputs.CrawlerS3TargetsGetArgs>? _s3Targets;

        /// <summary>
        /// List nested Amazon S3 target arguments. See below.
        /// </summary>
        public InputList<Inputs.CrawlerS3TargetsGetArgs> S3Targets
        {
            get => _s3Targets ?? (_s3Targets = new InputList<Inputs.CrawlerS3TargetsGetArgs>());
            set => _s3Targets = value;
        }

        /// <summary>
        /// A cron expression used to specify the schedule. For more information, see [Time-Based Schedules for Jobs and Crawlers](https://docs.aws.amazon.com/glue/latest/dg/monitor-data-warehouse-schedule.html). For example, to run something every day at 12:15 UTC, you would specify: `cron(15 12 * * ? *)`.
        /// </summary>
        [Input("schedule")]
        public Input<string>? Schedule { get; set; }

        /// <summary>
        /// Policy for the crawler's update and deletion behavior.
        /// </summary>
        [Input("schemaChangePolicy")]
        public Input<Inputs.CrawlerSchemaChangePolicyGetArgs>? SchemaChangePolicy { get; set; }

        /// <summary>
        /// The name of Security Configuration to be used by the crawler
        /// </summary>
        [Input("securityConfiguration")]
        public Input<string>? SecurityConfiguration { get; set; }

        /// <summary>
        /// The table prefix used for catalog tables that are created.
        /// </summary>
        [Input("tablePrefix")]
        public Input<string>? TablePrefix { get; set; }

        [Input("tags")]
        private InputMap<object>? _tags;

        /// <summary>
        /// Key-value mapping of resource tags
        /// </summary>
        public InputMap<object> Tags
        {
            get => _tags ?? (_tags = new InputMap<object>());
            set => _tags = value;
        }

        public CrawlerState()
        {
        }
    }

    namespace Inputs
    {

    public sealed class CrawlerCatalogTargetsArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// The name of the Glue database to be synchronized.
        /// </summary>
        [Input("databaseName", required: true)]
        public Input<string> DatabaseName { get; set; } = null!;

        [Input("tables", required: true)]
        private InputList<string>? _tables;

        /// <summary>
        /// A list of catalog tables to be synchronized.
        /// </summary>
        public InputList<string> Tables
        {
            get => _tables ?? (_tables = new InputList<string>());
            set => _tables = value;
        }

        public CrawlerCatalogTargetsArgs()
        {
        }
    }

    public sealed class CrawlerCatalogTargetsGetArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// The name of the Glue database to be synchronized.
        /// </summary>
        [Input("databaseName", required: true)]
        public Input<string> DatabaseName { get; set; } = null!;

        [Input("tables", required: true)]
        private InputList<string>? _tables;

        /// <summary>
        /// A list of catalog tables to be synchronized.
        /// </summary>
        public InputList<string> Tables
        {
            get => _tables ?? (_tables = new InputList<string>());
            set => _tables = value;
        }

        public CrawlerCatalogTargetsGetArgs()
        {
        }
    }

    public sealed class CrawlerDynamodbTargetsArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// The path to the Amazon S3 target.
        /// </summary>
        [Input("path", required: true)]
        public Input<string> Path { get; set; } = null!;

        public CrawlerDynamodbTargetsArgs()
        {
        }
    }

    public sealed class CrawlerDynamodbTargetsGetArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// The path to the Amazon S3 target.
        /// </summary>
        [Input("path", required: true)]
        public Input<string> Path { get; set; } = null!;

        public CrawlerDynamodbTargetsGetArgs()
        {
        }
    }

    public sealed class CrawlerJdbcTargetsArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// The name of the connection to use to connect to the JDBC target.
        /// </summary>
        [Input("connectionName", required: true)]
        public Input<string> ConnectionName { get; set; } = null!;

        [Input("exclusions")]
        private InputList<string>? _exclusions;

        /// <summary>
        /// A list of glob patterns used to exclude from the crawl.
        /// </summary>
        public InputList<string> Exclusions
        {
            get => _exclusions ?? (_exclusions = new InputList<string>());
            set => _exclusions = value;
        }

        /// <summary>
        /// The path to the Amazon S3 target.
        /// </summary>
        [Input("path", required: true)]
        public Input<string> Path { get; set; } = null!;

        public CrawlerJdbcTargetsArgs()
        {
        }
    }

    public sealed class CrawlerJdbcTargetsGetArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// The name of the connection to use to connect to the JDBC target.
        /// </summary>
        [Input("connectionName", required: true)]
        public Input<string> ConnectionName { get; set; } = null!;

        [Input("exclusions")]
        private InputList<string>? _exclusions;

        /// <summary>
        /// A list of glob patterns used to exclude from the crawl.
        /// </summary>
        public InputList<string> Exclusions
        {
            get => _exclusions ?? (_exclusions = new InputList<string>());
            set => _exclusions = value;
        }

        /// <summary>
        /// The path to the Amazon S3 target.
        /// </summary>
        [Input("path", required: true)]
        public Input<string> Path { get; set; } = null!;

        public CrawlerJdbcTargetsGetArgs()
        {
        }
    }

    public sealed class CrawlerS3TargetsArgs : Pulumi.ResourceArgs
    {
        [Input("exclusions")]
        private InputList<string>? _exclusions;

        /// <summary>
        /// A list of glob patterns used to exclude from the crawl.
        /// </summary>
        public InputList<string> Exclusions
        {
            get => _exclusions ?? (_exclusions = new InputList<string>());
            set => _exclusions = value;
        }

        /// <summary>
        /// The path to the Amazon S3 target.
        /// </summary>
        [Input("path", required: true)]
        public Input<string> Path { get; set; } = null!;

        public CrawlerS3TargetsArgs()
        {
        }
    }

    public sealed class CrawlerS3TargetsGetArgs : Pulumi.ResourceArgs
    {
        [Input("exclusions")]
        private InputList<string>? _exclusions;

        /// <summary>
        /// A list of glob patterns used to exclude from the crawl.
        /// </summary>
        public InputList<string> Exclusions
        {
            get => _exclusions ?? (_exclusions = new InputList<string>());
            set => _exclusions = value;
        }

        /// <summary>
        /// The path to the Amazon S3 target.
        /// </summary>
        [Input("path", required: true)]
        public Input<string> Path { get; set; } = null!;

        public CrawlerS3TargetsGetArgs()
        {
        }
    }

    public sealed class CrawlerSchemaChangePolicyArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// The deletion behavior when the crawler finds a deleted object. Valid values: `LOG`, `DELETE_FROM_DATABASE`, or `DEPRECATE_IN_DATABASE`. Defaults to `DEPRECATE_IN_DATABASE`.
        /// </summary>
        [Input("deleteBehavior")]
        public Input<string>? DeleteBehavior { get; set; }

        /// <summary>
        /// The update behavior when the crawler finds a changed schema. Valid values: `LOG` or `UPDATE_IN_DATABASE`. Defaults to `UPDATE_IN_DATABASE`.
        /// </summary>
        [Input("updateBehavior")]
        public Input<string>? UpdateBehavior { get; set; }

        public CrawlerSchemaChangePolicyArgs()
        {
        }
    }

    public sealed class CrawlerSchemaChangePolicyGetArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// The deletion behavior when the crawler finds a deleted object. Valid values: `LOG`, `DELETE_FROM_DATABASE`, or `DEPRECATE_IN_DATABASE`. Defaults to `DEPRECATE_IN_DATABASE`.
        /// </summary>
        [Input("deleteBehavior")]
        public Input<string>? DeleteBehavior { get; set; }

        /// <summary>
        /// The update behavior when the crawler finds a changed schema. Valid values: `LOG` or `UPDATE_IN_DATABASE`. Defaults to `UPDATE_IN_DATABASE`.
        /// </summary>
        [Input("updateBehavior")]
        public Input<string>? UpdateBehavior { get; set; }

        public CrawlerSchemaChangePolicyGetArgs()
        {
        }
    }
    }

    namespace Outputs
    {

    [OutputType]
    public sealed class CrawlerCatalogTargets
    {
        /// <summary>
        /// The name of the Glue database to be synchronized.
        /// </summary>
        public readonly string DatabaseName;
        /// <summary>
        /// A list of catalog tables to be synchronized.
        /// </summary>
        public readonly ImmutableArray<string> Tables;

        [OutputConstructor]
        private CrawlerCatalogTargets(
            string databaseName,
            ImmutableArray<string> tables)
        {
            DatabaseName = databaseName;
            Tables = tables;
        }
    }

    [OutputType]
    public sealed class CrawlerDynamodbTargets
    {
        /// <summary>
        /// The path to the Amazon S3 target.
        /// </summary>
        public readonly string Path;

        [OutputConstructor]
        private CrawlerDynamodbTargets(string path)
        {
            Path = path;
        }
    }

    [OutputType]
    public sealed class CrawlerJdbcTargets
    {
        /// <summary>
        /// The name of the connection to use to connect to the JDBC target.
        /// </summary>
        public readonly string ConnectionName;
        /// <summary>
        /// A list of glob patterns used to exclude from the crawl.
        /// </summary>
        public readonly ImmutableArray<string> Exclusions;
        /// <summary>
        /// The path to the Amazon S3 target.
        /// </summary>
        public readonly string Path;

        [OutputConstructor]
        private CrawlerJdbcTargets(
            string connectionName,
            ImmutableArray<string> exclusions,
            string path)
        {
            ConnectionName = connectionName;
            Exclusions = exclusions;
            Path = path;
        }
    }

    [OutputType]
    public sealed class CrawlerS3Targets
    {
        /// <summary>
        /// A list of glob patterns used to exclude from the crawl.
        /// </summary>
        public readonly ImmutableArray<string> Exclusions;
        /// <summary>
        /// The path to the Amazon S3 target.
        /// </summary>
        public readonly string Path;

        [OutputConstructor]
        private CrawlerS3Targets(
            ImmutableArray<string> exclusions,
            string path)
        {
            Exclusions = exclusions;
            Path = path;
        }
    }

    [OutputType]
    public sealed class CrawlerSchemaChangePolicy
    {
        /// <summary>
        /// The deletion behavior when the crawler finds a deleted object. Valid values: `LOG`, `DELETE_FROM_DATABASE`, or `DEPRECATE_IN_DATABASE`. Defaults to `DEPRECATE_IN_DATABASE`.
        /// </summary>
        public readonly string? DeleteBehavior;
        /// <summary>
        /// The update behavior when the crawler finds a changed schema. Valid values: `LOG` or `UPDATE_IN_DATABASE`. Defaults to `UPDATE_IN_DATABASE`.
        /// </summary>
        public readonly string? UpdateBehavior;

        [OutputConstructor]
        private CrawlerSchemaChangePolicy(
            string? deleteBehavior,
            string? updateBehavior)
        {
            DeleteBehavior = deleteBehavior;
            UpdateBehavior = updateBehavior;
        }
    }
    }
}
