// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aws.Glue.Inputs
{

    public sealed class CrawlerS3TargetGetArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The name of a connection which allows crawler to access data in S3 within a VPC.
        /// </summary>
        [Input("connectionName")]
        public Input<string>? ConnectionName { get; set; }

        /// <summary>
        /// The ARN of the dead-letter SQS queue.
        /// </summary>
        [Input("dlqEventQueueArn")]
        public Input<string>? DlqEventQueueArn { get; set; }

        /// <summary>
        /// The ARN of the SQS queue to receive S3 notifications from.
        /// </summary>
        [Input("eventQueueArn")]
        public Input<string>? EventQueueArn { get; set; }

        [Input("exclusions")]
        private InputList<string>? _exclusions;

        /// <summary>
        /// A list of glob patterns used to exclude from the crawl.
        /// </summary>
        public InputList<string> Exclusions
        {
            get => _exclusions ?? (_exclusions = new InputList<string>());
            set => _exclusions = value;
        }

        /// <summary>
        /// The path to the Amazon S3 target.
        /// </summary>
        [Input("path", required: true)]
        public Input<string> Path { get; set; } = null!;

        /// <summary>
        /// Sets the number of files in each leaf folder to be crawled when crawling sample files in a dataset. If not set, all the files are crawled. A valid value is an integer between 1 and 249.
        /// </summary>
        [Input("sampleSize")]
        public Input<int>? SampleSize { get; set; }

        public CrawlerS3TargetGetArgs()
        {
        }
        public static new CrawlerS3TargetGetArgs Empty => new CrawlerS3TargetGetArgs();
    }
}
