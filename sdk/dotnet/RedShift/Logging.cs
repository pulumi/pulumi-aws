// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aws.RedShift
{
    /// <summary>
    /// Resource for managing an AWS Redshift Logging configuration.
    /// 
    /// ## Example Usage
    /// 
    /// ### Basic Usage
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Aws = Pulumi.Aws;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var example = new Aws.RedShift.Logging("example", new()
    ///     {
    ///         ClusterIdentifier = exampleAwsRedshiftCluster.Id,
    ///         LogDestinationType = "cloudwatch",
    ///         LogExports = new[]
    ///         {
    ///             "connectionlog",
    ///             "userlog",
    ///         },
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ### S3 Destination Type
    /// 
    /// ```csharp
    /// using System.Collections.Generic;
    /// using System.Linq;
    /// using Pulumi;
    /// using Aws = Pulumi.Aws;
    /// 
    /// return await Deployment.RunAsync(() =&gt; 
    /// {
    ///     var example = new Aws.RedShift.Logging("example", new()
    ///     {
    ///         ClusterIdentifier = exampleAwsRedshiftCluster.Id,
    ///         LogDestinationType = "s3",
    ///         BucketName = exampleAwsS3Bucket.Id,
    ///         S3KeyPrefix = "example-prefix/",
    ///     });
    /// 
    /// });
    /// ```
    /// 
    /// ## Import
    /// 
    /// Using `pulumi import`, import Redshift Logging using the `id`. For example:
    /// 
    /// ```sh
    /// $ pulumi import aws:redshift/logging:Logging example cluster-id-12345678
    /// ```
    /// </summary>
    [AwsResourceType("aws:redshift/logging:Logging")]
    public partial class Logging : global::Pulumi.CustomResource
    {
        /// <summary>
        /// Name of an existing S3 bucket where the log files are to be stored. Required when `log_destination_type` is `s3`. Must be in the same region as the cluster and the cluster must have read bucket and put object permissions. For more information on the permissions required for the bucket, please read the AWS [documentation](http://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html#db-auditing-enable-logging)
        /// </summary>
        [Output("bucketName")]
        public Output<string?> BucketName { get; private set; } = null!;

        /// <summary>
        /// Identifier of the source cluster.
        /// 
        /// The following arguments are optional:
        /// </summary>
        [Output("clusterIdentifier")]
        public Output<string> ClusterIdentifier { get; private set; } = null!;

        /// <summary>
        /// Log destination type. Valid values are `s3` and `cloudwatch`.
        /// </summary>
        [Output("logDestinationType")]
        public Output<string?> LogDestinationType { get; private set; } = null!;

        /// <summary>
        /// Collection of exported log types. Required when `log_destination_type` is `cloudwatch`. Valid values are `connectionlog`, `useractivitylog`, and `userlog`.
        /// </summary>
        [Output("logExports")]
        public Output<ImmutableArray<string>> LogExports { get; private set; } = null!;

        /// <summary>
        /// Prefix applied to the log file names.
        /// </summary>
        [Output("s3KeyPrefix")]
        public Output<string?> S3KeyPrefix { get; private set; } = null!;


        /// <summary>
        /// Create a Logging resource with the given unique name, arguments, and options.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resource</param>
        /// <param name="args">The arguments used to populate this resource's properties</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public Logging(string name, LoggingArgs args, CustomResourceOptions? options = null)
            : base("aws:redshift/logging:Logging", name, args ?? new LoggingArgs(), MakeResourceOptions(options, ""))
        {
        }

        private Logging(string name, Input<string> id, LoggingState? state = null, CustomResourceOptions? options = null)
            : base("aws:redshift/logging:Logging", name, state, MakeResourceOptions(options, id))
        {
        }

        private static CustomResourceOptions MakeResourceOptions(CustomResourceOptions? options, Input<string>? id)
        {
            var defaultOptions = new CustomResourceOptions
            {
                Version = Utilities.Version,
            };
            var merged = CustomResourceOptions.Merge(defaultOptions, options);
            // Override the ID if one was specified for consistency with other language SDKs.
            merged.Id = id ?? merged.Id;
            return merged;
        }
        /// <summary>
        /// Get an existing Logging resource's state with the given name, ID, and optional extra
        /// properties used to qualify the lookup.
        /// </summary>
        ///
        /// <param name="name">The unique name of the resulting resource.</param>
        /// <param name="id">The unique provider ID of the resource to lookup.</param>
        /// <param name="state">Any extra arguments used during the lookup.</param>
        /// <param name="options">A bag of options that control this resource's behavior</param>
        public static Logging Get(string name, Input<string> id, LoggingState? state = null, CustomResourceOptions? options = null)
        {
            return new Logging(name, id, state, options);
        }
    }

    public sealed class LoggingArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Name of an existing S3 bucket where the log files are to be stored. Required when `log_destination_type` is `s3`. Must be in the same region as the cluster and the cluster must have read bucket and put object permissions. For more information on the permissions required for the bucket, please read the AWS [documentation](http://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html#db-auditing-enable-logging)
        /// </summary>
        [Input("bucketName")]
        public Input<string>? BucketName { get; set; }

        /// <summary>
        /// Identifier of the source cluster.
        /// 
        /// The following arguments are optional:
        /// </summary>
        [Input("clusterIdentifier", required: true)]
        public Input<string> ClusterIdentifier { get; set; } = null!;

        /// <summary>
        /// Log destination type. Valid values are `s3` and `cloudwatch`.
        /// </summary>
        [Input("logDestinationType")]
        public Input<string>? LogDestinationType { get; set; }

        [Input("logExports")]
        private InputList<string>? _logExports;

        /// <summary>
        /// Collection of exported log types. Required when `log_destination_type` is `cloudwatch`. Valid values are `connectionlog`, `useractivitylog`, and `userlog`.
        /// </summary>
        public InputList<string> LogExports
        {
            get => _logExports ?? (_logExports = new InputList<string>());
            set => _logExports = value;
        }

        /// <summary>
        /// Prefix applied to the log file names.
        /// </summary>
        [Input("s3KeyPrefix")]
        public Input<string>? S3KeyPrefix { get; set; }

        public LoggingArgs()
        {
        }
        public static new LoggingArgs Empty => new LoggingArgs();
    }

    public sealed class LoggingState : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Name of an existing S3 bucket where the log files are to be stored. Required when `log_destination_type` is `s3`. Must be in the same region as the cluster and the cluster must have read bucket and put object permissions. For more information on the permissions required for the bucket, please read the AWS [documentation](http://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html#db-auditing-enable-logging)
        /// </summary>
        [Input("bucketName")]
        public Input<string>? BucketName { get; set; }

        /// <summary>
        /// Identifier of the source cluster.
        /// 
        /// The following arguments are optional:
        /// </summary>
        [Input("clusterIdentifier")]
        public Input<string>? ClusterIdentifier { get; set; }

        /// <summary>
        /// Log destination type. Valid values are `s3` and `cloudwatch`.
        /// </summary>
        [Input("logDestinationType")]
        public Input<string>? LogDestinationType { get; set; }

        [Input("logExports")]
        private InputList<string>? _logExports;

        /// <summary>
        /// Collection of exported log types. Required when `log_destination_type` is `cloudwatch`. Valid values are `connectionlog`, `useractivitylog`, and `userlog`.
        /// </summary>
        public InputList<string> LogExports
        {
            get => _logExports ?? (_logExports = new InputList<string>());
            set => _logExports = value;
        }

        /// <summary>
        /// Prefix applied to the log file names.
        /// </summary>
        [Input("s3KeyPrefix")]
        public Input<string>? S3KeyPrefix { get; set; }

        public LoggingState()
        {
        }
        public static new LoggingState Empty => new LoggingState();
    }
}
