// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.policypacks.aws.bedrock.outputs;

import com.pulumi.core.UndeferrableValue;
import java.lang.Double;
import java.lang.Integer;
import java.lang.String;
import java.util.List;


public final class AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfiguration {

    /**
     * Maximum number of tokens to allow in the generated response.
     * 
     */
    private UndeferrableValue<Integer> maxLength;

    public Integer maxLength() {
        if (maxLength == null) return null;
        return maxLength.getValue("AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfiguration.maxLength");
    }

    /**
     * List of stop sequences. A stop sequence is a sequence of characters that causes the model to stop generating the response.
     * 
     */
    private UndeferrableValue<List<String>> stopSequences;

    public List<String> stopSequences() {
        if (stopSequences == null) return null;
        return stopSequences.getValue("AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfiguration.stopSequences");
    }

    /**
     * Likelihood of the model selecting higher-probability options while generating a response. A lower value makes the model more likely to choose higher-probability options, while a higher value makes the model more likely to choose lower-probability options.
     * 
     */
    private UndeferrableValue<Double> temperature;

    public Double temperature() {
        if (temperature == null) return null;
        return temperature.getValue("AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfiguration.temperature");
    }

    /**
     * Number of top most-likely candidates, between 0 and 500, from which the model chooses the next token in the sequence.
     * 
     */
    private UndeferrableValue<Integer> topK;

    public Integer topK() {
        if (topK == null) return null;
        return topK.getValue("AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfiguration.topK");
    }

    /**
     * Top percentage of the probability distribution of next tokens, between 0 and 1 (denoting 0% and 100%), from which the model chooses the next token in the sequence.
     * 
     */
    private UndeferrableValue<Double> topP;

    public Double topP() {
        if (topP == null) return null;
        return topP.getValue("AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfiguration.topP");
    }

}
