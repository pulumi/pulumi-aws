// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.policypacks.aws.mwaa;

import com.pulumi.core.UndeferrableValue;
import com.pulumi.core.annotations.PolicyResourceType;
import com.pulumi.policypacks.aws.mwaa.inputs.EnvironmentLoggingConfigurationArgs;
import com.pulumi.policypacks.aws.mwaa.inputs.EnvironmentNetworkConfigurationArgs;
import java.lang.Integer;
import java.lang.String;
import java.util.Map;
import javax.annotation.Nullable;


@PolicyResourceType(type="aws:mwaa/environment:Environment")
public final class EnvironmentArgs extends com.pulumi.resources.PolicyResourceInput {

    /**
     * The `airflow_configuration_options` parameter specifies airflow override options. Check the [Official documentation](https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-env-variables.html#configuring-env-variables-reference) for all possible configuration options.
     * 
     */
    private UndeferrableValue<Map<String,String>> airflowConfigurationOptions;

    public Map<String,String> airflowConfigurationOptions() {
        if (airflowConfigurationOptions == null) return null;
        return airflowConfigurationOptions.getValue("EnvironmentArgs.airflowConfigurationOptions");
    }

    /**
     * Airflow version of your environment, will be set by default to the latest version that MWAA supports.
     * 
     */
    private UndeferrableValue<String> airflowVersion;

    public String airflowVersion() {
        if (airflowVersion == null) return null;
        return airflowVersion.getValue("EnvironmentArgs.airflowVersion");
    }

    /**
     * The relative path to the DAG folder on your Amazon S3 storage bucket. For example, dags. For more information, see [Importing DAGs on Amazon MWAA](https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-import.html).
     * 
     */
    private UndeferrableValue<String> dagS3Path;

    public String dagS3Path() {
        if (dagS3Path == null) return null;
        return dagS3Path.getValue("EnvironmentArgs.dagS3Path");
    }

    /**
     * Defines whether the VPC endpoints configured for the environment are created and managed by the customer or by AWS. If set to `SERVICE`, Amazon MWAA will create and manage the required VPC endpoints in your VPC. If set to `CUSTOMER`, you must create, and manage, the VPC endpoints for your VPC. Defaults to `SERVICE` if not set.
     * 
     */
    private UndeferrableValue<String> endpointManagement;

    public String endpointManagement() {
        if (endpointManagement == null) return null;
        return endpointManagement.getValue("EnvironmentArgs.endpointManagement");
    }

    /**
     * Environment class for the cluster. Possible options are `mw1.micro`, `mw1.small`, `mw1.medium`, `mw1.large`. Will be set by default to `mw1.small`. Please check the [AWS Pricing](https://aws.amazon.com/de/managed-workflows-for-apache-airflow/pricing/) for more information about the environment classes.
     * 
     */
    private UndeferrableValue<String> environmentClass;

    public String environmentClass() {
        if (environmentClass == null) return null;
        return environmentClass.getValue("EnvironmentArgs.environmentClass");
    }

    /**
     * The Amazon Resource Name (ARN) of the task execution role that the Amazon MWAA and its environment can assume. Check the [official AWS documentation](https://docs.aws.amazon.com/mwaa/latest/userguide/mwaa-create-role.html) for the detailed role specification.
     * 
     */
    private UndeferrableValue<String> executionRoleArn;

    public String executionRoleArn() {
        if (executionRoleArn == null) return null;
        return executionRoleArn.getValue("EnvironmentArgs.executionRoleArn");
    }

    /**
     * The Amazon Resource Name (ARN) of your KMS key that you want to use for encryption. Will be set to the ARN of the managed KMS key `aws/airflow` by default. Please check the [Official Documentation](https://docs.aws.amazon.com/mwaa/latest/userguide/custom-keys-certs.html) for more information.
     * 
     */
    private UndeferrableValue<String> kmsKey;

    public String kmsKey() {
        if (kmsKey == null) return null;
        return kmsKey.getValue("EnvironmentArgs.kmsKey");
    }

    /**
     * The Apache Airflow logs you want to send to Amazon CloudWatch Logs. See `logging_configuration` Block for details.
     * 
     */
    private UndeferrableValue<EnvironmentLoggingConfigurationArgs> loggingConfiguration;

    public EnvironmentLoggingConfigurationArgs loggingConfiguration() {
        if (loggingConfiguration == null) return null;
        return loggingConfiguration.getValue("EnvironmentArgs.loggingConfiguration");
    }

    /**
     * The maximum number of web servers that you want to run in your environment. Value need to be between `2` and `5` if `environment_class` is not `mw1.micro`, `1` otherwise.
     * 
     */
    private UndeferrableValue<Integer> maxWebservers;

    public Integer maxWebservers() {
        if (maxWebservers == null) return null;
        return maxWebservers.getValue("EnvironmentArgs.maxWebservers");
    }

    /**
     * The maximum number of workers that can be automatically scaled up. Value need to be between `1` and `25`. Will be `10` by default.
     * 
     */
    private UndeferrableValue<Integer> maxWorkers;

    public Integer maxWorkers() {
        if (maxWorkers == null) return null;
        return maxWorkers.getValue("EnvironmentArgs.maxWorkers");
    }

    /**
     * The minimum number of web servers that you want to run in your environment. Value need to be between `2` and `5` if `environment_class` is not `mw1.micro`, `1` otherwise.
     * 
     */
    private UndeferrableValue<Integer> minWebservers;

    public Integer minWebservers() {
        if (minWebservers == null) return null;
        return minWebservers.getValue("EnvironmentArgs.minWebservers");
    }

    /**
     * The minimum number of workers that you want to run in your environment. Will be `1` by default.
     * 
     */
    private UndeferrableValue<Integer> minWorkers;

    public Integer minWorkers() {
        if (minWorkers == null) return null;
        return minWorkers.getValue("EnvironmentArgs.minWorkers");
    }

    /**
     * The name of the Apache Airflow Environment
     * 
     */
    private UndeferrableValue<String> name;

    public String name() {
        if (name == null) return null;
        return name.getValue("EnvironmentArgs.name");
    }

    /**
     * Specifies the network configuration for your Apache Airflow Environment. This includes two private subnets as well as security groups for the Airflow environment. Each subnet requires internet connection, otherwise the deployment will fail. See `network_configuration` Block for details.
     * 
     */
    private UndeferrableValue<EnvironmentNetworkConfigurationArgs> networkConfiguration;

    public EnvironmentNetworkConfigurationArgs networkConfiguration() {
        if (networkConfiguration == null) return null;
        return networkConfiguration.getValue("EnvironmentArgs.networkConfiguration");
    }

    /**
     * The plugins.zip file version you want to use.
     * 
     */
    private UndeferrableValue<String> pluginsS3ObjectVersion;

    public String pluginsS3ObjectVersion() {
        if (pluginsS3ObjectVersion == null) return null;
        return pluginsS3ObjectVersion.getValue("EnvironmentArgs.pluginsS3ObjectVersion");
    }

    /**
     * The relative path to the plugins.zip file on your Amazon S3 storage bucket. For example, plugins.zip. If a relative path is provided in the request, then plugins_s3_object_version is required. For more information, see [Importing DAGs on Amazon MWAA](https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-import.html).
     * 
     */
    private UndeferrableValue<String> pluginsS3Path;

    public String pluginsS3Path() {
        if (pluginsS3Path == null) return null;
        return pluginsS3Path.getValue("EnvironmentArgs.pluginsS3Path");
    }

    /**
     * The requirements.txt file version you want to use.
     * 
     */
    private UndeferrableValue<String> requirementsS3ObjectVersion;

    public String requirementsS3ObjectVersion() {
        if (requirementsS3ObjectVersion == null) return null;
        return requirementsS3ObjectVersion.getValue("EnvironmentArgs.requirementsS3ObjectVersion");
    }

    /**
     * The relative path to the requirements.txt file on your Amazon S3 storage bucket. For example, requirements.txt. If a relative path is provided in the request, then requirements_s3_object_version is required. For more information, see [Importing DAGs on Amazon MWAA](https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-dag-import.html).
     * 
     */
    private UndeferrableValue<String> requirementsS3Path;

    public String requirementsS3Path() {
        if (requirementsS3Path == null) return null;
        return requirementsS3Path.getValue("EnvironmentArgs.requirementsS3Path");
    }

    /**
     * The number of schedulers that you want to run in your environment. v2.0.2 and above accepts `2` - `5`, default `2`. v1.10.12 accepts `1`.
     * 
     */
    private UndeferrableValue<Integer> schedulers;

    public Integer schedulers() {
        if (schedulers == null) return null;
        return schedulers.getValue("EnvironmentArgs.schedulers");
    }

    /**
     * The Amazon Resource Name (ARN) of your Amazon S3 storage bucket. For example, arn:aws:s3:::airflow-mybucketname.
     * 
     */
    private UndeferrableValue<String> sourceBucketArn;

    public String sourceBucketArn() {
        if (sourceBucketArn == null) return null;
        return sourceBucketArn.getValue("EnvironmentArgs.sourceBucketArn");
    }

    /**
     * The version of the startup shell script you want to use. You must specify the version ID that Amazon S3 assigns to the file every time you update the script.
     * 
     */
    private UndeferrableValue<String> startupScriptS3ObjectVersion;

    public String startupScriptS3ObjectVersion() {
        if (startupScriptS3ObjectVersion == null) return null;
        return startupScriptS3ObjectVersion.getValue("EnvironmentArgs.startupScriptS3ObjectVersion");
    }

    /**
     * The relative path to the script hosted in your bucket. The script runs as your environment starts before starting the Apache Airflow process. Use this script to install dependencies, modify configuration options, and set environment variables. See [Using a startup script](https://docs.aws.amazon.com/mwaa/latest/userguide/using-startup-script.html). Supported for environment versions 2.x and later.
     * 
     */
    private UndeferrableValue<String> startupScriptS3Path;

    public String startupScriptS3Path() {
        if (startupScriptS3Path == null) return null;
        return startupScriptS3Path.getValue("EnvironmentArgs.startupScriptS3Path");
    }

    /**
     * A map of resource tags to associate with the resource. If configured with a provider `default_tags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
     * 
     */
    private UndeferrableValue<Map<String,String>> tags;

    public Map<String,String> tags() {
        if (tags == null) return null;
        return tags.getValue("EnvironmentArgs.tags");
    }

    /**
     * Specifies whether the webserver should be accessible over the internet or via your specified VPC. Possible options: `PRIVATE_ONLY` (default) and `PUBLIC_ONLY`.
     * 
     */
    private UndeferrableValue<String> webserverAccessMode;

    public String webserverAccessMode() {
        if (webserverAccessMode == null) return null;
        return webserverAccessMode.getValue("EnvironmentArgs.webserverAccessMode");
    }

    /**
     * Specifies the start date for the weekly maintenance window.
     * 
     */
    private UndeferrableValue<String> weeklyMaintenanceWindowStart;

    public String weeklyMaintenanceWindowStart() {
        if (weeklyMaintenanceWindowStart == null) return null;
        return weeklyMaintenanceWindowStart.getValue("EnvironmentArgs.weeklyMaintenanceWindowStart");
    }

}
