// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.policypacks.aws.bedrock;

import java.lang.Double;
import java.lang.Integer;
import java.lang.String;
import java.util.List;


public final class AgentAgentPromptOverrideConfigurationPromptConfigurationInferenceConfiguration {

    /**
     * Maximum number of tokens to allow in the generated response.
     * 
     */
    public Integer maxLength;



    /**
     * List of stop sequences. A stop sequence is a sequence of characters that causes the model to stop generating the response.
     * 
     */
    public List<String> stopSequences;



    /**
     * Likelihood of the model selecting higher-probability options while generating a response. A lower value makes the model more likely to choose higher-probability options, while a higher value makes the model more likely to choose lower-probability options.
     * 
     */
    public Double temperature;



    /**
     * Number of top most-likely candidates, between 0 and 500, from which the model chooses the next token in the sequence.
     * 
     */
    public Integer topK;



    /**
     * Top percentage of the probability distribution of next tokens, between 0 and 1 (denoting 0% and 100%), from which the model chooses the next token in the sequence.
     * 
     */
    public Double topP;



}
