// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.policypacks.aws.sagemaker;

import com.pulumi.core.UndeferrableValue;
import com.pulumi.core.annotations.PolicyResourceType;
import com.pulumi.policypacks.aws.sagemaker.inputs.ModelContainerArgs;
import com.pulumi.policypacks.aws.sagemaker.inputs.ModelInferenceExecutionConfigArgs;
import com.pulumi.policypacks.aws.sagemaker.inputs.ModelPrimaryContainerArgs;
import com.pulumi.policypacks.aws.sagemaker.inputs.ModelVpcConfigArgs;
import java.lang.Boolean;
import java.lang.String;
import java.util.List;
import java.util.Map;
import javax.annotation.Nullable;


@PolicyResourceType(type="aws:sagemaker/model:Model")
public final class ModelArgs extends com.pulumi.resources.PolicyResourceInput {

    /**
     * Specifies containers in the inference pipeline. If not specified, the `primary_container` argument is required. Fields are documented below.
     * 
     */
    private UndeferrableValue<List<ModelContainerArgs>> containers;

    public List<ModelContainerArgs> containers() {
        if (containers == null) return null;
        return containers.getValue("ModelArgs.containers");
    }

    /**
     * Isolates the model container. No inbound or outbound network calls can be made to or from the model container.
     * 
     */
    private UndeferrableValue<Boolean> enableNetworkIsolation;

    public Boolean enableNetworkIsolation() {
        if (enableNetworkIsolation == null) return null;
        return enableNetworkIsolation.getValue("ModelArgs.enableNetworkIsolation");
    }

    /**
     * A role that SageMaker AI can assume to access model artifacts and docker images for deployment.
     * 
     */
    private UndeferrableValue<String> executionRoleArn;

    public String executionRoleArn() {
        if (executionRoleArn == null) return null;
        return executionRoleArn.getValue("ModelArgs.executionRoleArn");
    }

    /**
     * Specifies details of how containers in a multi-container endpoint are called. see Inference Execution Config.
     * 
     */
    private UndeferrableValue<ModelInferenceExecutionConfigArgs> inferenceExecutionConfig;

    public ModelInferenceExecutionConfigArgs inferenceExecutionConfig() {
        if (inferenceExecutionConfig == null) return null;
        return inferenceExecutionConfig.getValue("ModelArgs.inferenceExecutionConfig");
    }

    /**
     * The name of the model (must be unique). If omitted, this provider will assign a random, unique name.
     * 
     */
    private UndeferrableValue<String> name;

    public String name() {
        if (name == null) return null;
        return name.getValue("ModelArgs.name");
    }

    /**
     * The primary docker image containing inference code that is used when the model is deployed for predictions.  If not specified, the `container` argument is required. Fields are documented below.
     * 
     */
    private UndeferrableValue<ModelPrimaryContainerArgs> primaryContainer;

    public ModelPrimaryContainerArgs primaryContainer() {
        if (primaryContainer == null) return null;
        return primaryContainer.getValue("ModelArgs.primaryContainer");
    }

    /**
     * A map of tags to assign to the resource. .If configured with a provider `default_tags` configuration block present, tags with matching keys will overwrite those defined at the provider-level.
     * 
     */
    private UndeferrableValue<Map<String,String>> tags;

    public Map<String,String> tags() {
        if (tags == null) return null;
        return tags.getValue("ModelArgs.tags");
    }

    /**
     * Specifies the VPC that you want your model to connect to. VpcConfig is used in hosting services and in batch transform.
     * 
     */
    private UndeferrableValue<ModelVpcConfigArgs> vpcConfig;

    public ModelVpcConfigArgs vpcConfig() {
        if (vpcConfig == null) return null;
        return vpcConfig.getValue("ModelArgs.vpcConfig");
    }

}
